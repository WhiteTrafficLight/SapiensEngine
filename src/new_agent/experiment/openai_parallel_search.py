"""
OpenAI ì›¹ì„œì¹˜ íˆ´ì„ ì´ìš©í•œ ë³‘ë ¬ ì›¹ì„œì¹˜ êµ¬í˜„

ìƒˆë¡œìš´ OpenAI Responses APIì˜ ì›¹ì„œì¹˜ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ê²€ìƒ‰ êµ¬í˜„
"""

import os
import time
import logging
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import openai

logger = logging.getLogger(__name__)

class OpenAIParallelSearcher:
    """
    OpenAI ì›¹ì„œì¹˜ íˆ´ì„ ì‚¬ìš©í•œ ë³‘ë ¬ ì›¹ ê²€ìƒ‰ê¸°
    
    OpenAI Responses APIì˜ web_search_preview ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬
    ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ë™ì‹œì— ë³‘ë ¬ë¡œ ì²˜ë¦¬
    """
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o"):
        """
        OpenAI ë³‘ë ¬ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        
        Args:
            api_key: OpenAI API í‚¤
            model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸: gpt-4o)
        """
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY")
        
        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        self.client = openai.OpenAI(api_key=self.api_key)
        self.model = model
        self.search_history = []
        
        logger.info(f"OpenAI Parallel Searcher ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {model})")
    
    async def search_single_query_async(self, query: str, context_size: str = "low") -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì¿¼ë¦¬ ë¹„ë™ê¸° ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            context_size: ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ("low", "medium", "high")
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        try:
            logger.info(f"ğŸš€ OpenAI ì›¹ì„œì¹˜ ì‹œì‘: '{query}'")
            
            # OpenAI Responses API í˜¸ì¶œ
            response = await asyncio.to_thread(
                self.client.responses.create,
                model=self.model,
                tools=[{
                    "type": "web_search_preview",
                    "search_context_size": context_size
                }],
                input=query
            )
            
            # ì›ë³¸ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ì €ì¥ - ë³€í™˜í•˜ì§€ ì•ŠìŒ
            raw_output = []
            output_text = ""
            
            if hasattr(response, 'output') and response.output:
                # ì›ë³¸ outputì„ ê·¸ëŒ€ë¡œ ì €ì¥
                for output_item in response.output:
                    if hasattr(output_item, 'model_dump'):
                        raw_output.append(output_item.model_dump())
                    elif hasattr(output_item, '__dict__'):
                        raw_output.append(output_item.__dict__)
                    else:
                        raw_output.append(str(output_item))
            
            # output_text ì¶”ì¶œ (í¸ì˜ë¥¼ ìœ„í•´)
            if hasattr(response, 'output_text'):
                output_text = response.output_text
            
            end_time = time.time()
            search_time = end_time - start_time
            
            # ì›ë³¸ ì‘ë‹µ êµ¬ì¡° ê·¸ëŒ€ë¡œ ë°˜í™˜
            search_result = {
                "query": query,
                "raw_openai_output": raw_output,  # ì›ë³¸ output ê·¸ëŒ€ë¡œ
                "output_text": output_text,       # í…ìŠ¤íŠ¸ë§Œ ë”°ë¡œ (í¸ì˜ìš©)
                "search_time": search_time,
                "timestamp": datetime.now().isoformat(),
                "source": "openai_web_search_raw",
                "context_size": context_size,
                "model": self.model
            }
            
            self.search_history.append(search_result)
            
            logger.info(f"âœ… OpenAI ì›¹ì„œì¹˜ ì™„ë£Œ: ì›ë³¸ ì‘ë‹µ ì €ì¥ ({search_time:.2f}ì´ˆ)")
            
            return search_result
            
        except Exception as e:
            end_time = time.time()
            search_time = end_time - start_time
            
            logger.error(f"âŒ OpenAI ì›¹ì„œì¹˜ ì‹¤íŒ¨: {str(e)}")
            
            error_result = {
                "query": query,
                "raw_openai_output": [],
                "output_text": "",
                "search_time": search_time,
                "timestamp": datetime.now().isoformat(),
                "source": "openai_web_search_raw",
                "context_size": context_size,
                "model": self.model,
                "error": str(e)
            }
            
            self.search_history.append(error_result)
            return error_result
    
    async def search_multiple_queries_parallel(self, queries: List[str], context_size: str = "low") -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ë³‘ë ¬ë¡œ ê²€ìƒ‰ (ìƒˆë¡œìš´ ë°©ì‹)
        
        Args:
            queries: ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
            context_size: ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ í¬ê¸°
            
        Returns:
            ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        overall_start_time = time.time()
        
        logger.info(f"ğŸ”¥ OpenAI ë³‘ë ¬ ì›¹ì„œì¹˜ ì‹œì‘: {len(queries)}ê°œ ì¿¼ë¦¬")
        
        # ëª¨ë“  ì¿¼ë¦¬ë¥¼ ë¹„ë™ê¸° íƒœìŠ¤í¬ë¡œ ìƒì„±
        tasks = []
        for i, query in enumerate(queries, 1):
            logger.info(f"  [{i}/{len(queries)}] íƒœìŠ¤í¬ ìƒì„±: '{query}'")
            task = self.search_single_query_async(query, context_size)
            tasks.append(task)
        
        # ëª¨ë“  íƒœìŠ¤í¬ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
        logger.info(f"âš¡ {len(tasks)}ê°œ ê²€ìƒ‰ íƒœìŠ¤í¬ ë³‘ë ¬ ì‹¤í–‰ ì¤‘...")
        
        try:
            all_results = await asyncio.gather(*tasks, return_exceptions=True)
        except Exception as e:
            logger.error(f"ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            all_results = []
        
        overall_end_time = time.time()
        total_time = overall_end_time - overall_start_time
        
        # ê²°ê³¼ ì •ë¦¬
        successful_results = []
        individual_times = []
        
        for i, result in enumerate(all_results):
            if isinstance(result, Exception):
                logger.error(f"ì¿¼ë¦¬ {i+1} ì‹¤í–‰ ì¤‘ ì˜ˆì™¸: {str(result)}")
                error_result = {
                    "query": queries[i] if i < len(queries) else f"query_{i}",
                    "raw_openai_output": [],
                    "output_text": "",
                    "search_time": 0,
                    "timestamp": datetime.now().isoformat(),
                    "source": "openai_web_search_raw",
                    "context_size": context_size,
                    "model": self.model,
                    "error": str(result)
                }
                successful_results.append(error_result)
                individual_times.append(0)
            else:
                successful_results.append(result)
                individual_times.append(result.get("search_time", 0))
        
        # ê²°ê³¼ í†µí•©
        all_search_results = []
        total_found = 0
        
        for result in successful_results:
            # ì›ë³¸ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ìœ ì§€
            all_search_results.append(result)
            total_found += len(result.get("raw_openai_output", []))
        
        final_result = {
            "method": "openai_web_search_parallel",
            "queries": queries,
            "total_queries": len(queries),
            "all_results": all_search_results,  # ê°œë³„ ê²€ìƒ‰ ê²°ê³¼ë“¤ì„ ê·¸ëŒ€ë¡œ ì €ì¥
            "total_found": total_found,
            "individual_results": successful_results,
            "individual_times": individual_times,
            "total_time": total_time,
            "average_time_per_query": total_time / len(queries) if queries else 0,
            "timestamp": datetime.now().isoformat(),
            "context_size": context_size,
            "model": self.model,
            "performance_stats": {
                "fastest_query": min(individual_times) if individual_times else 0,
                "slowest_query": max(individual_times) if individual_times else 0,
                "total_requests": len(queries),
                "successful_requests": len([r for r in successful_results if not r.get("error")]),
                "parallel_efficiency": (sum(individual_times) / total_time) if total_time > 0 else 0  # ë³‘ë ¬ íš¨ìœ¨ì„±
            }
        }
        
        logger.info(f"ğŸ OpenAI ë³‘ë ¬ ì›¹ì„œì¹˜ ì™„ë£Œ:")
        logger.info(f"   ğŸ“Š ì´ {len(queries)}ê°œ ì¿¼ë¦¬, {total_found}ê°œ ê²°ê³¼")
        logger.info(f"   â±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"   ğŸ“ˆ ì¿¼ë¦¬ë‹¹ í‰ê· : {final_result['average_time_per_query']:.2f}ì´ˆ")
        logger.info(f"   ğŸš€ ë³‘ë ¬ íš¨ìœ¨ì„±: {final_result['performance_stats']['parallel_efficiency']:.2f}")
        
        return final_result
    
    def search_multiple_queries_parallel_sync(self, queries: List[str], context_size: str = "low") -> Dict[str, Any]:
        """
        ë™ê¸°ì  ë˜í¼ í•¨ìˆ˜ - ë³‘ë ¬ ê²€ìƒ‰ì„ ë™ê¸° í•¨ìˆ˜ì—ì„œ í˜¸ì¶œ
        
        Args:
            queries: ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
            context_size: ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ í¬ê¸°
            
        Returns:
            ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±í•˜ì—¬ ì‹¤í–‰
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                return loop.run_until_complete(
                    self.search_multiple_queries_parallel(queries, context_size)
                )
            finally:
                loop.close()
                
        except Exception as e:
            logger.error(f"ë™ê¸° ë˜í¼ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "method": "openai_web_search_parallel",
                "queries": queries,
                "total_queries": len(queries),
                "all_results": [],
                "total_found": 0,
                "individual_results": [],
                "individual_times": [],
                "total_time": 0,
                "average_time_per_query": 0,
                "timestamp": datetime.now().isoformat(),
                "context_size": context_size,
                "model": self.model,
                "error": str(e)
            }
    
    def _extract_domain(self, url: str) -> str:
        """URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ"""
        try:
            from urllib.parse import urlparse
            domain = urlparse(url).netloc
            if domain.startswith("www."):
                domain = domain[4:]
            return domain
        except:
            return "unknown"
    
    def get_search_history(self) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.search_history
    
    def clear_history(self):
        """ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì‚­ì œ"""
        self.search_history = []
        logger.info("ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ í†µê³„ ë°˜í™˜"""
        if not self.search_history:
            return {"message": "ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        times = [h.get("search_time", 0) for h in self.search_history if "search_time" in h]
        
        return {
            "total_searches": len(self.search_history),
            "successful_searches": len([h for h in self.search_history if not h.get("error")]),
            "average_time": sum(times) / len(times) if times else 0,
            "fastest_search": min(times) if times else 0,
            "slowest_search": max(times) if times else 0,
            "total_results_found": sum(h.get("total_found", 0) for h in self.search_history)
        } 