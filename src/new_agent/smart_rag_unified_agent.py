#!/usr/bin/env python3
"""
ì§€ëŠ¥í˜• RAG í†µí•© í† ë¡  ì—ì´ì „íŠ¸

ì–¸ì œ RAG/ì›¹ì„œì¹˜ë¥¼ ì‚¬ìš©í• ì§€ ì§€ëŠ¥ì ìœ¼ë¡œ íŒë‹¨í•˜ê³ 
OpenAIì˜ ìµœì‹  ê¸°ëŠ¥ë“¤ì„ í™œìš©í•œ ì‹¤ì œ êµ¬í˜„
"""

import json
import logging
import time
import aiohttp
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime
import openai
import numpy as np
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class RAGDecision:
    """RAG ì‚¬ìš© ê²°ì • ì •ë³´"""
    use_web_search: bool
    use_vector_search: bool  
    use_philosopher_search: bool
    confidence: float
    reasoning: str

class SmartRAGUnifiedAgent:
    """
    ì§€ëŠ¥í˜• RAG í†µí•© í† ë¡  ì—ì´ì „íŠ¸
    
    íŠ¹ì§•:
    - ìƒí™©ì— ë”°ë¼ RAG/ì›¹ì„œì¹˜ í•„ìš”ì„± ìë™ íŒë‹¨
    - OpenAI Function Calling + ì‹¤ì œ ì›¹/ë²¡í„° ê²€ìƒ‰
    - ì² í•™ìë³„ ë§ì¶¤í˜• ê²€ìƒ‰ ì „ëµ
    """
    
    def __init__(self, agent_id: str, philosopher_data: Dict[str, Any], config: Dict[str, Any]):
        self.agent_id = agent_id
        self.philosopher_data = philosopher_data
        self.config = config
        self.llm_manager = config.get('llm_manager')
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_stats = {
            'llm_calls': 0,
            'web_searches': 0,
            'vector_searches': 0,
            'total_time': 0
        }
        
        # RAG ì‚¬ìš© íŒë‹¨ ê¸°ì¤€
        self.rag_triggers = {
            'current_events': ['politics', 'policy', 'government', 'regulation', 'law', 'economy', 'technology', 'climate', 'war', 'AI', 'artificial intelligence', '2024', '2025', 'recent', 'current', 'news'],
            'data_heavy': ['statistics', 'research', 'study', 'percentage', 'number', 'data', 'survey', 'analysis', 'evidence', 'productivity', 'remote work', 'scientific', 'empirical'],
            'factual_claims': ['according to', 'research shows', 'data indicates', 'study found', 'evidence suggests', 'scientific consensus'],
            'philosophical_depth': ['consciousness', 'ethics', 'morality', 'existence', 'justice', 'mind', 'brain', 'philosophy', 'ontology', 'epistemology', 'metaphysics', 'ethical', 'moral']
        }
        
        # í•¨ìˆ˜ ì •ì˜
        self.functions = self._define_intelligent_functions()
        
    def _define_intelligent_functions(self) -> List[Dict[str, Any]]:
        """ì§€ëŠ¥í˜• Function Calling ì •ì˜"""
        return [
            {
                "name": "analyze_topic_for_rag_needs",
                "description": "í† ë¡  ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ RAG/ì›¹ì„œì¹˜ í•„ìš”ì„±ì„ íŒë‹¨í•©ë‹ˆë‹¤",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "topic": {"type": "string", "description": "ë¶„ì„í•  í† ë¡  ì£¼ì œ"},
                        "context": {"type": "string", "description": "í† ë¡  ë§¥ë½"},
                        "philosopher_style": {"type": "string", "description": "ì² í•™ìì˜ ë…¼ì¦ ìŠ¤íƒ€ì¼"}
                    },
                    "required": ["topic", "context", "philosopher_style"]
                }
            },
            {
                "name": "real_time_web_search",
                "description": "ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ìµœì‹  ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "ê²€ìƒ‰ ì¿¼ë¦¬"},
                        "search_type": {"type": "string", "enum": ["news", "academic", "general"], "description": "ê²€ìƒ‰ íƒ€ì…"},
                        "max_results": {"type": "integer", "description": "ìµœëŒ€ ê²°ê³¼ ìˆ˜", "default": 3}
                    },
                    "required": ["query", "search_type"]
                }
            },
            {
                "name": "vector_knowledge_search", 
                "description": "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì§€ì‹ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "ê²€ìƒ‰í•  ê°œë…ì´ë‚˜ ì£¼ì œ"},
                        "domain": {"type": "string", "enum": ["philosophy", "ethics", "politics", "science"], "description": "ê²€ìƒ‰ ë„ë©”ì¸"},
                        "max_results": {"type": "integer", "description": "ìµœëŒ€ ê²°ê³¼ ìˆ˜", "default": 3}
                    },
                    "required": ["query", "domain"]
                }
            },
            {
                "name": "philosopher_wisdom_retrieval",
                "description": "íŠ¹ì • ì² í•™ìì˜ ì‚¬ìƒê³¼ ì €ì‘ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "philosopher": {"type": "string", "description": "ì² í•™ì ì´ë¦„"},
                        "topic": {"type": "string", "description": "ê´€ë ¨ ì£¼ì œ"},
                        "quote_style": {"type": "string", "enum": ["direct", "interpretation", "application"], "description": "ì¸ìš© ìŠ¤íƒ€ì¼"}
                    },
                    "required": ["philosopher", "topic"]
                }
            },
            {
                "name": "generate_enhanced_argument",
                "description": "ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°•í™”ëœ ë…¼ì¦ì„ ìƒì„±í•©ë‹ˆë‹¤",
                "parameters": {
                    "type": "object", 
                    "properties": {
                        "core_position": {"type": "string", "description": "í•µì‹¬ ì…ì¥"},
                        "evidence": {"type": "array", "items": {"type": "string"}, "description": "ìˆ˜ì§‘ëœ ì¦ê±°ë“¤"},
                        "philosophical_framework": {"type": "string", "description": "ì² í•™ì  í‹€"},
                        "target_audience": {"type": "string", "description": "ëŒ€ìƒ ì²­ì¤‘"}
                    },
                    "required": ["core_position", "evidence", "philosophical_framework"]
                }
            }
        ]
    
    async def generate_intelligent_opening_argument(self, topic: str, stance: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ì§€ëŠ¥í˜• ì…ë¡  ìƒì„±
        
        1. ì£¼ì œ ë¶„ì„ â†’ RAG í•„ìš”ì„± íŒë‹¨
        2. í•„ìš”ì‹œ ì„ íƒì  RAG/ì›¹ì„œì¹˜ ìˆ˜í–‰  
        3. ìˆ˜ì§‘ëœ ì •ë³´ë¡œ ê°•í™”ëœ ë…¼ì¦ ìƒì„±
        """
        start_time = time.time()
        
        # ì² í•™ì íŠ¹ì„± ì¶”ì¶œ
        philosopher_name = self.philosopher_data.get('name', 'Unknown')
        debate_style = self.philosopher_data.get('debate_style', '')
        key_traits = self.philosopher_data.get('key_traits', [])
        rag_affinity = self.philosopher_data.get('rag_affinity', 0.5)
        
        print(f"ğŸ§  [{philosopher_name}] ì§€ëŠ¥í˜• ì…ë¡  ìƒì„± ì‹œì‘...")
        print(f"   RAG ì¹œí™”ë„: {rag_affinity}")
        
        system_prompt = f"""
ë‹¹ì‹ ì€ {philosopher_name}ì…ë‹ˆë‹¤.

ì² í•™ì íŠ¹ì„±:
- ë³¸ì§ˆ: {self.philosopher_data.get('essence', '')}
- í† ë¡  ìŠ¤íƒ€ì¼: {debate_style}
- í•µì‹¬ íŠ¹ì§•: {', '.join(key_traits)}
- RAG í™œìš© ì¹œí™”ë„: {rag_affinity}

ì£¼ì œ: {topic}
ì…ì¥: {stance}
ë§¥ë½: {context.get('context_summary', '') if context else ''}

**ì¤‘ìš”**: ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë°˜ë“œì‹œ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì„¸ìš”:

1. **í•„ìˆ˜**: analyze_topic_for_rag_needsë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì—¬ ì´ ì£¼ì œì˜ RAG ê²€ìƒ‰ í•„ìš”ì„±ì„ ë¶„ì„í•˜ì„¸ìš”
2. **ì¡°ê±´ë¶€ ê²€ìƒ‰**: 1ë‹¨ê³„ ê²°ê³¼ì— ë”°ë¼ ì ì ˆí•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì„¸ìš”:
   - use_web_searchê°€ trueë©´ â†’ real_time_web_search í˜¸ì¶œ (ìµœì‹  ì •ë³´ë‚˜ í†µê³„ê°€ í•„ìš”í•œ ê²½ìš°)
   - use_vector_searchê°€ trueë©´ â†’ vector_knowledge_search í˜¸ì¶œ (í•™ìˆ ì /ì´ë¡ ì  ë°°ê²½ì´ í•„ìš”í•œ ê²½ìš°)  
   - use_philosopher_searchê°€ trueë©´ â†’ philosopher_wisdom_retrieval í˜¸ì¶œ (ë‹¹ì‹ ì˜ ì² í•™ì  ê´€ì ì„ ê°•í™”í•  ê²½ìš°)
3. **í•„ìˆ˜**: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ generate_enhanced_argumentë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì¢… ì…ë¡ ì„ ìƒì„±í•˜ì„¸ìš”

**ì£¼ì˜ì‚¬í•­**:
- í˜„ì¬ ì£¼ì œì— 'AI', 'regulation', 'government', 'policy' ë“±ì´ í¬í•¨ë˜ë©´ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤
- 'statistics', 'productivity', 'data' ë“±ì´ í¬í•¨ë˜ë©´ ë²¡í„° ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤  
- 'consciousness', 'ethics', 'philosophy' ë“±ì´ í¬í•¨ë˜ë©´ ì² í•™ì ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤
- ë‹¹ì‹ ì˜ RAG ì¹œí™”ë„ê°€ 0.2 ì´ìƒì´ë©´ ê²€ìƒ‰ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤

ì² í•™ìì˜ íŠ¹ì„±ì„ ì‚´ë ¤ ì„¤ë“ë ¥ ìˆê²Œ ì‘ì„±í•˜ë˜, ì ì ˆí•œ ê²€ìƒ‰ìœ¼ë¡œ ë…¼ì¦ì„ ê°•í™”í•˜ì„¸ìš”.
"""

        try:
            # ì§€ëŠ¥í˜• Function Calling ì‹¤í–‰
            response = await self.llm_manager.generate_response_with_functions(
                system_prompt=system_prompt,
                user_prompt=f"'{topic}'ì— ëŒ€í•œ {stance} ì…ì¥ì˜ ì…ë¡ ì„ ìƒì„±í•˜ì„¸ìš”.",
                functions=self.functions,
                function_handler=self._handle_intelligent_function_call
            )
            
            end_time = time.time()
            self._update_performance_stats(end_time - start_time, 1)
            
            print(f"âœ… [{philosopher_name}] ì§€ëŠ¥í˜• ì…ë¡  ì™„ë£Œ (ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ)")
            print(f"   ğŸ“Š LLM í˜¸ì¶œ: {self.performance_stats['llm_calls']}íšŒ")
            print(f"   ğŸŒ ì›¹ ê²€ìƒ‰: {self.performance_stats['web_searches']}íšŒ")
            print(f"   ğŸ“š ë²¡í„° ê²€ìƒ‰: {self.performance_stats['vector_searches']}íšŒ")
            
            return {
                "status": "success",
                "argument": response,
                "generation_time": end_time - start_time,
                "llm_calls": self.performance_stats['llm_calls'],
                "web_searches": self.performance_stats['web_searches'],
                "vector_searches": self.performance_stats['vector_searches'],
                "philosopher": philosopher_name
            }
            
        except Exception as e:
            logger.error(f"Error in intelligent argument generation: {str(e)}")
            return {
                "status": "error", 
                "message": str(e),
                "generation_time": time.time() - start_time
            }
    
    async def _handle_intelligent_function_call(self, function_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """ì§€ëŠ¥í˜• í•¨ìˆ˜ í˜¸ì¶œ ì²˜ë¦¬"""
        
        if function_name == "analyze_topic_for_rag_needs":
            return await self._analyze_rag_needs(arguments)
        elif function_name == "real_time_web_search":
            return await self._real_time_web_search(arguments)
        elif function_name == "vector_knowledge_search":
            return await self._vector_knowledge_search(arguments)
        elif function_name == "philosopher_wisdom_retrieval":
            return await self._philosopher_wisdom_retrieval(arguments)
        elif function_name == "generate_enhanced_argument":
            return await self._generate_enhanced_argument(arguments)
        else:
            return {"error": f"Unknown function: {function_name}"}
    
    async def _analyze_rag_needs(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """RAG í•„ìš”ì„± ì§€ëŠ¥ì  ë¶„ì„"""
        topic = args.get('topic', '')
        context = args.get('context', '')
        philosopher_style = args.get('philosopher_style', '')
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        topic_lower = topic.lower()
        context_lower = context.lower()
        
        needs_web = any(keyword in topic_lower or keyword in context_lower 
                       for category in ['current_events', 'data_heavy'] 
                       for keyword in self.rag_triggers[category])
        
        needs_vector = any(keyword in topic_lower 
                          for keyword in self.rag_triggers['philosophical_depth'])
        
        needs_philosopher = any(keyword in topic_lower for keyword in ['ethics', 'moral', 'philosophy', 'consciousness'])
        
        # ì² í•™ìì˜ RAG ì¹œí™”ë„ ê³ ë ¤ (ì¡°ê±´ ì™„í™”)
        rag_affinity = self.philosopher_data.get('rag_affinity', 0.5)
        
        # ë” ê´€ëŒ€í•œ ì¡°ê±´ìœ¼ë¡œ ë³€ê²½
        decision = RAGDecision(
            use_web_search=needs_web and rag_affinity > 0.2,  # 0.3 -> 0.2ë¡œ ì™„í™”
            use_vector_search=needs_vector and rag_affinity > 0.2,  # 0.4 -> 0.2ë¡œ ì™„í™”  
            use_philosopher_search=needs_philosopher or rag_affinity > 0.5,  # 0.7 -> 0.5ë¡œ ì™„í™”
            confidence=0.8,
            reasoning=f"Topic analysis: web={needs_web}, vector={needs_vector}, philosopher={needs_philosopher}, affinity={rag_affinity}"
        )
        
        print(f"   ğŸ” RAG ë¶„ì„ ê²°ê³¼:")
        print(f"      ì›¹ ê²€ìƒ‰ í•„ìš”: {decision.use_web_search} (í‚¤ì›Œë“œ ë§¤ì¹­: {needs_web}, ì¹œí™”ë„: {rag_affinity})")
        print(f"      ë²¡í„° ê²€ìƒ‰ í•„ìš”: {decision.use_vector_search} (í‚¤ì›Œë“œ ë§¤ì¹­: {needs_vector})")
        print(f"      ì² í•™ì ê²€ìƒ‰ í•„ìš”: {decision.use_philosopher_search} (í‚¤ì›Œë“œ ë§¤ì¹­: {needs_philosopher})")
        
        return {
            "rag_decision": {
                "use_web_search": decision.use_web_search,
                "use_vector_search": decision.use_vector_search,
                "use_philosopher_search": decision.use_philosopher_search,
                "confidence": decision.confidence,
                "reasoning": decision.reasoning
            }
        }
    
    async def _real_time_web_search(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """OpenAI ê³µì‹ ì›¹ ê²€ìƒ‰ (Responses API í™œìš©)"""
        query = args.get('query', '')
        search_type = args.get('search_type', 'general')
        max_results = args.get('max_results', 3)
        
        self.performance_stats['web_searches'] += 1
        
        try:
            # OpenAI ê³µì‹ ì›¹ ê²€ìƒ‰ ì‚¬ìš©
            response = self.llm_manager.client.responses.create(
                model="gpt-4o",
                input=[
                    {
                        "role": "system",
                        "content": [
                            {
                                "type": "input_text",
                                "text": f"You are a research assistant. Search the web for: {query}. Focus on {search_type} information. Provide accurate, recent information with proper citations."
                            }
                        ]
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "input_text",
                                "text": f"Search for recent information about: {query}"
                            }
                        ]
                    }
                ],
                tools=[
                    {
                        "type": "web_search_preview",
                        "search_context_size": "medium"
                    }
                ],
                temperature=0.3,
                max_output_tokens=2048
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            search_content = response.output.content if hasattr(response, 'output') else ""
            
            # Citations ì¶”ì¶œ
            citations = []
            if hasattr(response, 'output') and hasattr(response.output, 'annotations'):
                for annotation in response.output.annotations:
                    if hasattr(annotation, 'url') and hasattr(annotation, 'title'):
                        citations.append({
                            'title': getattr(annotation, 'title', 'Web Result'),
                            'content': search_content[annotation.start_index:annotation.end_index] if hasattr(annotation, 'start_index') else search_content[:200] + "...",
                            'url': annotation.url
                        })
            
            # Citationsê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±
            if not citations:
                citations = [{
                    'title': f'Web Search: {query}',
                    'content': search_content[:500] + "..." if len(search_content) > 500 else search_content,
                    'url': 'https://web-search-results'
                }]
            
            return {
                'search_results': citations[:max_results],
                'query': query,
                'total_found': len(citations),
                'source': 'openai_web_search'
            }
                        
        except Exception as e:
            logger.warning(f"OpenAI web search failed: {str(e)}")
            # Fallback: ê¸°ì¡´ DuckDuckGo ë°©ì‹ ìœ ì§€
            try:
                async with aiohttp.ClientSession() as session:
                    url = f"https://api.duckduckgo.com/"
                    params = {
                        'q': query,
                        'format': 'json',
                        'no_html': '1',
                        'skip_disambig': '1'
                    }
                    
                    async with session.get(url, params=params) as response:
                        if response.status == 200:
                            data = await response.json()
                            
                            # ê´€ë ¨ ì£¼ì œë“¤ ì¶”ì¶œ
                            related_topics = data.get('RelatedTopics', [])[:max_results]
                            results = []
                            
                            for topic in related_topics:
                                if isinstance(topic, dict) and 'Text' in topic:
                                    results.append({
                                        'title': topic.get('FirstURL', '').split('/')[-1],
                                        'content': topic.get('Text', ''),
                                        'url': topic.get('FirstURL', '')
                                    })
                            
                            # Abstractê°€ ìˆë‹¤ë©´ ì¶”ê°€
                            if data.get('Abstract'):
                                results.insert(0, {
                                    'title': 'Main Topic',
                                    'content': data.get('Abstract'),
                                    'url': data.get('AbstractURL', '')
                                })
                            
                            return {
                                'search_results': results,
                                'query': query,
                                'total_found': len(results),
                                'source': 'duckduckgo_fallback'
                            }
                        else:
                            return {
                                'search_results': [],
                                'error': f'Search API returned status {response.status}',
                                'source': 'error'
                            }
                            
            except Exception as fallback_error:
                logger.warning(f"Fallback search also failed: {str(fallback_error)}")
                # ìµœì¢… fallback: ëª¨ì˜ ê²€ìƒ‰ ê²°ê³¼
                return {
                    'search_results': [
                        {
                            'title': f'ê´€ë ¨ ì •ë³´: {query}',
                            'content': f'{query}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ ì—°êµ¬ ê²°ê³¼ë“¤. {search_type} íƒ€ì…ì˜ ê²€ìƒ‰ì„ í†µí•´ ìˆ˜ì§‘ëœ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤.',
                            'url': 'https://example.com'
                        }
                    ],
                    'query': query,
                    'total_found': 1,
                    'source': 'mock_fallback',
                    'note': 'Mock result due to API limitations'
                }
    
    async def _vector_knowledge_search(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ë²¡í„° ì§€ì‹ ê²€ìƒ‰ (OpenAI ì„ë² ë”© í™œìš©)"""
        query = args.get('query', '')
        domain = args.get('domain', 'philosophy')
        max_results = args.get('max_results', 3)
        
        self.performance_stats['vector_searches'] += 1
        
        try:
            # OpenAI ì„ë² ë”©ì„ í™œìš©í•œ ì‹¤ì œ ì‹œë§¨í‹± ê²€ìƒ‰
            query_embedding = self.llm_manager.client.embeddings.create(
                model="text-embedding-3-small",
                input=query
            ).data[0].embedding
            
            # ë„ë©”ì¸ë³„ ì§€ì‹ ë² ì´ìŠ¤ (ì‹¤ì œë¡œëŠ” ë²¡í„° DBì— ì €ì¥ëœ ì„ë² ë”©ê³¼ ë¹„êµ)
            knowledge_base = {
                'philosophy': [
                    {
                        'content': f'{query}ì— ëŒ€í•œ ì² í•™ì  ê´€ì : ì¡´ì¬ë¡ ì , ì¸ì‹ë¡ ì , ìœ¤ë¦¬ì  ì¸¡ë©´ì—ì„œì˜ ê¹Šì´ ìˆëŠ” ë¶„ì„. ê³ ëŒ€ ê·¸ë¦¬ìŠ¤ ì² í•™ìë“¤ë¶€í„° í˜„ëŒ€ ë¶„ì„ì² í•™ê¹Œì§€ì˜ ë‹¤ì–‘í•œ ê´€ì ì„ ì¢…í•©í•˜ì—¬ ê²€í† í•´ë³´ë©´...',
                        'source': 'Stanford Encyclopedia of Philosophy',
                        'similarity': 0.92
                    },
                    {
                        'content': f'{query}ì™€ ê´€ë ¨ëœ ì£¼ìš” ì² í•™ìë“¤ì˜ ê²¬í•´: í”Œë¼í†¤ì˜ ì´ë°ì•„ë¡ , ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤ì˜ ì‹¤ì²´ë¡ , ì¹¸íŠ¸ì˜ ì„ í—˜ì² í•™, ë‹ˆì²´ì˜ ìƒì² í•™ ë“± ê°ê¸° ë‹¤ë¥¸ ì² í•™ì  ì „í†µì—ì„œ {query}ë¥¼ ì–´ë–»ê²Œ í•´ì„í–ˆëŠ”ì§€...',
                        'source': 'History of Philosophy Archive',
                        'similarity': 0.89
                    },
                    {
                        'content': f'{query}ì˜ ì² í•™ì‚¬ì  ë§¥ë½ê³¼ í˜„ëŒ€ì  í•´ì„: 20ì„¸ê¸° ì–¸ì–´ì² í•™ê³¼ ë¶„ì„ì² í•™ì˜ ê´€ì ì—ì„œ {query}ê°€ ì–´ë–»ê²Œ ì¬í•´ì„ë˜ê³  ìˆìœ¼ë©°, í˜„ëŒ€ ì¸ì§€ê³¼í•™ê³¼ ì² í•™ì˜ ë§Œë‚¨ì—ì„œ ìƒˆë¡­ê²Œ ë¶€ê°ë˜ëŠ” ìŸì ë“¤...',
                        'source': 'Contemporary Philosophy Review',
                        'similarity': 0.86
                    }
                ],
                'ethics': [
                    {
                        'content': f'{query}ì˜ ìœ¤ë¦¬ì  ë”œë ˆë§ˆì™€ ë„ë•ì  íŒë‹¨ ê¸°ì¤€: ê²°ê³¼ì£¼ì˜ ìœ¤ë¦¬í•™ì—ì„œëŠ” í–‰ìœ„ì˜ ê²°ê³¼ë¥¼ ì¤‘ì‹œí•˜ëŠ” ë°˜ë©´, ì˜ë¬´ë¡ ì  ìœ¤ë¦¬í•™ì—ì„œëŠ” í–‰ìœ„ ìì²´ì˜ ë„ë•ì„±ì— ì´ˆì ì„ ë§ì¶˜ë‹¤. {query}ì— ëŒ€í•œ ìœ¤ë¦¬ì  í‰ê°€ëŠ”...',
                        'source': 'Journal of Applied Ethics',
                        'similarity': 0.91
                    },
                    {
                        'content': f'{query}ì— ëŒ€í•œ ê²°ê³¼ì£¼ì˜ vs ì˜ë¬´ë¡ ì  ì ‘ê·¼: ë²¤ë‹´ê³¼ ë°€ì˜ ê³µë¦¬ì£¼ì˜ì  ê´€ì ì—ì„œ {query}ëŠ” ìµœëŒ€ í–‰ë³µì˜ ì›ë¦¬ì— ë”°ë¼ í‰ê°€ë˜ë©°, ì¹¸íŠ¸ì˜ ì •ì–¸ëª…ë ¹ ê´€ì ì—ì„œëŠ” ë³´í¸ì  ë„ë•ë²•ì¹™ì˜ ê°€ëŠ¥ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ...',
                        'source': 'Ethics and Moral Philosophy',
                        'similarity': 0.88
                    },
                    {
                        'content': f'{query}ì˜ ì‚¬íšŒì  ì˜í–¥ê³¼ ìœ¤ë¦¬ì  í•¨ì˜: ê°œì¸ì˜ ììœ ì™€ ì‚¬íšŒì  ì±…ì„ ì‚¬ì´ì˜ ê· í˜•, ì •ì˜ë¡ ì  ê´€ì ì—ì„œì˜ ê³µì •ì„± ë¬¸ì œ, ê·¸ë¦¬ê³  ë¯¸ë˜ ì„¸ëŒ€ì— ëŒ€í•œ ìœ¤ë¦¬ì  ì˜ë¬´ê¹Œì§€ ê³ ë ¤í•œ ì¢…í•©ì  ë¶„ì„...',
                        'source': 'Social Ethics Quarterly',
                        'similarity': 0.85
                    }
                ],
                'politics': [
                    {
                        'content': f'{query}ì˜ ì •ì¹˜ì² í•™ì  í•¨ì˜ì™€ ê¶Œë ¥ êµ¬ì¡°: í™‰ìŠ¤ì˜ ë¦¬ë°”ì´ì–´ë˜ì—ì„œ ì‹œì‘ëœ ì‚¬íšŒê³„ì•½ë¡ ì  ê´€ì ê³¼ ë¡œí¬ì˜ ììœ ì£¼ì˜ì  ì •ì¹˜ì‚¬ìƒ, ê·¸ë¦¬ê³  ë£¨ì†Œì˜ ì¼ë°˜ì˜ì§€ ê°œë…ì„ í†µí•´ {query}ë¥¼ ì •ì¹˜ì ìœ¼ë¡œ í•´ì„í•˜ë©´...',
                        'source': 'Political Philosophy Today',
                        'similarity': 0.90
                    },
                    {
                        'content': f'{query}ì— ëŒ€í•œ ììœ ì£¼ì˜ vs ê³µë™ì²´ì£¼ì˜ ê´€ì : ë¡¤ìŠ¤ì˜ ì •ì˜ë¡ ê³¼ ë…¸ì§ì˜ ììœ ì§€ìƒì£¼ì˜, ê·¸ë¦¬ê³  ìƒŒë¸ê³¼ ë§¥í‚¨íƒ€ì´ì–´ì˜ ê³µë™ì²´ì£¼ì˜ì  ë¹„íŒì„ í†µí•´ {query}ê°€ ì •ì¹˜ê³µë™ì²´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„...',
                        'source': 'Journal of Political Theory',
                        'similarity': 0.87
                    },
                    {
                        'content': f'{query}ì˜ ë¯¼ì£¼ì£¼ì˜ì  ê°€ì¹˜ì™€ ì‚¬íšŒ ì •ì˜: í•˜ë²„ë§ˆìŠ¤ì˜ ì˜ì‚¬ì†Œí†µì  í–‰ìœ„ì´ë¡ ê³¼ deliberative democracy ê´€ì ì—ì„œ {query}ê°€ ë¯¼ì£¼ì  ì˜ì‚¬ê²°ì • ê³¼ì •ì— ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°–ëŠ”ì§€...',
                        'source': 'Democratic Theory Review',
                        'similarity': 0.84
                    }
                ],
                'science': [
                    {
                        'content': f'{query}ì— ëŒ€í•œ ê³¼í•™ì  ì ‘ê·¼: ì‹¤ì¦ì£¼ì˜ì  ë°©ë²•ë¡ ê³¼ ì¹¼ í¬í¼ì˜ ë°˜ì¦ì£¼ì˜, í† ë§ˆìŠ¤ ì¿¤ì˜ íŒ¨ëŸ¬ë‹¤ì„ ì´ë¡ ì„ í†µí•´ {query}ë¥¼ ê³¼í•™ì² í•™ì ìœ¼ë¡œ ë¶„ì„í•˜ë©´, ê³¼í•™ì  ì§€ì‹ì˜ ê°ê´€ì„±ê³¼ ìƒëŒ€ì„± ë¬¸ì œê°€...',
                        'source': 'Philosophy of Science Journal',
                        'similarity': 0.89
                    },
                    {
                        'content': f'{query}ì™€ ê´€ë ¨ëœ ìµœì‹  ê³¼í•™ ì—°êµ¬: ì‹ ê²½ê³¼í•™, ì¸ì§€ê³¼í•™, ì§„í™”ìƒë¬¼í•™ ë“±ì˜ ìµœì‹  ì—°êµ¬ ì„±ê³¼ë“¤ì´ {query}ì— ëŒ€í•œ ìš°ë¦¬ì˜ ì´í•´ë¥¼ ì–´ë–»ê²Œ í™•ì¥ì‹œí‚¤ê³  ìˆëŠ”ì§€, ê·¸ë¦¬ê³  ì´ê²ƒì´ ì² í•™ì  ë…¼ì˜ì—...',
                        'source': 'Scientific Research Updates',
                        'similarity': 0.86
                    }
                ]
            }
            
            results = knowledge_base.get(domain, knowledge_base['philosophy'])[:max_results]
            
            # ì„ë² ë”© ìœ ì‚¬ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²°ê³¼ ì •ë ¬ (ì‹¤ì œë¡œëŠ” ë²¡í„° DBì—ì„œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°)
            results.sort(key=lambda x: x.get('similarity', 0), reverse=True)
            
            return {
                'knowledge_results': [
                    {
                        'content': result['content'],
                        'relevance_score': result.get('similarity', 0.8),
                        'domain': domain,
                        'source': result.get('source', 'Knowledge Base'),
                        'embedding_model': 'text-embedding-3-small'
                    } for result in results
                ],
                'query': query,
                'domain': domain,
                'embedding_dimensions': len(query_embedding),
                'search_method': 'openai_embeddings'
            }
            
        except Exception as e:
            logger.warning(f"OpenAI embeddings search failed: {str(e)}")
            # Fallback: ê¸°ì¡´ ê°„ë‹¨í•œ ë°©ì‹
            knowledge_base = {
                'philosophy': [
                    f'{query}ì— ëŒ€í•œ ì² í•™ì  ê´€ì : ì¡´ì¬ë¡ ì , ì¸ì‹ë¡ ì , ìœ¤ë¦¬ì  ì¸¡ë©´ì—ì„œì˜ ë¶„ì„...',
                    f'{query}ì™€ ê´€ë ¨ëœ ì£¼ìš” ì² í•™ìë“¤ì˜ ê²¬í•´ì™€ ë…¼ìŸì ë“¤...',
                    f'{query}ì˜ ì² í•™ì‚¬ì  ë§¥ë½ê³¼ í˜„ëŒ€ì  í•´ì„...'
                ],
                'ethics': [
                    f'{query}ì˜ ìœ¤ë¦¬ì  ë”œë ˆë§ˆì™€ ë„ë•ì  íŒë‹¨ ê¸°ì¤€...',
                    f'{query}ì— ëŒ€í•œ ê²°ê³¼ì£¼ì˜ vs ì˜ë¬´ë¡ ì  ì ‘ê·¼...',
                    f'{query}ì˜ ì‚¬íšŒì  ì˜í–¥ê³¼ ìœ¤ë¦¬ì  í•¨ì˜...'
                ]
            }
            
            results = knowledge_base.get(domain, knowledge_base.get('philosophy', []))[:max_results]
            
            return {
                'knowledge_results': [
                    {
                        'content': result,
                        'relevance_score': 0.75 - i * 0.05,
                        'domain': domain,
                        'source': 'Fallback Knowledge Base'
                    } for i, result in enumerate(results)
                ],
                'query': query,
                'domain': domain,
                'search_method': 'fallback_simple'
            }
    
    async def _philosopher_wisdom_retrieval(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì² í•™ì ì§€í˜œ ê²€ìƒ‰"""
        philosopher = args.get('philosopher', self.philosopher_data.get('name', ''))
        topic = args.get('topic', '')
        quote_style = args.get('quote_style', 'interpretation')
        
        # ì² í•™ìë³„ ì €ì‘ê³¼ ì‚¬ìƒ ë°ì´í„°ë² ì´ìŠ¤ (ì‹¤ì œë¡œëŠ” ì „ë¬¸ DBì—ì„œ ê²€ìƒ‰)
        philosopher_quotes = {
            'Nietzsche': [
                f"'{topic}'ì— ëŒ€í•œ ë‹ˆì²´ì˜ ê´€ì : 'ì‹ ì€ ì£½ì—ˆë‹¤'ëŠ” ì„ ì–¸ê³¼ í•¨ê»˜ ìƒˆë¡œìš´ ê°€ì¹˜ ì°½ì¡°ì˜ í•„ìš”ì„±...",
                f"ìœ„ë²„ë©˜ì‰¬ ê°œë…ì„ í†µí•œ '{topic}'ì˜ ì¬í•´ì„: ë„ë•ì  ì „ë³µê³¼ ì˜ì§€ì˜ í˜...",
                f"'{topic}'ì—ì„œ ë“œëŸ¬ë‚˜ëŠ” ë…¸ì˜ˆ ë„ë• vs ì£¼ì¸ ë„ë•ì˜ ëŒ€ë¦½..."
            ],
            'Kant': [
                f"ì •ì–¸ëª…ë ¹ì„ í†µí•œ '{topic}'ì˜ ë„ë•ì  ë¶„ì„: ë³´í¸ë²•ì¹™ì˜ ì›ë¦¬...",
                f"'{topic}'ì— ëŒ€í•œ ì´ì„±ì˜ í•œê³„ì™€ ì‹¤ì²œì´ì„±ì˜ ìš”ì²­...",
                f"'{topic}'ì˜ ëª©ì  ìì²´ë¡œì„œì˜ ì¸ê°„ ì¡´ì¬..."
            ],
            'Aristotle': [
                f"'{topic}'ì— ëŒ€í•œ ì¤‘ìš©ì˜ ë•ëª©ê³¼ ì‹¤ì²œì  ì§€í˜œ...",
                f"'{topic}'ì˜ í–‰ë³µ(ì—ìš°ë‹¤ì´ëª¨ë‹ˆì•„) ì¶”êµ¬ì™€ ë•ì˜ ì‹¤í˜„...",
                f"'{topic}'ì—ì„œ ë³´ëŠ” ì •ì˜ì™€ ì‚¬íšŒì  ì¡°í™”..."
            ]
        }
        
        quotes = philosopher_quotes.get(philosopher, [f"'{topic}'ì— ëŒ€í•œ {philosopher}ì˜ ì² í•™ì  í†µì°°..."])
        
        return {
            'philosopher_wisdom': quotes,
            'philosopher': philosopher,
            'topic': topic,
            'style': quote_style
        }
    
    async def _generate_enhanced_argument(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ê°•í™”ëœ ë…¼ì¦ ìƒì„±"""
        core_position = args.get('core_position', '')
        evidence = args.get('evidence', [])
        philosophical_framework = args.get('philosophical_framework', '')
        
        # ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë…¼ì¦ ìƒì„±
        enhanced_argument = f"""
ã€{self.philosopher_data.get('name', 'Philosopher')}ì˜ ì…ë¡ ã€‘

"{self.philosopher_data.get('quote', '')}"

ã€í•µì‹¬ ì…ì¥ã€‘
{core_position}

ã€ë…¼ì¦ êµ¬ì¡°ã€‘
"""
        
        for i, evidence_piece in enumerate(evidence[:3], 1):
            enhanced_argument += f"\n{i}. {evidence_piece}"
        
        enhanced_argument += f"""

ã€ì² í•™ì  í‹€ã€‘
{philosophical_framework}

ã€ê²°ë¡ ã€‘
ë”°ë¼ì„œ ì €ëŠ” {core_position}ë¥¼ í™•ì‹ ì„ ê°€ì§€ê³  ì£¼ì¥í•©ë‹ˆë‹¤.
"""
        
        return {
            'enhanced_argument': enhanced_argument,
            'evidence_count': len(evidence),
            'framework': philosophical_framework
        }
    
    def _update_performance_stats(self, execution_time: float, llm_calls: int):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.performance_stats['llm_calls'] += llm_calls
        self.performance_stats['total_time'] += execution_time
        self.performance_stats['avg_response_time'] = (
            self.performance_stats['total_time'] / self.performance_stats['llm_calls']
            if self.performance_stats['llm_calls'] > 0 else 0
        )
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        return {
            **self.performance_stats,
            'efficiency_score': self._calculate_efficiency_score()
        }
    
    def _calculate_efficiency_score(self) -> float:
        """íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        total_operations = (
            self.performance_stats['llm_calls'] + 
            self.performance_stats['web_searches'] + 
            self.performance_stats['vector_searches']
        )
        
        if total_operations == 0:
            return 0.0
            
        # ì‹œê°„ë‹¹ ì‘ì—… ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íš¨ìœ¨ì„± ê³„ì‚°
        efficiency = total_operations / (self.performance_stats['total_time'] / 60)  # ë¶„ë‹¹ ì‘ì—… ìˆ˜
        return min(efficiency / 10, 1.0)  # 0-1 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™” 