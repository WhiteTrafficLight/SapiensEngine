#!/usr/bin/env python3
"""
Quick Test for Fast Debate Generation

ì‹¤ì œ debate_topics.jsonì˜ ì½˜í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import time
from pathlib import Path
import sys

# Add project root to Python path
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from src.new.models.debate_models import FastDebateRequest, ContextType
from src.new.services.openai_service import OpenAIDebateService

def load_debate_topics():
    """debate_topics.json ë¡œë“œ"""
    topics_path = Path("agoramind/data/debate_topics.json")
    with open(topics_path, 'r', encoding='utf-8') as f:
        return json.load(f)

async def quick_demo(topic_data=None):
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ - ì‹¤ì œ ì½˜í…ìŠ¤íŠ¸ ì‚¬ìš©"""
    
    debate_topics = load_debate_topics()
    
    if topic_data is None:
        # ê¸°ë³¸ê°’: AI ìœ„í˜‘ vs í•´ë°© í† í”½ (URL ì½˜í…ìŠ¤íŠ¸ í¬í•¨)
        topic_data = debate_topics['categories']['science_and_technology']['topics'][0]
    
    print(f"ğŸš€ Testing: {topic_data['title']}")
    print(f"ğŸ“ Context Type: {topic_data['context']['type']}")
    print(f"ğŸ“„ Context Content: {topic_data['context']['content'][:100]}...")
    
    # ContextType ì„¤ì •
    context_type = ContextType.URL if topic_data['context']['type'] == 'url' else ContextType.TEXT
    
    # FastDebateRequest ìƒì„± - ì •í™•í•œ ì½˜í…ìŠ¤íŠ¸ ì‚¬ìš©
    request = FastDebateRequest(
        room_id=f"test_{topic_data['title'][:20].replace(' ', '_').lower()}",
        title=topic_data['title'],
        context=topic_data['context']['content'],
        context_type=context_type,
        pro_npcs=topic_data['pro_philosophers'],
        con_npcs=topic_data['con_philosophers'],
        moderator_style=str(topic_data['moderator_style'])
    )
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° ìƒì„±
    service = OpenAIDebateService(use_fine_tuned=False)
    
    start_time = time.time()
    package = await service.generate_complete_debate_package(request)
    generation_time = time.time() - start_time
    
    # ì „ì²´ ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… Generation completed in {generation_time:.2f} seconds")
    print(f"ğŸ“ Opening Message Length: {len(package.opening_message)} characters")
    print(f"\nğŸ­ FULL OPENING MESSAGE:")
    print("=" * 80)
    print(package.opening_message)
    print("=" * 80)
    
    print(f"\nğŸ“Š Stance Statements:")
    print(f"PRO: {package.stance_statements.pro}")
    print(f"CON: {package.stance_statements.con}")
    
    if package.context_summary:
        print(f"\nğŸ“„ Context Summary:")
        print(f"Summary: {package.context_summary.summary}")
        print(f"Key Points: {package.context_summary.key_points}")
    
    return package.opening_message, generation_time

async def test_multiple_topics():
    """ì—¬ëŸ¬ í† í”½ í…ŒìŠ¤íŠ¸ - URLê³¼ TEXT ì½˜í…ìŠ¤íŠ¸ ëª¨ë‘ í¬í•¨"""
    
    debate_topics = load_debate_topics()
    
    test_topics = [
        # URL ì½˜í…ìŠ¤íŠ¸ í† í”½
        debate_topics['categories']['science_and_technology']['topics'][0],  # AI threat - URL
        debate_topics['categories']['global_and_current_affairs']['topics'][0],  # Climate refugees - URL
        
        # TEXT ì½˜í…ìŠ¤íŠ¸ í† í”½  
        debate_topics['categories']['dilemma_challenge']['topics'][0],  # Puppy dilemma - TEXT
        debate_topics['categories']['dilemma_challenge']['topics'][2],  # Memory erasure - TEXT
        
        # ë¹ˆ ì½˜í…ìŠ¤íŠ¸ í† í”½
        debate_topics['categories']['self_and_philosophy']['topics'][0],  # Absolute freedom - empty
    ]
    
    results = []
    
    for i, topic in enumerate(test_topics, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ§ª TEST {i}/{len(test_topics)}")
        print(f"{'='*60}")
        
        opening, time_taken = await quick_demo(topic)
        
        results.append({
            'topic': topic['title'],
            'context_type': topic['context']['type'],
            'has_context': bool(topic['context']['content'].strip()),
            'time': time_taken,
            'length': len(opening),
            'opening': opening
        })
        
        print(f"\nâ±ï¸  Time: {time_taken:.2f}s")
        print(f"ğŸ“ Length: {len(opening)} chars")
        print(f"ğŸ”— Context Type: {topic['context']['type']}")
        print(f"ğŸ“ Has Content: {bool(topic['context']['content'].strip())}")
    
    # ìµœì¢… ìš”ì•½
    print(f"\n{'='*60}")
    print("ğŸ“Š FINAL SUMMARY")
    print(f"{'='*60}")
    
    avg_time = sum(r['time'] for r in results) / len(results)
    avg_length = sum(r['length'] for r in results) / len(results)
    
    print(f"Average Generation Time: {avg_time:.2f}s")
    print(f"Average Opening Length: {avg_length:.0f} chars")
    
    # ì½˜í…ìŠ¤íŠ¸ íƒ€ì…ë³„ ë¶„ì„
    url_results = [r for r in results if r['context_type'] == 'url']
    text_results = [r for r in results if r['context_type'] == 'text']
    empty_results = [r for r in results if not r['has_context']]
    
    if url_results:
        url_avg = sum(r['time'] for r in url_results) / len(url_results)
        print(f"URL Context Average: {url_avg:.2f}s")
    
    if text_results:
        text_avg = sum(r['time'] for r in text_results) / len(text_results)
        print(f"Text Context Average: {text_avg:.2f}s")
    
    if empty_results:
        empty_avg = sum(r['time'] for r in empty_results) / len(empty_results)
        print(f"No Context Average: {empty_avg:.2f}s")
    
    return results

if __name__ == "__main__":
    print("ğŸš€ Starting Quick Debate Generation Test")
    print("Using actual contexts from debate_topics.json")
    
    # ë‹¨ì¼ í…ŒìŠ¤íŠ¸
    # asyncio.run(quick_demo())
    
    # ë‹¤ì¤‘ í…ŒìŠ¤íŠ¸ (URL, TEXT, ë¹ˆ ì½˜í…ìŠ¤íŠ¸ ëª¨ë‘ í¬í•¨)
    asyncio.run(test_multiple_topics()) 