"""
OpenAI Integration Service

Function Callingì„ í™œìš©í•˜ì—¬ ë‹¨ì¼ API í˜¸ì¶œë¡œ 
í† ë¡ ì— í•„ìš”í•œ ëª¨ë“  ìš”ì†Œë¥¼ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤
"""

import asyncio
import json
import time
import logging
from typing import Dict, Any, Optional, List
import openai
from openai import AsyncOpenAI
from pathlib import Path
import sys

# Add project root to Python path  
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from src.new.models.debate_models import (
    FastDebateRequest, DebatePackage, StanceStatements, 
    ContextSummary, PhilosopherProfile, ModeratorStyle
)

logger = logging.getLogger(__name__)

class OpenAIDebateService:
    """OpenAI APIë¥¼ í™œìš©í•œ ê³ ì† í† ë¡  ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: Optional[str] = None, use_fine_tuned: bool = False):
        self.client = AsyncOpenAI(api_key=api_key)
        self.use_fine_tuned = use_fine_tuned
        self.fine_tuned_model = "ft:gpt-4o-mini-2024-07-18:your-org::your-model-id"  # ğŸ”¥ íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš©ì‹œ
        self.base_model = "gpt-4o"
        
        # ëª¨ë”ë ˆì´í„° ìŠ¤íƒ€ì¼ ë§¤í•‘
        self.moderator_styles = {
            "0": {"name": "Jamie the Host", "personality": "casual, friendly, young"},
            "1": {"name": "Dr. Lee", "personality": "polite, academic, professional"},  
            "2": {"name": "Zuri Show", "personality": "energetic, entertaining, YouTuber"},
            "3": {"name": "Elias of the End", "personality": "serious, weighty, formal"},
            "4": {"name": "Miss Hana", "personality": "bright, educational, cheerful"}
        }
    
    async def generate_complete_debate_package(self, request: FastDebateRequest) -> DebatePackage:
        """ğŸš€ ë‹¨ì¼ API í˜¸ì¶œë¡œ ì™„ì „í•œ í† ë¡  íŒ¨í‚¤ì§€ ìƒì„±"""
        
        start_time = time.time()
        
        # Function Callingì„ ìœ„í•œ ë„êµ¬ ì •ì˜
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "create_complete_debate_package",
                    "description": "Create a complete debate package with stance statements, context summary, and opening message",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "stance_statements": {
                                "type": "object",
                                "properties": {
                                    "pro": {"type": "string", "description": "Pro stance statement"},
                                    "con": {"type": "string", "description": "Con stance statement"}
                                },
                                "required": ["pro", "con"]
                            },
                            "context_summary": {
                                "type": "object", 
                                "properties": {
                                    "summary": {"type": "string", "description": "Main content summary"},
                                    "key_points": {"type": "array", "items": {"type": "string"}},
                                    "relevant_quotes": {"type": "array", "items": {"type": "string"}}
                                }
                            },
                            "opening_message": {
                                "type": "string",
                                "description": "Complete moderator opening message"
                            }
                        },
                        "required": ["stance_statements", "opening_message"]
                    }
                }
            }
        ]
        
        # ëª¨ë”ë ˆì´í„° ìŠ¤íƒ€ì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        moderator_info = self.moderator_styles.get(request.moderator_style.value, self.moderator_styles["0"])
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (íŒŒì¸íŠœë‹ vs ê¸°ë³¸ ëª¨ë¸)
        if self.use_fine_tuned:
            system_prompt = self._get_fine_tuned_system_prompt(moderator_info)
        else:
            system_prompt = self._get_base_system_prompt(moderator_info)
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        user_prompt = self._build_user_prompt(request)
        
        try:
            # ğŸ”¥ ë‹¨ì¼ API í˜¸ì¶œë¡œ ëª¨ë“  ê²ƒ ìƒì„±
            model_to_use = self.fine_tuned_model if self.use_fine_tuned else self.base_model
            
            response = await self.client.chat.completions.create(
                model=model_to_use,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                tools=tools,
                tool_choice={"type": "function", "function": {"name": "create_complete_debate_package"}},
                max_tokens=4000,
                temperature=0.7
            )
            
            api_time = time.time() - start_time
            
            # Function Call ê²°ê³¼ íŒŒì‹±
            debate_package = self._parse_function_call_response(response, api_time)
            
            logger.info(f"âœ… Complete debate package generated in {api_time:.2f}s")
            return debate_package
            
        except Exception as e:
            logger.error(f"âŒ Error generating debate package: {str(e)}")
            # í´ë°±: ê¸°ë³¸ íŒ¨í‚¤ì§€ ë°˜í™˜
            return self._create_fallback_package(request, time.time() - start_time)
    
    def _get_base_system_prompt(self, moderator_info: Dict[str, str]) -> str:
        """ê¸°ë³¸ ëª¨ë¸ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return f"""You are {moderator_info['name']}, a debate moderator with a {moderator_info['personality']} style.

Your task is to create a COMPLETE debate package including:
1. Balanced pro/con stance statements for the topic
2. Context summary (if context provided)  
3. Complete opening message that introduces the debate professionally
4. Brief philosopher profiles for participants

Requirements:
- Generate balanced, fair stance statements
- Create engaging, comprehensive opening message
- Match your personality style: {moderator_info['personality']}
- Write in the same language as the debate topic
- Ensure opening message is complete and doesn't cut off mid-sentence

Use the create_complete_debate_package function to return structured results."""

    def _get_fine_tuned_system_prompt(self, moderator_info: Dict[str, str]) -> str:
        """íŒŒì¸íŠœë‹ ëª¨ë¸ìš© ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸"""
        return f"""Generate complete debate package as {moderator_info['name']} ({moderator_info['personality']})."""
    
    def _build_user_prompt(self, request: FastDebateRequest) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # ì°¸ê°€ì ì •ë³´
        pro_participants = ", ".join(request.pro_npcs)
        con_participants = ", ".join(request.con_npcs)
        
        # ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬
        context_section = ""
        if request.context.strip():
            if request.context_type.value == "url":
                # URLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                extracted_text = self._extract_text_from_url(request.context)
                context_section = f"\nContext (extracted from URL): {extracted_text}"
            else:
                context_section = f"\nContext: {request.context}"
        
        return f"""Create a complete debate package for this topic:

TOPIC: {request.title}
{context_section}

PARTICIPANTS:
- PRO side: {pro_participants}
- CON side: {con_participants}

REQUIREMENTS:
1. Create balanced pro/con stance statements
2. {f"Summarize the provided context" if request.context.strip() else "No context to summarize"}
3. Generate complete opening message that:
   - Introduces the topic and its importance
   - Presents both sides fairly
   - Introduces all participants
   - Sets expectations for respectful debate
   - Calls on PRO side to start first

Language: Write everything in the SAME LANGUAGE as the topic title.
Style: Match your personality and speaking style consistently.

Use the create_complete_debate_package function to provide structured output."""
    
    def _extract_text_from_url(self, url: str) -> str:
        """URLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ ë°©ì‹)"""
        try:
            import requests
            from bs4 import BeautifulSoup
            import re
            
            # User-Agent í—¤ë” ì¶”ê°€í•˜ì—¬ 403 Forbidden ì—ëŸ¬ ë°©ì§€
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
            
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼ íƒœê·¸ ì œê±°
            for script in soup(["script", "style"]):
                script.extract()
            
            text = soup.get_text(separator='\n')
            
            # ì—¬ëŸ¬ ì¤„ë°”ê¿ˆ ì •ë¦¬
            text = re.sub(r'\n{3,}', '\n\n', text)
            text = re.sub(r'\s{3,}', ' ', text)
            
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©)
            max_length = 8000  # ì•½ 8000ìë¡œ ì œí•œ
            if len(text) > max_length:
                text = text[:max_length] + "... (í…ìŠ¤íŠ¸ê°€ ê¸¸ì–´ì„œ ì¼ë¶€ë§Œ í‘œì‹œë¨)"
            
            logger.info(f"URL processing completed: {len(text)} characters extracted from {url}")
            return text
            
        except ImportError:
            logger.error("requests or BeautifulSoup not available for URL processing")
            return f"URL ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (URL: {url})"
        except Exception as e:
            logger.error(f"URL processing failed for {url}: {str(e)}")
            return f"URL ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)} (URL: {url})"
    
    def _parse_function_call_response(self, response, api_time: float) -> DebatePackage:
        """Function Call ì‘ë‹µ íŒŒì‹±"""
        
        try:
            # Function call ê²°ê³¼ ì¶”ì¶œ
            function_call = response.choices[0].message.tool_calls[0]
            function_args = json.loads(function_call.function.arguments)
            
            # DebatePackage êµ¬ì„±
            stance_statements = StanceStatements(**function_args["stance_statements"])
            
            context_summary = None
            if "context_summary" in function_args and function_args["context_summary"]:
                context_summary = ContextSummary(**function_args["context_summary"])
            
            return DebatePackage(
                stance_statements=stance_statements,
                context_summary=context_summary,
                opening_message=function_args["opening_message"],
                generation_time=api_time,
                system_version="v2_fast"
            )
            
        except Exception as e:
            logger.error(f"âŒ Error parsing function call response: {str(e)}")
            # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
            return self._extract_from_text_response(response, api_time)
    
    def _extract_from_text_response(self, response, api_time: float) -> DebatePackage:
        """í…ìŠ¤íŠ¸ ì‘ë‹µì—ì„œ ì •ë³´ ì¶”ì¶œ (í´ë°±)"""
        
        text_response = response.choices[0].message.content
        
        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì¶”ì¶œ (ê°œì„  ê°€ëŠ¥)
        stance_statements = StanceStatements(
            pro="Supporting this topic has merit and deserves consideration.",
            con="This topic raises concerns that need careful examination."
        )
        
        return DebatePackage(
            stance_statements=stance_statements,
            context_summary=None,
            opening_message=text_response[:1000] if text_response else "Welcome to today's debate.",
            generation_time=api_time,
            system_version="v2_fast_fallback"
        )
    
    def _create_fallback_package(self, request: FastDebateRequest, generation_time: float) -> DebatePackage:
        """API ì‹¤íŒ¨ì‹œ ê¸°ë³¸ íŒ¨í‚¤ì§€ ìƒì„±"""
        
        stance_statements = StanceStatements(
            pro=f"The position supporting '{request.title}' presents compelling arguments worth considering.",
            con=f"The position opposing '{request.title}' raises important concerns that must be addressed."
        )
        
        opening_message = f"""Welcome to today's debate on '{request.title}'.
        
We have distinguished participants representing both sides of this important issue.
Today's discussion will help us explore different perspectives and deepen our understanding.

Let's begin with the pro side presenting their opening arguments."""
        
        return DebatePackage(
            stance_statements=stance_statements,
            context_summary=None,
            opening_message=opening_message,
            generation_time=generation_time,
            system_version="v2_fast_fallback"
        )

    async def test_model_performance(self, test_cases: List[FastDebateRequest]) -> Dict[str, Any]:
        """ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        
        results = []
        total_start = time.time()
        
        for i, request in enumerate(test_cases):
            start_time = time.time()
            
            try:
                package = await self.generate_complete_debate_package(request)
                generation_time = time.time() - start_time
                
                results.append({
                    "test_case": i + 1,
                    "topic": request.title,
                    "generation_time": generation_time,
                    "success": True,
                    "opening_length": len(package.opening_message),
                    "has_context_summary": package.context_summary is not None
                })
                
            except Exception as e:
                results.append({
                    "test_case": i + 1,
                    "topic": request.title,
                    "generation_time": time.time() - start_time,
                    "success": False,
                    "error": str(e)
                })
        
        total_time = time.time() - total_start
        
        return {
            "total_time": total_time,
            "average_time": total_time / len(test_cases),
            "success_rate": sum(1 for r in results if r["success"]) / len(results),
            "results": results
        } 