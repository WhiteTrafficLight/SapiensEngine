import unittest
import sys
import time
import os
import logging
from pathlib import Path
from typing import Dict, Any, List
import re

# ë¡œê¹… ì„¤ì • ì¶”ê°€
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

# Add the src directory to the path for imports
current_dir = Path(__file__).parent.absolute()
src_path = current_dir.parent.parent / "src"
sys.path.insert(0, str(src_path))

# Add the project root to path as well for src imports to work
project_root = current_dir.parent.parent
sys.path.insert(0, str(project_root))

from agents.participant.debate_participant_agent import DebateParticipantAgent


class TestRealRAGArgumentGeneration(unittest.TestCase):
    """Test real RAG argument generation with actual external searches and LLM calls"""
    
    def setUp(self):
        """Set up test environment with real configurations"""
        self.agent_id = "nietzsche_real_test"
        self.agent_name = "Friedrich Nietzsche"
        self.topic = "ì´ì¬ëª…ì€ ê³µì‚°ë‹¹ì˜ ê¼­ë‘ê°ì‹œì¸ê°€?"
        self.stance_statement = "ì´ì¬ëª…ì€ ìœ„í—˜í•œ ê³µì‚°ì£¼ì˜ìì´ë‹¤"
        
        # Real Nietzsche configuration
        self.nietzsche_config = {
            "role": "pro",  # ì°¬ì„± ì…ì¥
            "personality": "provocative",
            "knowledge_level": "expert", 
            "style": "philosophical",
            "philosopher_key": "nietzsche",
            "argumentation_style": "emotional",
            "response_focus": "attack"
        }
        
        # Track the entire process
        self.process_log = []
        
    def log_step(self, step_name: str, data: Any = None):
        """Log each step of the process"""
        timestamp = time.strftime("%H:%M:%S")
        self.process_log.append({
            "timestamp": timestamp,
            "step": step_name,
            "data": data
        })
        print(f"\n[{timestamp}] ğŸ”„ {step_name}")
        if data:
            print(f"    ğŸ“Š Data: {str(data)[:200]}{'...' if len(str(data)) > 200 else ''}")

    def _analyze_rag_usage_in_argument(self, final_argument: str, search_results: List[Dict], agent) -> Dict[str, Any]:
        """Analyze how RAG search results are used in the final argument"""
        usage_analysis = {
            "total_search_results": len(search_results),
            "used_results": 0,
            "unused_results": 0,
            "content_matches": [],
            "keyword_matches": [],
            "url_references": [],
            "source_integration": {},
            "prompt_evidence": None,
            "evidence_threshold_met": False
        }
        
        # ì‹¤ì œ agent ë¡œì§ì— ë”°ë¥¸ í™œìš© ì—¬ë¶€ í™•ì¸
        best_evidence = None
        highest_relevance = 0
        
        # agentì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ best_evidence ì°¾ê¸°
        for query_data in agent.argument_queries:
            argument = query_data.get("argument", "")
            for evidence in query_data.get("evidence", []):
                for result in evidence.get("results", []):
                    relevance = result.get("relevance", 0)
                    content = result.get("content", "")
                    
                    if relevance > highest_relevance and relevance > 0.5:
                        highest_relevance = relevance
                        best_evidence = {
                            "argument": argument,
                            "source": result.get("title", "Research"),
                            "url": result.get("url", ""),
                            "relevance": relevance,
                            "raw_content": content[:150]
                        }
        
        # ì‹¤ì œ í”„ë¡¬í”„íŠ¸ í¬í•¨ ì—¬ë¶€ í™•ì¸ (agent ë¡œì§: highest_relevance > 0.5)
        if best_evidence and highest_relevance > 0.5:
            usage_analysis["used_results"] = 1
            usage_analysis["unused_results"] = len(search_results) - 1
            usage_analysis["evidence_threshold_met"] = True
            usage_analysis["prompt_evidence"] = {
                "source": best_evidence["source"],
                "relevance": highest_relevance,
                "url": best_evidence["url"],
                "content": best_evidence["raw_content"]
            }
            
            # ì‹¤ì œ ì…ë¡ ì—ì„œ í•´ë‹¹ ì†ŒìŠ¤ ì–¸ê¸‰ ì—¬ë¶€ í™•ì¸
            source_title_words = best_evidence["source"].split()[:3]  # ì†ŒìŠ¤ ì œëª©ì˜ ì²˜ìŒ 3ë‹¨ì–´
            for word in source_title_words:
                if len(word) > 3 and word.lower() in final_argument.lower():
                    usage_analysis["content_matches"].append({
                        "source": best_evidence["source"],
                        "content": f"Source reference: {word}",
                        "url": best_evidence["url"]
                    })
                    break
        else:
            usage_analysis["used_results"] = 0
            usage_analysis["unused_results"] = len(search_results)
            usage_analysis["evidence_threshold_met"] = False
        
        # Extract keywords from search results for additional analysis
        all_keywords = set()
        for result_data in search_results:
            result = result_data.get('result', {})
            title = result.get('title', '')
            content = result.get('content', '')
            
            # Extract meaningful keywords (Korean and English) - ë” ì—„ê²©í•œ ê¸°ì¤€
            title_keywords = [w for w in re.findall(r'[\wê°€-í£]{4,}', title) 
                            if w.lower() not in ['this', 'that', 'with', 'from', 'they', 'have', 'been', 'will', 'said', 'says']]
            content_keywords = [w for w in re.findall(r'[\wê°€-í£]{4,}', content) 
                              if w.lower() not in ['this', 'that', 'with', 'from', 'they', 'have', 'been', 'will', 'said', 'says']]
            all_keywords.update(title_keywords[:5])  # ì œëª©ì—ì„œ ì²˜ìŒ 5ê°œë§Œ
            all_keywords.update(content_keywords[:10])  # ë‚´ìš©ì—ì„œ ì²˜ìŒ 10ê°œë§Œ
        
        # Check for keyword usage in final argument
        for keyword in all_keywords:
            if len(keyword) > 3 and keyword.lower() in final_argument.lower():
                usage_analysis["keyword_matches"].append(keyword)
        
        # Check for URL or source references
        for result_data in search_results:
            result = result_data.get('result', {})
            url = result.get('url', '')
            if url and url in final_argument:
                usage_analysis["url_references"].append(url)
        
        return usage_analysis

    def test_complete_real_rag_argument_generation(self):
        """Test complete RAG argument generation process with real external calls"""
        
        print("\n" + "="*100)
        print("ğŸ­ ë‹ˆì²´(Nietzsche) ì‹¤ì œ RAG ê²€ìƒ‰ ì…ë¡  ìƒì„± í…ŒìŠ¤íŠ¸")
        print("="*100)
        print(f"ğŸ“‹ ì£¼ì œ: {self.topic}")
        print(f"ğŸ“ ì…ì¥: {self.stance_statement}")
        print(f"ğŸ§  ì² í•™ì: {self.agent_name}")
        print(f"âš™ï¸  ì‹¤ì œ LLM ë° ì™¸ë¶€ ê²€ìƒ‰ ì‚¬ìš©")
        print("="*100)
        
        # Step 1: Create agent with real configuration
        self.log_step("ì—ì´ì „íŠ¸ ì´ˆê¸°í™”")
        start_time = time.time()
        
        try:
            agent = DebateParticipantAgent(self.agent_id, self.agent_name, self.nietzsche_config)
            
            # Verify agent is properly initialized
            self.assertEqual(agent.philosopher_key, "nietzsche")
            self.assertEqual(agent.role, "pro")
            
            self.log_step("ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ", {
                "agent_id": agent.agent_id,
                "philosopher": agent.philosopher_name,
                "role": agent.role
            })
            
            # Step 2: Generate core arguments (real LLM call)
            self.log_step("í•µì‹¬ ì£¼ì¥ ìƒì„± ì‹œì‘")
            core_args_start = time.time()
            
            agent._generate_core_arguments(self.topic, self.stance_statement)
            
            core_args_end = time.time()
            self.log_step("í•µì‹¬ ì£¼ì¥ ìƒì„± ì™„ë£Œ", {
                "count": len(agent.core_arguments),
                "duration": f"{core_args_end - core_args_start:.2f}ì´ˆ"
            })
            
            # Print generated core arguments
            print(f"\nğŸ“‹ ìƒì„±ëœ í•µì‹¬ ì£¼ì¥ ({len(agent.core_arguments)}ê°œ):")
            for i, arg in enumerate(agent.core_arguments, 1):
                print(f"  {i}. {arg.get('argument', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                print(f"     ê·¼ê±°: {arg.get('rationale', 'ì—†ìŒ')}")
            
            # Verify core arguments were generated
            self.assertGreater(len(agent.core_arguments), 0, "í•µì‹¬ ì£¼ì¥ì´ ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤")
            
            # Step 3: Generate RAG queries for each argument (real LLM call)
            self.log_step("RAG ì¿¼ë¦¬ ìƒì„± ì‹œì‘")
            queries_start = time.time()
            
            agent._generate_rag_queries_for_arguments(self.topic)
            
            queries_end = time.time()
            self.log_step("RAG ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ", {
                "query_count": len(agent.argument_queries),
                "duration": f"{queries_end - queries_start:.2f}ì´ˆ"
            })
            
            # Print generated queries
            print(f"\nğŸ” ìƒì„±ëœ RAG ì¿¼ë¦¬ ({len(agent.argument_queries)}ê°œ):")
            for i, query_data in enumerate(agent.argument_queries, 1):
                arg = query_data.get('argument', 'ì•Œ ìˆ˜ ì—†ìŒ')
                for evidence in query_data.get('evidence', []):
                    query = evidence.get('query', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    source = evidence.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    print(f"  {i}. ì£¼ì¥: {arg[:50]}...")
                    print(f"     ì¿¼ë¦¬: {query}")
                    print(f"     ì†ŒìŠ¤: {source}")
            
            # Step 4: Perform real RAG searches
            self.log_step("ì‹¤ì œ RAG ê²€ìƒ‰ ì‹œì‘")
            rag_start = time.time()
            
            total_searches = 0
            search_results_summary = {
                "web": 0,
                "vector": 0, 
                "dialogue": 0,
                "philosopher": 0
            }
            
            agent._strengthen_arguments_with_rag()
            
            rag_end = time.time()
            
            # Count actual search results and collect for analysis
            all_search_results = []
            for query_data in agent.argument_queries:
                for evidence in query_data.get('evidence', []):
                    results = evidence.get('results', [])
                    total_searches += len(results)
                    source = evidence.get('source', 'unknown')
                    if source in search_results_summary:
                        search_results_summary[source] += len(results)
                    
                    # Store all results for later analysis
                    for result in results:
                        all_search_results.append({
                            'argument': query_data.get('argument', '')[:100],
                            'query': evidence.get('query', ''),
                            'source': source,
                            'result': result
                        })
            
            self.log_step("ì‹¤ì œ RAG ê²€ìƒ‰ ì™„ë£Œ", {
                "total_results": total_searches,
                "duration": f"{rag_end - rag_start:.2f}ì´ˆ",
                "breakdown": search_results_summary
            })
            
            # Print search results summary
            print(f"\nğŸ” RAG ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:")
            print(f"  ğŸ“Š ì´ ê²€ìƒ‰ ê²°ê³¼: {total_searches}ê°œ")
            for source, count in search_results_summary.items():
                if count > 0:
                    print(f"  ğŸ”— {source.upper()}: {count}ê°œ ê²°ê³¼")
            
            # Print ALL search results with clickable URLs
            print(f"\nğŸ“š ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ({total_searches}ê°œ):")
            print("=" * 80)
            
            for i, query_data in enumerate(agent.argument_queries, 1):
                argument = query_data.get('argument', 'ì•Œ ìˆ˜ ì—†ìŒ')
                print(f"\nğŸ¯ ì£¼ì¥ {i}: {argument}")
                
                for j, evidence in enumerate(query_data.get('evidence', []), 1):
                    query = evidence.get('query', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    source = evidence.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    results = evidence.get('results', [])
                    
                    print(f"  ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
                    print(f"  ğŸ“Š ì†ŒìŠ¤: {source}")
                    print(f"  ğŸ“ˆ ê²°ê³¼ ìˆ˜: {len(results)}ê°œ")
                    
                    for k, result in enumerate(results, 1):
                        title = result.get('title', 'ì œëª© ì—†ìŒ')
                        content = result.get('content', 'ë‚´ìš© ì—†ìŒ')
                        url = result.get('url', '')
                        relevance = result.get('relevance', 0.0)
                        
                        print(f"    {k}. ğŸ“° {title[:80]}...")
                        print(f"       ğŸ“ {content[:150]}...")
                        print(f"       ğŸ“Š ê´€ë ¨ë„: {relevance}")
                        if url:
                            print(f"       ğŸŒ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬: {url}")
                        print()
            
            print("=" * 80)
            
            # Step 5: Generate final opening argument (real LLM call)
            self.log_step("ìµœì¢… ì…ë¡  ìƒì„± ì‹œì‘")
            final_start = time.time()
            
            agent._generate_final_opening_argument(self.topic, self.stance_statement)
            
            final_end = time.time()
            self.log_step("ìµœì¢… ì…ë¡  ìƒì„± ì™„ë£Œ", {
                "argument_length": len(agent.prepared_argument) if agent.prepared_argument else 0,
                "duration": f"{final_end - final_start:.2f}ì´ˆ"
            })
            
            # Step 6: Mark argument as prepared
            agent.argument_prepared = True
            
            total_time = time.time() - start_time
            
            # Print final results
            print(f"\n" + "="*100)
            print("ğŸ“œ ìµœì¢… ìƒì„±ëœ ì…ë¡ :")
            print("="*100)
            if agent.prepared_argument:
                print(agent.prepared_argument)
            else:
                print("âŒ ì…ë¡ ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("="*100)
            
            # Step 7: Analyze RAG usage in final argument
            if agent.prepared_argument and all_search_results:
                print(f"\nğŸ” RAG ë°ì´í„° í™œìš©ë„ ë¶„ì„:")
                print("=" * 80)
                
                rag_analysis = self._analyze_rag_usage_in_argument(agent.prepared_argument, all_search_results, agent)
                
                print(f"ğŸ“Š ì´ ê²€ìƒ‰ ê²°ê³¼: {rag_analysis['total_search_results']}ê°œ")
                print(f"âœ… ì‚¬ìš©ëœ ê²°ê³¼: {rag_analysis['used_results']}ê°œ")
                print(f"âŒ ë¯¸ì‚¬ìš© ê²°ê³¼: {rag_analysis['unused_results']}ê°œ")
                print(f"ğŸ”‘ ë§¤ì¹­ëœ í‚¤ì›Œë“œ: {len(rag_analysis['keyword_matches'])}ê°œ")
                print(f"ğŸ“ ì½˜í…ì¸  ë§¤ì¹­: {len(rag_analysis['content_matches'])}ê°œ")
                print(f"ğŸ”— URL ì°¸ì¡°: {len(rag_analysis['url_references'])}ê°œ")
                
                # í”„ë¡¬í”„íŠ¸ í¬í•¨ ìƒì„¸ ì •ë³´
                print(f"ğŸ¯ ì¦ê±° ì„ê³„ê°’ ë‹¬ì„±: {'âœ…' if rag_analysis['evidence_threshold_met'] else 'âŒ'}")
                if rag_analysis['prompt_evidence']:
                    print(f"\nğŸ“‹ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ëœ ì¦ê±°:")
                    print(f"  ğŸ“° ì†ŒìŠ¤: {rag_analysis['prompt_evidence']['source']}")
                    print(f"  ğŸ“Š ìœ ì‚¬ë„: {rag_analysis['prompt_evidence']['relevance']}")
                    print(f"  ğŸ“ ë‚´ìš©: {rag_analysis['prompt_evidence']['content']}")
                    if rag_analysis['prompt_evidence']['url']:
                        print(f"  ğŸ”— URL: {rag_analysis['prompt_evidence']['url']}")
                else:
                    print(f"\nâŒ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ëœ ì¦ê±° ì—†ìŒ (ìœ ì‚¬ë„ < 0.5 ë˜ëŠ” ì¦ê±° ë¶€ì¡±)")
                
                if rag_analysis['keyword_matches']:
                    print(f"\nğŸ”‘ í™œìš©ëœ í‚¤ì›Œë“œ:")
                    for keyword in rag_analysis['keyword_matches'][:10]:  # Show first 10
                        print(f"  - {keyword}")
                
                if rag_analysis['content_matches']:
                    print(f"\nğŸ“ ì§ì ‘ í™œìš©ëœ ì½˜í…ì¸ :")
                    for match in rag_analysis['content_matches'][:3]:  # Show first 3
                        print(f"  ğŸ“° ì¶œì²˜: {match['source']}")
                        print(f"  ğŸ“ ë‚´ìš©: {match['content'][:100]}...")
                        if match['url']:
                            print(f"  ğŸ”— ë§í¬: {match['url']}")
                        print()
                
                if rag_analysis['url_references']:
                    print(f"\nğŸ”— ì°¸ì¡°ëœ URL:")
                    for url in rag_analysis['url_references']:
                        print(f"  - {url}")
                
                print("=" * 80)
            
            # Print process summary
            print(f"\nğŸ“Š ì „ì²´ í”„ë¡œì„¸ìŠ¤ ìš”ì•½:")
            print(f"  â±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"  ğŸ¯ í•µì‹¬ ì£¼ì¥ ìˆ˜: {len(agent.core_arguments)}ê°œ")
            print(f"  ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬ ìˆ˜: {len(agent.argument_queries)}ê°œ")
            print(f"  ğŸ“Š ì´ ê²€ìƒ‰ ê²°ê³¼: {total_searches}ê°œ")
            print(f"  ğŸ“œ ìµœì¢… ì…ë¡  ê¸¸ì´: {len(agent.prepared_argument) if agent.prepared_argument else 0}ì")
            
            # Print detailed process log
            print(f"\nğŸ“ ì„¸ë¶€ í”„ë¡œì„¸ìŠ¤ ë¡œê·¸:")
            for i, log_entry in enumerate(self.process_log, 1):
                print(f"  {i:2d}. [{log_entry['timestamp']}] {log_entry['step']}")
            
            # Assertions
            self.assertTrue(agent.argument_prepared, "ì…ë¡ ì´ ì¤€ë¹„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤")
            self.assertIsNotNone(agent.prepared_argument, "ì…ë¡  í…ìŠ¤íŠ¸ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤")
            self.assertGreater(len(agent.prepared_argument), 50, "ì…ë¡ ì´ ì¶©ë¶„íˆ ê¸¸ì–´ì•¼ í•©ë‹ˆë‹¤")
            self.assertTrue(len(agent.core_arguments) > 0, "í•µì‹¬ ì£¼ì¥ë“¤ì´ ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤")
            self.assertTrue(len(agent.argument_queries) > 0, "RAG ì¿¼ë¦¬ë“¤ì´ ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤")
            
            print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ì„±ê³µ! ë‹ˆì²´ì˜ ì‹¤ì œ RAG ê¸°ë°˜ ì…ë¡ ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            import traceback
            print(f"   ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
            raise

    def test_agent_initialization_with_real_data(self):
        """Test agent initialization with real philosopher data"""
        
        print("\n" + "="*60)
        print("âš™ï¸  ì—ì´ì „íŠ¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
        print("="*60)
        
        agent = DebateParticipantAgent(self.agent_id, self.agent_name, self.nietzsche_config)
        
        # Print loaded philosopher data
        print(f"ğŸ§  ì² í•™ì ì •ë³´:")
        print(f"  ì´ë¦„: {agent.philosopher_name}")
        print(f"  í•µì‹¬ ì‚¬ìƒ: {agent.philosopher_essence}")
        print(f"  í† ë¡  ìŠ¤íƒ€ì¼: {agent.philosopher_debate_style}")
        print(f"  ì„±ê²©: {agent.philosopher_personality}")
        print(f"  ì£¼ìš” íŠ¹ì„±: {', '.join(agent.philosopher_key_traits) if agent.philosopher_key_traits else 'ì—†ìŒ'}")
        print(f"  ëª…ì–¸: {agent.philosopher_quote}")
        
        # Test core functionality
        self.assertEqual(agent.philosopher_key, "nietzsche")
        self.assertEqual(agent.role, "pro")
        self.assertIsNotNone(agent.llm_manager)
        
        print(f"\nâœ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")


if __name__ == '__main__':
    # Set up test environment
    print("ğŸš€ ì‹¤ì œ RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("âš ï¸  ì£¼ì˜: ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œ LLM API í˜¸ì¶œê³¼ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤")
    print("ğŸ’° ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜í•˜ì„¸ìš”!")
    
    # Ask for confirmation
    try:
        confirm = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        if confirm not in ['y', 'yes']:
            print("í…ŒìŠ¤íŠ¸ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            sys.exit(0)
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    
    print("\n" + "="*100)
    
    # Create test suite for the specific tests we want to run
    suite = unittest.TestSuite()
    
    # Add tests in order
    suite.addTest(TestRealRAGArgumentGeneration('test_agent_initialization_with_real_data'))
    suite.addTest(TestRealRAGArgumentGeneration('test_complete_real_rag_argument_generation'))
    
    # Run tests with detailed output
    runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout, buffer=False)
    result = runner.run(suite)
    
    # Final summary
    print(f"\n" + "="*100)
    print("ğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"  âœ… ì„±ê³µ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"  âŒ ì‹¤íŒ¨: {len(result.failures)}")
    print(f"  ğŸš« ì˜¤ë¥˜: {len(result.errors)}")
    print("="*100)
    
    # Exit with appropriate code
    sys.exit(0 if result.wasSuccessful() else 1) 