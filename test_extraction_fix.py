#!/usr/bin/env python3

import logging
import sys
from pathlib import Path

# Add src to path  
current_dir = Path(__file__).parent.absolute()
src_path = current_dir / "src"
sys.path.insert(0, str(src_path))

# Set up detailed logging
logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')

from src.rag.retrieval.web_retriever import WebSearchRetriever

def test_extraction_fix():
    print("ğŸ§ª ìˆ˜ì •ëœ Wikipedia ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # Create retriever
    retriever = WebSearchRetriever(
        search_provider="google",
        max_results=1
    )
    
    # Test URL
    test_url = "https://en.wikipedia.org/wiki/Lee_Jae-myung"
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ URL: {test_url}")
    
    # Mock search result
    mock_search_result = {
        "title": "Lee Jae-myung - Wikipedia",
        "url": test_url,
        "snippet": "South Korean politician",
        "source": "google_api",
        "position": 1
    }
    
    print("ğŸ” ìˆ˜ì •ëœ ì½˜í…ì¸  ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
    
    try:
        content, metadata = retriever._extract_page_content(test_url, mock_search_result)
        
        print(f"ğŸ“ ì½˜í…ì¸  ê¸¸ì´: {len(content)} ë¬¸ì")
        print(f"ğŸ“Š ë‹¨ì–´ ìˆ˜: {len(content.split())} ë‹¨ì–´")
        print(f"ğŸ·ï¸  ì œëª©: {metadata.get('title', 'No title')}")
        print(f"âš™ï¸  ì¶”ì¶œ ë°©ë²•: {metadata.get('extraction_method', 'Unknown')}")
        
        if content:
            print(f"âœ… ì¶”ì¶œ ì„±ê³µ!")
            print(f"\nğŸ“„ ì½˜í…ì¸  ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 300ì):")
            print("=" * 50)
            print(content[:300] + "...")
            print("=" * 50)
            
            # retrieve_and_extractë„ í…ŒìŠ¤íŠ¸
            print(f"\nğŸ”„ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (retrieve_and_extract)")
            chunks = retriever.retrieve_and_extract('Lee Jae-myung', max_pages=1)
            print(f"ğŸ“Š ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}")
            
            if chunks:
                for i, chunk in enumerate(chunks[:3]):
                    score = chunk.get("score", chunk.get("similarity", 0))
                    print(f"  ì²­í¬ {i+1}: {len(chunk['text'])} ë¬¸ì, ì ìˆ˜: {score:.3f}")
            
        else:
            print("âŒ ì½˜í…ì¸ ê°€ ë¹„ì–´ìˆìŒ")
            print(f"ğŸ” ì—ëŸ¬: {metadata.get('error', 'Unknown error')}")
            print(f"ğŸ” ë‹¨ì–´ ìˆ˜: {metadata.get('word_count', 'Unknown')}")
            
    except Exception as e:
        print(f"âŒ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        import traceback
        print(f"ğŸ” ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")

if __name__ == "__main__":
    test_extraction_fix() 