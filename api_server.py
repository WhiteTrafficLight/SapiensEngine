# api_server.py ìˆ˜ì •
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict, Any, Union, Set
import logging
import uvicorn
import os
import yaml
from fastapi.staticfiles import StaticFiles
import openai
import requests
from slugify import slugify
import time
import asyncio
import random
import aiohttp
from uuid import uuid4
from datetime import datetime
from types import SimpleNamespace
import json

# Sapiens Engine ì„í¬íŠ¸
from sapiens_engine.core.llm_manager import LLMManager
from sapiens_engine.core.config_loader import ConfigLoader

# NPC ì„í¬íŠ¸ ë¶€ë¶„ ì œê±°í•˜ê³  ì§ì ‘ í•„ìš”í•œ ì„¤ëª… ìƒì„±

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# YAML íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_yaml_file(file_path):
    """YAML íŒŒì¼ì„ ë¡œë“œ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return yaml.safe_load(file)
    except Exception as e:
        logger.error(f"Error loading YAML file {file_path}: {e}")
        return {}

# ì² í•™ì ì •ë³´ ë¡œë“œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PHILOSOPHERS_FILE = os.path.join(BASE_DIR, "sapiens_engine/config/philosophers.yaml")
logger.info(f"Loading philosophers from: {PHILOSOPHERS_FILE}")
philosophers_data = load_yaml_file(PHILOSOPHERS_FILE)
if not philosophers_data:
    logger.warning("Failed to load philosophers data. Using hardcoded descriptions.")

# ì² í•™ì ì´ˆìƒí™” ë§¤í•‘
PORTRAITS_MAP = {
    "socrates": "Socrates.png",
    "plato": "Plato.png",
    "aristotle": "Aristotle.png",
    "kant": "Kant.png",
    "nietzsche": "Nietzsche.png",
    "hegel": "Hegel.png",
    "marx": "Marx.png",
    "sartre": "Sartre.png",
    "camus": "Camus.png",
    "beauvoir": "Beauvoir.png",
    "rousseau": "Rousseau.png",
    "confucius": "Confucius.png",
    "laozi": "Laozi.png",
    "buddha": "Buddha.png",
    "wittgenstein": "Wittgenstein.png"
}

# ìš”ì²­ ëª¨ë¸ ì •ì˜
class InitialChatRequest(BaseModel):
    philosopher: str
    topic: str
    context: Optional[str] = ""
    user_message: Optional[str] = None

# ì±„íŒ…ë°© ìƒì„± ìš”ì²­ ëª¨ë¸ ì¶”ê°€
class ChatRoomCreationRequest(BaseModel):
    title: str
    context: Optional[str] = ""
    contextUrl: Optional[str] = None
    contextFileContent: Optional[str] = None
    maxParticipants: int
    npcs: List[str]
    isPublic: Optional[bool] = True
    currentUser: Optional[str] = None
    # ìƒˆ í•„ë“œ ì¶”ê°€
    generateInitialMessage: Optional[bool] = True
    llmProvider: Optional[str] = "openai"
    llmModel: Optional[str] = "gpt-4o"

# ëŒ€í™” ìƒì„± ìš”ì²­ ëª¨ë¸ ì¶”ê°€
class ChatGenerateRequest(BaseModel):
    npc_descriptions: Optional[str] = None
    npcs: Optional[List[str]] = []  # í•„ìˆ˜ í•„ë“œë¥¼ Optionalë¡œ ì„¤ì •
    topic: Optional[str] = ""
    context: Optional[str] = ""
    previous_dialogue: Optional[str] = ""
    llm_provider: Optional[str] = "openai"
    llm_model: Optional[str] = "gpt-4o"
    api_key: Optional[str] = None  # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë°›ì€ API í‚¤

# ì‘ë‹µ ëª¨ë¸ ì •ì˜
class ChatResponse(BaseModel):
    response: str
    philosopher: str
    metadata: Optional[Dict[str, Any]] = None

# Portrait generation request model
class PortraitRequest(BaseModel):
    npc_name: str
    role: str
    reference_philosophers: List[str]
    voice_style: str  # include user-specified voice style for expression

# NPC ìƒì„± ìš”ì²­ ëª¨ë¸ ë° ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
class NpcCreateRequest(BaseModel):
    name: str
    role: str
    voice_style: str
    reference_philosophers: List[str]
    communication_style: str
    debate_approach: str
    created_by: str
    created_at: str

# NPC ê°„ ìë™ ëŒ€í™” ìƒì„±ì„ ìœ„í•œ ìš”ì²­ í´ë˜ìŠ¤
class DialogueGenerateRequest(BaseModel):
    participants: List[str]  # NPC ID ëª©ë¡
    topic: str
    rounds: Optional[int] = 3  # ëŒ€í™” ë¼ìš´ë“œ ìˆ˜
    context: Optional[str] = ""  # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸

# ìë™ ëŒ€í™” ìš”ì²­ ëª¨ë¸
class AutoConversationRequest(BaseModel):
    room_id: str
    npcs: List[str]
    topic: Optional[str] = ""
    delay_range: Optional[List[int]] = [15, 25]

# ìë™ ëŒ€í™” ì‘ë‹µ ëª¨ë¸
class AutoConversationResponse(BaseModel):
    status: str
    room_id: str
    message: Optional[str] = None

# ìë™ ëŒ€í™” í™œì„±í™” ìƒíƒœ ì¶”ì  (ì„œë²„ ë©”ëª¨ë¦¬ì— ì €ì¥)
active_auto_conversations = {}

# íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€í•  ì „ì—­ ìºì‹œ ë³€ìˆ˜
# NPC ìºì‹œ ì„¤ì •
npc_cache = {}  # IDë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ëŠ” ìºì‹œ ë”•ì…”ë„ˆë¦¬
npc_cache_ttl = 60 * 10  # ìºì‹œ ìœ íš¨ ì‹œê°„: 10ë¶„

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="Sapiens Engine API")

# í™˜ê²½ ì„¤ì • ì¶œë ¥
nextjs_api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
logger.info(f"===== ì‹œìŠ¤í…œ í™˜ê²½ ì„¤ì • =====")
logger.info(f"NEXTJS_API_URL: {nextjs_api_url}")
logger.info(f"OPENAI_API_KEY: {'ì„¤ì •ë¨' if os.environ.get('OPENAI_API_KEY') else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
logger.info(f"DEBUG ëª¨ë“œ: {logging.getLogger().level == logging.DEBUG}")
logger.info(f"==================")

# CORS ì„¤ì • (AgoraMind ì›¹ ì•±ì—ì„œ ì ‘ê·¼ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” êµ¬ì²´ì ì¸ ì˜¤ë¦¬ì§„ìœ¼ë¡œ ë³€ê²½
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë ‰í† ë¦¬ ê²½ë¡œ ë””ë²„ê¹…
logger.info(f"Current directory: {os.getcwd()}")
logger.info(f"BASE_DIR: {BASE_DIR}")
logger.info(f"Files in current directory: {os.listdir('.')}")

# /portraits ê²½ë¡œë¡œ ì´ˆìƒí™” ì •ì  íŒŒì¼ ì„œë¹„ìŠ¤ - ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
PORTRAITS_DIR = os.path.join(os.getcwd(), "portraits")
logger.info(f"Portrait directory path: {PORTRAITS_DIR}")
if os.path.isdir(PORTRAITS_DIR):
    app.mount("/portraits", StaticFiles(directory=PORTRAITS_DIR), name="portraits")
    logger.info(f"Mounted portraits from {PORTRAITS_DIR} at /portraits")
else:
    logger.error(f"!!! Portraits directory not found: {PORTRAITS_DIR}")
    # ì˜¤ë¥˜ ë°œìƒ í›„ ì„œë²„ ì¢…ë£Œ
    logger.error("Portrait directory not found - cannot serve images")

# LLM ë§¤ë‹ˆì € ì´ˆê¸°í™”
config_loader = ConfigLoader()
llm_manager = LLMManager(config_loader)

# ì² í•™ì ì„¤ëª… ì‚¬ì „ (NPC í´ë˜ìŠ¤ ëŒ€ì‹  ì§ì ‘ ì •ì˜)
philosopher_descriptions = {
    "socrates": "Socrates was an Ancient Greek philosopher known for the Socratic method of questioning, seeking wisdom through dialogue, and the phrase 'I know that I know nothing'. His style is to ask probing questions, challenge assumptions, and use irony. Key concepts include: Socratic method, Examined life, Intellectual humility, Ethical inquiry, Dialectic.",
    "plato": "Plato was an Ancient Greek philosopher, student of Socrates, and founder of the Academy. Known for his theory of Forms, belief in objective truths, and political philosophy. His style is dialectical, making references to eternal ideals and using allegories to illustrate points. Key concepts include: Theory of Forms, The Good, The Republic, The soul, Philosopher-kings.",
    "aristotle": "Aristotle was an Ancient Greek philosopher, student of Plato, and tutor to Alexander the Great. Known for empiricism, virtue ethics, and systematic classification of knowledge. His style is methodical, analytical, and balanced, focusing on practical wisdom and the middle path. Key concepts include: Golden mean, Four causes, Virtue ethics, Eudaimonia, Practical wisdom.",
    "kant": "Kant was an 18th century German philosopher known for his work on ethics, metaphysics, epistemology, and aesthetics. His style is formal, structured, and precise, using technical terminology and emphasizing universal moral principles. Key concepts include: Categorical imperative, Duty, Phenomena vs. noumena, Synthetic a priori, Transcendental idealism.",
    "nietzsche": "Nietzsche was a 19th century German philosopher known for his critique of morality, religion, and contemporary culture. His style is bold, provocative, and poetic, using aphorisms and metaphors to challenge conventional wisdom. Key concepts include: Will to power, Eternal recurrence, Ãœbermensch, Master-slave morality, Perspectivism.",
    "sartre": "Sartre was a 20th century French existentialist philosopher and writer who emphasized freedom, responsibility, and authenticity in human existence. His style is direct, challenging, and focused on concrete human situations. Key concepts include: Existence precedes essence, Radical freedom, Bad faith, Being-for-itself, Authenticity.",
    "camus": "Camus was a 20th century French philosopher associated with absurdism who explored how to find meaning in an indifferent universe. His style is philosophical yet accessible, using literary references and everyday examples. Key concepts include: The Absurd, Revolt, Sisyphus, Philosophical suicide, Authentic living.",
    "simone de beauvoir": "Simone de Beauvoir was a 20th century French philosopher and feminist theorist who explored ethics, politics, and the social construction of gender. Her style connects abstract concepts to lived experiences, especially regarding gender and social relationships. Key concepts include: Situated freedom, The Other, Woman as Other, Ethics of ambiguity, Reciprocal recognition.",
    "marx": "Marx was a 19th century German philosopher, economist, and political theorist who developed historical materialism and critiqued capitalism. His style is analytical and critical, focusing on material conditions and class relations. Key concepts include: Historical materialism, Class struggle, Alienation, Commodity fetishism, Dialectical materialism.",
    "rousseau": "Rousseau was an 18th century Genevan philosopher of the Enlightenment known for his work on political philosophy, education, and human nature. His style combines passionate rhetoric with systematic analysis, appealing to natural human qualities. Key concepts include: Natural state, General will, Social contract, Noble savage, Authentic self."
}

# OpenAI API key
openai.api_key = os.environ.get("OPENAI_API_KEY")

# WebSocket ì—°ê²° ê´€ë¦¬ì
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, List[WebSocket]] = {}
        self.auto_conversation_tasks: Dict[str, asyncio.Task] = {}
    
    async def connect(self, websocket: WebSocket, room_id: str):
        await websocket.accept()
        if room_id not in self.active_connections:
            self.active_connections[room_id] = []
        self.active_connections[room_id].append(websocket)
        logger.info(f"WebSocket connection established for room {room_id}")
    
    async def disconnect(self, websocket: WebSocket, room_id: str):
        if room_id in self.active_connections:
            try:
                self.active_connections[room_id].remove(websocket)
                if not self.active_connections[room_id]:
                    del self.active_connections[room_id]
                logger.info(f"WebSocket connection closed for room {room_id}")
            except ValueError:
                logger.warning(f"WebSocket not found in connections for room {room_id}")
    
    async def broadcast(self, message: dict, room_id: str):
        if room_id in self.active_connections:
            disconnected_ws = []
            for connection in self.active_connections[room_id]:
                try:
                    await connection.send_json(message)
                except RuntimeError as e:
                    logger.error(f"Error broadcasting to client: {str(e)}")
                    disconnected_ws.append(connection)
            
            # ì—°ê²° ì¢…ë£Œëœ ì›¹ì†Œì¼“ ì •ë¦¬
            for ws in disconnected_ws:
                await self.disconnect(ws, room_id)
    
    def start_auto_conversation(self, room_id: str, task: asyncio.Task):
        self.auto_conversation_tasks[room_id] = task
        logger.info(f"Started auto conversation for room {room_id}")
    
    def stop_auto_conversation(self, room_id: str):
        if room_id in self.auto_conversation_tasks:
            if not self.auto_conversation_tasks[room_id].done():
                self.auto_conversation_tasks[room_id].cancel()
            del self.auto_conversation_tasks[room_id]
            logger.info(f"Stopped auto conversation for room {room_id}")
            return True
        return False

# ConnectionManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
manager = ConnectionManager()

# ì±„íŒ… ë©”ì‹œì§€ë¥¼ Next.js APIë¥¼ í†µí•´ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
async def save_message_to_db(room_id: str, message: dict):
    try:
        # Next.js API í˜¸ì¶œí•˜ì—¬ ë©”ì‹œì§€ ì €ì¥
        async with aiohttp.ClientSession() as session:
            # API ì—”ë“œí¬ì¸íŠ¸ URL (ì‹¤ì œ URLë¡œ ë³€ê²½ í•„ìš”)
            api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
            url = f"{api_url}/api/rooms"
            
            # ë©”ì‹œì§€ ë°ì´í„° ì¤€ë¹„
            payload = {
                "id": room_id,
                "message": message
            }
            
            # API í˜¸ì¶œ
            async with session.put(url, json=payload) as response:
                if response.status == 200:
                    logger.info(f"Message saved to database for room {room_id}: {message['id']}")
                    return True
                else:
                    error_text = await response.text()
                    logger.error(f"Failed to save message: {error_text}")
                    return False
    except Exception as e:
        logger.error(f"Error saving message to database: {str(e)}")
        return False

# ì±„íŒ…ë°© ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
async def get_room_messages(room_id: str, limit: int = 20):
    try:
        # Next.js API í˜¸ì¶œí•˜ì—¬ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        async with aiohttp.ClientSession() as session:
            # API ì—”ë“œí¬ì¸íŠ¸ URL (ì‹¤ì œ URLë¡œ ë³€ê²½ í•„ìš”)
            api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
            url = f"{api_url}/api/rooms?id={room_id}"
            
            # API í˜¸ì¶œ
            async with session.get(url) as response:
                if response.status == 200:
                    data = await response.json()
                    messages = data.get("messages", [])
                    
                    # ì œí•œëœ ìˆ˜ì˜ ìµœì‹  ë©”ì‹œì§€ë§Œ ë°˜í™˜
                    if len(messages) > limit:
                        messages = messages[-limit:]
                    
                    logger.info(f"Retrieved {len(messages)} messages for room {room_id}")
                    return messages
                else:
                    error_text = await response.text()
                    logger.error(f"Failed to get messages: {error_text}")
                    return []
    except Exception as e:
        logger.error(f"Error retrieving messages: {str(e)}")
        return []

# ì±„íŒ…ë°© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
async def get_room_data(room_id: str):
    try:
        # Next.js API í˜¸ì¶œí•˜ì—¬ ì±„íŒ…ë°© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        async with aiohttp.ClientSession() as session:
            api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
            url = f"{api_url}/api/rooms?id={room_id}"
            
            async with session.get(url) as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"Retrieved room data for {room_id}")
                    return data
                else:
                    error_text = await response.text()
                    logger.error(f"Failed to get room data: {error_text}")
                    return {}
    except Exception as e:
        logger.error(f"Error retrieving room data: {str(e)}")
        return {}

# ìë™ ëŒ€í™” ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/auto-conversation", response_model=AutoConversationResponse)
async def start_auto_conversation(request: AutoConversationRequest, background_tasks: BackgroundTasks):
    """ìë™ ëŒ€í™” ìƒì„± ì‹œì‘"""
    room_id = request.room_id
    
    # ì´ë¯¸ ìë™ ëŒ€í™”ê°€ í™œì„±í™”ëœ ì±„íŒ…ë°©ì¸ì§€ í™•ì¸
    if room_id in active_auto_conversations:
        # ì´ì „ íƒœìŠ¤í¬ ì¤‘ì§€
        active_auto_conversations[room_id]["active"] = False
        logger.info(f"Stopping existing auto conversation for room {room_id}")
        # ì¶©ë¶„í•œ ì‹œê°„ì„ ì£¼ì–´ íƒœìŠ¤í¬ê°€ ì¢…ë£Œë˜ë„ë¡ í•¨
        await asyncio.sleep(1)
    
    # ìƒˆ ìë™ ëŒ€í™” ìƒíƒœ ì¶”ì  ì„¤ì •
    active_auto_conversations[room_id] = {
        "active": True,
        "npcs": request.npcs,
        "topic": request.topic,
        "delay_range": request.delay_range,
        "last_message_time": time.time()
    }
    
    # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ìë™ ëŒ€í™” ë£¨í”„ ì‹œì‘
    background_tasks.add_task(
        auto_conversation_loop,
        room_id,
        request.npcs,
        request.topic,
        request.delay_range
    )
    
    logger.info(f"Started auto conversation for room {room_id} with {len(request.npcs)} NPCs")
    return {"status": "started", "room_id": room_id}

@app.delete("/api/auto-conversation", response_model=AutoConversationResponse)
async def stop_auto_conversation(room_id: str):
    """ìë™ ëŒ€í™” ìƒì„± ì¤‘ì§€ - Query parameterë¡œ room_idë¥¼ ë°›ìŒ"""
    logger.info(f"Stopping auto conversation for room {room_id}")
    
    # active_auto_conversations ìƒíƒœ ë””ë²„ê¹…
    logger.debug(f"í˜„ì¬ í™œì„± ëŒ€í™” ìƒíƒœ: {active_auto_conversations}")
    
    if room_id in active_auto_conversations:
        logger.info(f"í•´ë‹¹ ë°©ì˜ ìë™ ëŒ€í™” ì •ë³´: {active_auto_conversations[room_id]}")
        # active í”Œë˜ê·¸ë¥¼ Falseë¡œ ì„¤ì •
        active_auto_conversations[room_id]["active"] = False
        
        # active í”Œë˜ê·¸ ì„¤ì • ì§í›„ ìƒíƒœ í™•ì¸
        logger.info(f"active=False ì„¤ì • í›„ ìƒíƒœ: {active_auto_conversations[room_id]}")
        
        # ë°”ë¡œ ì‚­ì œí•˜ì§€ ì•Šê³  active í”Œë˜ê·¸ë§Œ ë”
        # ì´ë ‡ê²Œ í•˜ë©´ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì¢…ë£Œë¨
        logger.info(f"Stopped auto conversation for room {room_id}")
        return {"status": "stopped", "room_id": room_id}
    else:
        logger.warning(f"No active auto conversation found for room {room_id}")
        return {"status": "not_found", "room_id": room_id, "message": "No active auto conversation found"}

# ìë™ ëŒ€í™” ìƒì„± ë£¨í”„ í•¨ìˆ˜
async def auto_conversation_loop(room_id: str, npcs: List[str], topic: str, delay_range: List[int]):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” ìë™ ëŒ€í™” ìƒì„± ë£¨í”„"""
    try:
        logger.debug(f"====== ìë™ ëŒ€í™” ë£¨í”„ ì‹œì‘ - ë°© ID: {room_id} ======")
        logger.debug(f"NPC ëª©ë¡: {npcs}")
        logger.debug(f"ì£¼ì œ: {topic}")
        logger.debug(f"ì§€ì—° ë²”ìœ„: {delay_range}")
        logger.debug(f"í˜„ì¬ í™œì„± ëŒ€í™”: {active_auto_conversations}")
        
        min_delay, max_delay = delay_range
        prev_npc = None
        message_count = 0
        max_messages = 50  # ì•ˆì „ì¥ì¹˜: ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜ ì œí•œ
        
        # ì´ì „ ëŒ€í™” ë©”ì‹œì§€ë¥¼ ë³´ê´€í•  ëŒ€í™” ê¸°ë¡
        dialogue_history = ""
        
        # ë£¨í”„ ì‹¤í–‰ - active í”Œë˜ê·¸ê°€ ì¼œì ¸ ìˆëŠ” ë™ì•ˆ ê³„ì† ì‹¤í–‰
        while active_auto_conversations.get(room_id, {}).get("active", False) and message_count < max_messages:
            try:
                logger.debug(f"====== ìë™ ëŒ€í™” ë£¨í”„ ì‚¬ì´í´ {message_count+1} ======")
                # í˜„ì¬ NPC ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë™ì  ì—…ë°ì´íŠ¸ ê°€ëŠ¥)
                current_npcs = active_auto_conversations.get(room_id, {}).get("npcs", npcs)
                current_topic = active_auto_conversations.get(room_id, {}).get("topic", topic)
                
                logger.debug(f"í˜„ì¬ active_auto_conversations ìƒíƒœ: {active_auto_conversations}")
                
                if len(current_npcs) < 2:
                    logger.warning(f"Not enough NPCs for auto conversation in room {room_id}")
                    break
                
                # ë¨¼ì € ì±„íŒ…ë°©ì˜ ìµœê·¼ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜´ (ìµœëŒ€ 10ê°œ)
                if message_count == 0 or message_count % 5 == 0:  # ì²˜ìŒê³¼ 5íšŒ ì£¼ê¸°ë¡œ ë©”ì‹œì§€ ê°±ì‹ 
                    try:
                        logger.debug(f"ì±„íŒ…ë°© {room_id}ì˜ ìµœê·¼ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°")
                        recent_messages = await get_room_messages(room_id, limit=10)
                        
                        # ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        if recent_messages:
                            dialogue_history = ""
                            for msg in recent_messages:
                                sender = msg.get('senderName', msg.get('sender', 'Unknown'))
                                text = msg.get('text', '')
                                if text:
                                    dialogue_history += f"{sender}: {text}\n\n"
                            
                            logger.debug(f"ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ë¨: {len(recent_messages)}ê°œ ë©”ì‹œì§€")
                            logger.debug(f"ëŒ€í™” ê¸°ë¡ ìƒ˜í”Œ: {dialogue_history[:200]}...")
                        else:
                            logger.debug(f"ì±„íŒ…ë°© {room_id}ì—ì„œ ê°€ì ¸ì˜¨ ë©”ì‹œì§€ ì—†ìŒ")
                    except Exception as e:
                        logger.error(f"ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
                
                # ì´ì „ NPCì™€ ë‹¤ë¥¸ NPC ì„ íƒ
                available_npcs = [npc for npc in current_npcs if npc != prev_npc]
                if not available_npcs:
                    available_npcs = current_npcs
                
                # ë¬´ì‘ìœ„ë¡œ ë‹¤ìŒ NPC ì„ íƒ
                responding_npc_id = random.choice(available_npcs)
                prev_npc = responding_npc_id
                
                logger.debug(f"ì„ íƒëœ NPC ID: {responding_npc_id}")
                
                # NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                logger.info(f"Generating response from NPC: {responding_npc_id}")
                
                try:
                    # ì—¬ê¸°ì„œ NPC ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ë•Œ ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
                    logger.info(f"ğŸ“£ Getting details for NPC ID: {responding_npc_id}")
                    npc_info = await get_npc_details(responding_npc_id)
                    logger.info(f"ğŸ“£ NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ: {npc_info.get('name', 'Unknown')}")
                    logger.debug(f"ğŸ“‹ ê°€ì ¸ì˜¨ NPC ì •ë³´ ì „ì²´: {npc_info}")
                except Exception as npc_err:
                    logger.error(f"NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(npc_err)}")
                    # ë‹¤ìŒ ì‚¬ì´í´ë¡œ ë„˜ì–´ê°
                    await asyncio.sleep(5)
                    continue
                
                # NPC ì„¤ëª… êµ¬ì„± - custom NPCì˜ ê²½ìš° ì¶”ê°€ íŠ¹ì„± í¬í•¨
                npc_description = f"{npc_info['name']}: {npc_info.get('description', 'A philosopher with unique perspectives')}"
                
                # Custom NPCì¸ ê²½ìš° ì¶”ê°€ íŠ¹ì„± í¬í•¨
                if npc_info.get('is_custom', False):
                    # ì¶”ê°€ íŠ¹ì„±ì´ ìˆìœ¼ë©´ ì„¤ëª…ì— ì¶”ê°€
                    additional_traits = []
                    
                    if npc_info.get('voice_style'):
                        additional_traits.append(f"Voice style: {npc_info['voice_style']}")
                    
                    if npc_info.get('debate_approach'):
                        additional_traits.append(f"Debate approach: {npc_info['debate_approach']}")
                    
                    if npc_info.get('communication_style'):
                        additional_traits.append(f"Communication style: {npc_info['communication_style']}")
                    
                    # íŠ¹ì„±ì´ ìˆìœ¼ë©´ ì„¤ëª…ì— ì¶”ê°€
                    if additional_traits:
                        traits_text = "; ".join(additional_traits)
                        npc_description += f". {traits_text}"
                        logger.info(f"ğŸ“£ Custom NPC ì¶”ê°€ íŠ¹ì„± í¬í•¨: {traits_text}")
                
                # ë©”ì‹œì§€ ìƒì„± - ëŒ€í™” ê¸°ë¡ ë°˜ì˜
                logger.info(f"Generating philosophical response for {npc_info['name']} on topic: {current_topic}")
                logger.debug(f"ì´ì „ ëŒ€í™” ê¸¸ì´: {len(dialogue_history)} ë¬¸ì")
                logger.info(f"ğŸ“£ NPC ì„¤ëª…: {npc_description}")
                try:
                    response_text, _ = llm_manager.generate_philosophical_response(
                        npc_description=npc_description,
                        topic=current_topic,
                        context="",
                        previous_dialogue=dialogue_history  # ì´ì „ ë©”ì‹œì§€ ê¸°ë¡ ì „ë‹¬
                    )
                    logger.debug(f"LLMì—ì„œ ìƒì„±ëœ ì‘ë‹µ: {response_text[:100]}...")
                except Exception as llm_err:
                    logger.error(f"LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(llm_err)}")
                    # ë‹¤ìŒ ì‚¬ì´í´ë¡œ ë„˜ì–´ê°
                    await asyncio.sleep(5)
                    continue
                
                # ì‘ë‹µ ë©”ì‹œì§€ êµ¬ì„± - ë” ë§ì€ NPC ì •ë³´ í¬í•¨
                message_id = f"auto-{uuid4().hex[:8]}"
                message = {
                    "id": message_id,
                    "text": response_text,
                    "sender": responding_npc_id,  # senderë¥¼ NPC IDë¡œ ì„¤ì •í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆê²Œ í•¨
                    "senderName": npc_info.get('name', responding_npc_id.capitalize()),  # ì¶”ê°€: NPC ì´ë¦„
                    "senderType": "npc",  # ì¶”ê°€: ë°œì‹ ì íƒ€ì…
                    "isUser": False,
                    "timestamp": datetime.now().isoformat(),
                    "portrait_url": npc_info.get('portrait_url', None),  # ì¶”ê°€: í”„ë¡œí•„ ì´ë¯¸ì§€ URL
                    "npc_id": responding_npc_id  # ì¶”ê°€: NPC ID ëª…ì‹œì  í¬í•¨
                }
                
                logger.info(f"ğŸ“£ ìµœì¢… ë©”ì‹œì§€ ê°ì²´: {message}")
                logger.info(f"Generated message for {message['senderName']} in room {room_id}")
                logger.info(f"Message: {message['text'][:100]}...")
                
                # ëŒ€í™” ê¸°ë¡ì— ìƒˆ ë©”ì‹œì§€ ì¶”ê°€
                dialogue_history += f"{message['senderName']}: {message['text']}\n\n"
                
                # Next.js APIë¥¼ í†µí•´ ë©”ì‹œì§€ ì €ì¥ ë° ë¸Œë¡œë“œìºìŠ¤íŠ¸
                nextjs_api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
                logger.info(f"Sending message to Next.js API at {nextjs_api_url}/api/rooms")
                
                try:
                    # ë©”ì‹œì§€ ì €ì¥ ìš”ì²­
                    async with aiohttp.ClientSession() as session:
                        # ë¡œê·¸ì— URLê³¼ payload ë‚´ìš©ì„ ìì„¸íˆ ì¶œë ¥
                        request_payload = {
                            "message": message
                        }
                        # URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ room_id ì „ë‹¬
                        request_url = f"{nextjs_api_url}/api/rooms?id={room_id}"
                        logger.info(f"Sending to Next.js API - URL: {request_url}")
                        logger.debug(f"ì „ì²´ Payload: {request_payload}")
                        
                        api_response = await session.put(
                            request_url,
                            json=request_payload,
                            headers={
                                "Content-Type": "application/json"
                            }
                        )
                        
                        # ì‘ë‹µ í™•ì¸
                        status_code = api_response.status
                        logger.info(f"Response status code: {status_code}")
                        
                        response_text = await api_response.text()
                        logger.debug(f"Next.js API ì‘ë‹µ ì „ì²´: {response_text}")
                        
                        if status_code == 200:
                            try:
                                response_data = await api_response.json()
                                success = response_data.get('success', False)
                                logger.info(f"Message successfully saved to DB: {success}")
                                
                                # ì„±ê³µ ì—¬ë¶€ë¥¼ ëª…í™•í•˜ê²Œ ì¶œë ¥
                                if success:
                                    logger.info(f"âœ… ë©”ì‹œì§€ ì €ì¥ ì„±ê³µ - ID: {message['id']}, ë°œì‹ ì: {message['senderName']}")
                                else:
                                    logger.warning(f"âš ï¸ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨ - ID: {message['id']}, ë°œì‹ ì: {message['senderName']}")
                            except Exception as json_err:
                                logger.error(f"ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {str(json_err)}")
                                success = False
                            
                            # ì„±ê³µ ì‘ë‹µì¼ ê²½ìš° WebSocket ì—°ê²°ì„ ìœ„í•œ ì¶”ê°€ ìš”ì²­ (WebSocket ì´ë²¤íŠ¸ ë°œìƒì„ ìœ„í•´)
                            try:
                                # ë©”ì‹œì§€ê°€ ì €ì¥ë˜ì—ˆìœ¼ë‹ˆ ì†Œì¼“ ì„œë²„ì— ì•Œë¦¼
                                socket_data = {
                                    "action": "broadcast",
                                    "room": room_id,
                                    "event": "new-message",
                                    "data": {
                                        "roomId": room_id,
                                        "message": message
                                    }
                                }
                                logger.debug(f"ì†Œì¼“ API ìš”ì²­ í˜ì´ë¡œë“œ: {socket_data}")
                                
                                socket_notify_response = await session.post(
                                    f"{nextjs_api_url}/api/socket",
                                    json=socket_data,
                                    headers={
                                        "Content-Type": "application/json"
                                    }
                                )
                                socket_status = socket_notify_response.status
                                socket_text = await socket_notify_response.text()
                                logger.info(f"Socket notification status: {socket_status}")
                                
                                try:
                                    socket_data = json.loads(socket_text)
                                    socket_success = socket_data.get('success', False)
                                    logger.info(f"Socket broadcast success: {socket_success}")
                                    
                                    if socket_success:
                                        logger.info(f"âœ… ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì„±ê³µ - ë©”ì‹œì§€ ID: {message['id']}")
                                    else:
                                        logger.warning(f"âš ï¸ ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨ - ë©”ì‹œì§€ ID: {message['id']}")
                                except:
                                    logger.debug(f"Socket ì‘ë‹µ ì „ì²´: {socket_text}")
                            except Exception as socket_err:
                                logger.error(f"Error notifying socket server: {str(socket_err)}", exc_info=True)
                        else:
                            error_text = await api_response.text()
                            logger.error(f"Failed to save message to DB. Status: {status_code}, Error: {error_text}")
                except Exception as e:
                    logger.error(f"Error sending message to Next.js API: {str(e)}", exc_info=True)
                
                # ë©”ì‹œì§€ ì¹´ìš´íŠ¸ ì¦ê°€
                message_count += 1
                
                # ë‹¤ìŒ ë©”ì‹œì§€ ëŒ€ê¸° ì‹œê°„ (ê¸°ë³¸ê°’: 15-25ì´ˆ ëœë¤)
                wait_time = random.randint(min_delay, max_delay)
                logger.info(f"Waiting {wait_time} seconds before next message")
                
                # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì‹œê°„ ì—…ë°ì´íŠ¸
                if room_id in active_auto_conversations:
                    active_auto_conversations[room_id]["last_message_time"] = time.time()
                
                # ëŒ€ê¸° - ì‚¬ì´ì— active ìƒíƒœê°€ ë³€ê²½ë˜ë©´ ì¦‰ì‹œ ì¢…ë£Œ
                for i in range(wait_time):
                    if not active_auto_conversations.get(room_id, {}).get("active", False):
                        logger.debug(f"ëŒ€ê¸° ì¤‘ active ìƒíƒœ ë³€ê²½ìœ¼ë¡œ ë£¨í”„ ì¢…ë£Œ")
                        break
                    if i % 5 == 0:  # 5ì´ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
                        logger.debug(f"ëŒ€ê¸° ì¤‘... {i}/{wait_time}ì´ˆ")
                    await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"Error in auto conversation cycle: {str(e)}", exc_info=True)
                # ì—ëŸ¬ ë°œìƒ ì‹œ 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
                await asyncio.sleep(5)
        
        # ë£¨í”„ ì¢…ë£Œ í›„ ì •ë¦¬
        if room_id in active_auto_conversations:
            logger.info(f"Auto conversation loop completed for room {room_id} after {message_count} messages")
            # ë£¨í”„ê°€ ì™„ë£Œë˜ë©´ ìƒíƒœì—ì„œ ì œê±°
            del active_auto_conversations[room_id]
            
    except Exception as e:
        logger.exception(f"Unexpected error in auto conversation loop: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒíƒœì—ì„œ ì œê±°
        if room_id in active_auto_conversations:
            del active_auto_conversations[room_id]

# WebSocket ì—”ë“œí¬ì¸íŠ¸
@app.websocket("/ws/{room_id}")
async def websocket_endpoint(websocket: WebSocket, room_id: str):
    await manager.connect(websocket, room_id)
    try:
        while True:
            data = await websocket.receive_json()
            logger.info(f"Received WebSocket message: {data}")
            
            if "command" in data:
                if data["command"] == "start_auto":
                    # ìë™ ëŒ€í™” ì‹œì‘
                    npcs = data.get("npcs", [])
                    topic = data.get("topic", "")
                    
                    if len(npcs) < 2:
                        await websocket.send_json({
                            "type": "error",
                            "message": "At least 2 NPCs are required for auto conversation"
                        })
                    else:
                        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ì§€
                        manager.stop_auto_conversation(room_id)
                        
                        # ìƒˆ íƒœìŠ¤í¬ ì‹œì‘
                        task = asyncio.create_task(
                            auto_conversation_loop(room_id, npcs, topic)
                        )
                        manager.start_auto_conversation(room_id, task)
                        
                elif data["command"] == "stop_auto":
                    # ìë™ ëŒ€í™” ì¤‘ì§€
                    if manager.stop_auto_conversation(room_id):
                        await websocket.send_json({
                            "type": "auto_conversation_status",
                            "status": "stopped",
                            "room_id": room_id
                        })
                    else:
                        await websocket.send_json({
                            "type": "error",
                            "message": "No active auto conversation to stop"
                        })
                        
            elif "message" in data:
                # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë³´ë‚¸ ì¼ë°˜ ë©”ì‹œì§€ ì²˜ë¦¬ (í•„ìš”ì‹œ êµ¬í˜„)
                pass
                
    except WebSocketDisconnect:
        await manager.disconnect(websocket, room_id)
    except Exception as e:
        logger.exception(f"Error in WebSocket connection: {str(e)}")
        try:
            await manager.disconnect(websocket, room_id)
        except:
            pass

# ë‹¤ìŒ NPC ì„ íƒ ë„ìš°ë¯¸ í•¨ìˆ˜
def select_next_npc(npcs: List[str], last_speaker: str = None) -> str:
    """
    ëŒ€í™”ì—ì„œ ì‘ë‹µí•  ë‹¤ìŒ NPC ì„ íƒ
    
    Args:
        npcs: ê°€ëŠ¥í•œ NPC ëª©ë¡
        last_speaker: ì´ì „ ë©”ì‹œì§€ ë°œì‹ ì (ìˆìœ¼ë©´)
    
    Returns:
        ì„ íƒëœ NPC ID
    """
    if not npcs:
        raise ValueError("No NPCs available")
    
    # ì´ì „ ë°œì‹ ìê°€ ì—†ìœ¼ë©´ ëœë¤ ì„ íƒ
    if not last_speaker:
        return random.choice(npcs)
    
    # ì´ì „ ë°œì‹ ìê°€ ì•„ë‹Œ NPC ì¤‘ì—ì„œ ì„ íƒ
    available_npcs = [npc for npc in npcs if last_speaker not in npc]
    if available_npcs:
        return random.choice(available_npcs)
    
    # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ì²« ë²ˆì§¸ NPC ë°˜í™˜
    return npcs[0]

@app.get("/")
def read_root():
    return {"message": "Welcome to Sapiens Engine API"}

@app.get("/api/philosophers")
async def get_philosophers():
    """ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ ì² í•™ì ëª©ë¡ ë°˜í™˜"""
    philosophers_list = []
    
    # YAML íŒŒì¼ì—ì„œ ë¡œë“œí•œ ì² í•™ì ì •ë³´ ì‚¬ìš©
    if philosophers_data:
        for key, data in philosophers_data.items():
            # build item with portrait_url
            portrait_url = None
            if key in PORTRAITS_MAP:
                portrait_url = f"http://localhost:8000/portraits/{PORTRAITS_MAP[key]}"
            item = {
                "id": key,
                "name": data.get("name", "Unknown"),
                "period": data.get("period", ""),
                "nationality": data.get("nationality", "")
            }
            if portrait_url:
                item["portrait_url"] = portrait_url
            philosophers_list.append(item)
    else:
        # YAML íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´ ì‚¬ìš©
        for key, description in philosopher_descriptions.items():
            name = description.split(' was ')[0]
            philosophers_list.append({
                "id": key,
                "name": name
            })
    
    return {
        "philosophers": philosophers_list
    }

@app.get("/api/philosophers/{philosopher_id}")
async def get_philosopher_details(philosopher_id: str):
    """íŠ¹ì • ì² í•™ìì˜ ì„¸ë¶€ ì •ë³´ ë°˜í™˜"""
    philosopher_id = philosopher_id.lower()
    
    # YAML íŒŒì¼ì—ì„œ ì² í•™ì ì •ë³´ ì°¾ê¸°
    if philosopher_id in philosophers_data:
        data = philosophers_data[philosopher_id]
        # portrait_url ì¶”ê°€
        portrait_url = None
        if philosopher_id in PORTRAITS_MAP:
            portrait_url = f"http://localhost:8000/portraits/{PORTRAITS_MAP[philosopher_id]}"
        response = { "id": philosopher_id, **data }
        if portrait_url:
            response["portrait_url"] = portrait_url
        return response
        
    # ê¸°ë³¸ ì •ë³´ì—ì„œ ì°¾ê¸°
    if philosopher_id in philosopher_descriptions:
        description = philosopher_descriptions[philosopher_id]
        name = description.split(' was ')[0]
        response = {
            "id": philosopher_id,
            "name": name,
            "description": description
        }
        if philosopher_id in PORTRAITS_MAP:
            response["portrait_url"] = f"http://localhost:8000/portraits/{PORTRAITS_MAP[philosopher_id]}"
        return response
        
    # ì² í•™ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
    raise HTTPException(status_code=404, detail=f"Philosopher '{philosopher_id}' not found")

@app.post("/api/chat/initial", response_model=ChatResponse)
async def create_initial_chat(request: InitialChatRequest):
    try:
        logger.info(f"Received initial chat request: {request}")
        
        # ìš”ì²­í•œ ì² í•™ì ê²€ìƒ‰
        philosopher = request.philosopher.lower()
        
        # ì² í•™ì ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        if philosopher in philosopher_descriptions:
            philosopher_description = philosopher_descriptions[philosopher]
        else:
            # ê¸°ë³¸ ì„¤ëª… ìƒì„±
            logger.warning(f"Philosopher {philosopher} not found in configuration")
            philosopher_description = f"{request.philosopher} is a philosopher interested in various philosophical topics."
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        user_message = ""
        if request.user_message:
            user_message = f"User: {request.user_message}\n"
        
        # ì‘ë‹µ ìƒì„±
        response_text, metadata = llm_manager.generate_philosophical_response(
            npc_description=philosopher_description,
            topic=request.topic,
            context=request.context,
            previous_dialogue=user_message
        )
        
        return ChatResponse(
            response=response_text,
            philosopher=request.philosopher,
            metadata=metadata
        )
    
    except Exception as e:
        logger.exception(f"Error generating initial chat response: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/portraits/generate")
async def generate_portrait(request: PortraitRequest):
    """Generate NPC portrait via OpenAI and save to static portraits folder"""
    try:
        # ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ ìœ„í•œ ì°¸ì¡° ì´ë¯¸ì§€ URL ìƒì„±
        style_image_urls = []
        for ph in request.reference_philosophers:
            pid = ph.lower()
            if pid in PORTRAITS_MAP:
                style_image_urls.append(f"http://localhost:8000/portraits/{PORTRAITS_MAP[pid]}")
        style_refs_text = ""
        if style_image_urls:
            style_refs_text = " Use the following reference images for style: " + ", ".join(style_image_urls) + "."

        # ë¹Œë“œí•  í”„ë¡¬í”„íŠ¸: ê³ ì •ëœ ìŠ¤íƒ€ì¼ & ì² í•™ì ì–¼êµ´ ì™„ì „ ë³‘í•©, ìŒì„± ìŠ¤íƒ€ì¼(í‘œì •) ë°˜ì˜
        ref_urls = ", ".join(style_image_urls)
        const_style = "A sepia-toned charcoal portrait (chest-up), fine pencil texture on vintage paper background, soft diffuse lighting, rich warm tones."
        philosophers = ", ".join(request.reference_philosophers)
        
        # ë” ëª…í™•í•œ ë¸”ë Œë”© ì§€ì‹œì‚¬í•­
        blend_text = f"""Create ONE SINGLE FICTIONAL FACE that is a perfect 50/50 hybrid fusion between 
        {philosophers}. Do not show multiple separate individuals or different faces. 
        Create ONE new imaginary person with merged facial features from both philosophers."""
        
        # í‘œì • ì§€ì‹œì‚¬í•­
        render_text = f"This merged character should have an expression/demeanor that shows: {request.voice_style}"
        
        prompt = (
            f"{const_style} {blend_text} {render_text} "
            f"The portrait should be of ONE person named {request.npc_name}, not multiple people. "
            f"Generate a square (1024x1024 pixels) high-quality PNG portrait. "
            "Provide a PNG without any text or overlays."
        )
        # OpenAI ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ with explicit model (using new openai-python v1.0 interface)
        response = openai.images.generate(
            model="dall-e-3",
            prompt=prompt,
            n=1,
            size="1024x1024"
        )
        image_url = response.data[0].url
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        img_bytes = requests.get(image_url).content
        # íŒŒì¼ëª… ìƒì„±
        filename = f"{slugify(request.npc_name)}_{int(time.time())}.png"
        filepath = os.path.join(PORTRAITS_DIR, filename)
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
        with open(filepath, 'wb') as img_file:
            img_file.write(img_bytes)
        
        # íŒŒì¼ ì €ì¥ ê²€ì¦
        if os.path.exists(filepath):
            file_size = os.path.getsize(filepath)
            logger.info(f"Image saved successfully: {filepath} ({file_size} bytes)")
        else:
            logger.error(f"Failed to save image: {filepath}")
            raise HTTPException(status_code=500, detail="Failed to save generated image")
        
        # ë°˜í™˜í•  URL (ì ˆëŒ€ ê²½ë¡œë¡œ ë³€ê²½)
        return { 'url': f"http://localhost:8000/portraits/{filename}" }
    except Exception as e:
        logger.exception(f"Error generating portrait: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/npc/create")
async def create_npc(request: NpcCreateRequest):
    """Stub NPC creation endpoint: returns generated ID to Next.js"""
    new_id = str(uuid4())
    return { "id": new_id }

@app.post("/api/chat/generate")
async def generate_chat_response(request: ChatGenerateRequest):
    """ëŒ€í™” ë§¥ë½ì— ë”°ë¥¸ ì² í•™ì ì‘ë‹µ ìƒì„±"""
    try:
        logger.info(f"Received chat generate request: topic={request.topic}, npcs={request.npcs}")
        logger.info(f"Using LLM provider: {request.llm_provider}, model: {request.llm_model}")
        
        # API í‚¤ê°€ ì œê³µëœ ê²½ìš° ì„ì‹œë¡œ ì„¤ì •
        original_api_key = None
        if request.api_key:
            logger.info("Using API key provided by client")
            original_api_key = os.environ.get("OPENAI_API_KEY")
            os.environ["OPENAI_API_KEY"] = request.api_key
            openai.api_key = request.api_key
        
        try:
            # ì°¸ì—¬í•˜ëŠ” NPCë“¤ ì¤‘ì—ì„œ ì‘ë‹µí•  NPC ì„ íƒ
            # í˜„ì¬ëŠ” ê°„ë‹¨í•˜ê²Œ ì²« ë²ˆì§¸ ë˜ëŠ” ëŒ€í™” ë‚´ìš©ì— ì–¸ê¸‰ëœ NPCë¥¼ ì„ íƒ
            # ë” ë³µì¡í•œ ì „ëµì„ êµ¬í˜„í•  ìˆ˜ ìˆìŒ
            responding_philosopher = select_responding_philosopher(request.npcs, request.previous_dialogue)
            logger.info(f"Selected responding philosopher: {responding_philosopher}")
            
            # NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            npc_info = await get_npc_details(responding_philosopher)
            logger.info(f"Retrieved NPC info: {npc_info.get('name', 'Unknown')}")
            
            # NPC ì„¤ëª… êµ¬ì„± (ì œê³µëœ ì„¤ëª… ë˜ëŠ” ê¸°ë³¸ ì„¤ëª…)
            npc_description = f"{npc_info['name']}: {npc_info.get('description', 'A philosopher with unique perspectives')}"
            
            # Custom NPCì¸ ê²½ìš° ì¶”ê°€ íŠ¹ì„± í¬í•¨
            if npc_info.get('is_custom', False):
                # ì¶”ê°€ íŠ¹ì„±ì´ ìˆìœ¼ë©´ ì„¤ëª…ì— ì¶”ê°€
                additional_traits = []
                
                if npc_info.get('voice_style'):
                    additional_traits.append(f"Voice style: {npc_info['voice_style']}")
                
                if npc_info.get('debate_approach'):
                    additional_traits.append(f"Debate approach: {npc_info['debate_approach']}")
                
                if npc_info.get('communication_style'):
                    additional_traits.append(f"Communication style: {npc_info['communication_style']}")
                
                # íŠ¹ì„±ì´ ìˆìœ¼ë©´ ì„¤ëª…ì— ì¶”ê°€
                if additional_traits:
                    traits_text = "; ".join(additional_traits)
                    npc_description += f". {traits_text}"
                    logger.info(f"ğŸ“£ Custom NPC ì¶”ê°€ íŠ¹ì„± í¬í•¨: {traits_text}")
            
            logger.info(f"Using NPC description: {npc_description[:150]}...")
            
            # llm_managerë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
            response_text, metadata = llm_manager.generate_philosophical_response(
                npc_description=npc_description,
                topic=request.topic,
                context=request.context,
                previous_dialogue=request.previous_dialogue,
                llm_provider=request.llm_provider,
                llm_model=request.llm_model
            )
            
            return {
                "response": response_text,
                "philosopher": responding_philosopher,
                "metadata": metadata
            }
        finally:
            # ì›ë˜ API í‚¤ ë³µì›
            if original_api_key is not None:
                os.environ["OPENAI_API_KEY"] = original_api_key
                openai.api_key = original_api_key
    
    except Exception as e:
        logger.exception(f"Error generating chat response: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

def select_responding_philosopher(npcs: List[str], previous_dialogue: str) -> str:
    """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•˜ì—¬ ì‘ë‹µí•  ì² í•™ìë¥¼ ì„ íƒ"""
    if not npcs:
        raise ValueError("No philosophers available to respond")
    
    # ê°„ë‹¨í•œ ì‘ë‹µ ì² í•™ì ì„ íƒ ë¡œì§:
    # 1. ì´ì „ ëŒ€í™”ì—ì„œ íŠ¹ì • ì² í•™ìê°€ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
    # 2. ì–¸ê¸‰ëœ ì² í•™ìê°€ ì°¸ì—¬ ì² í•™ì ëª©ë¡ì— ìˆìœ¼ë©´ í•´ë‹¹ ì² í•™ì ì„ íƒ
    # 3. ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì² í•™ì ì„ íƒ
    
    # ëŒ€í™”ì—ì„œ ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸°
    user_messages = [line for line in previous_dialogue.split('\n') if line.startswith('User:')]
    if user_messages:
        last_user_message = user_messages[-1].replace('User:', '').strip().lower()
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ì— ì–¸ê¸‰ëœ ì² í•™ì ì°¾ê¸°
        for philosopher in npcs:
            if philosopher.lower() in last_user_message:
                logger.info(f"User mentioned philosopher: {philosopher}")
                return philosopher
    
    # ì–¸ê¸‰ëœ ì² í•™ìê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì² í•™ì ì„ íƒ
    return npcs[0]

@app.get("/api/npc/get")
async def get_npc_details(id: str):
    try:
        # ë¹ˆ ID ê²€ì¦
        if not id:
            logger.warning("No NPC ID provided")
            return {"error": "NPC ID is required"}
            
        logger.info(f"Fetching NPC details for ID: {id}")
        
        # ìºì‹œì—ì„œ í™•ì¸
        cache_key = f"npc:{id}"
        current_time = time.time()
        if cache_key in npc_cache and (current_time - npc_cache[cache_key]['timestamp'] < npc_cache_ttl):
            logger.info(f"ğŸ” Cache hit: NPC {id} found in cache")
            return npc_cache[cache_key]['data']
        
        # MongoDB ObjectID í˜•ì‹ ê°ì§€
        is_mongo_id = len(id) == 24 and all(c in '0123456789abcdefABCDEF' for c in id)
        is_uuid = len(id) > 30 and id.count('-') >= 4
        
        # Custom NPC (MongoDB ID ë˜ëŠ” UUID)ì¸ ê²½ìš° Next.js APIì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        if is_mongo_id or is_uuid:
            logger.info(f"ID {id} appears to be a custom NPC (MongoDB or UUID)")
            
            try:
                # Next.js APIì—ì„œ NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ì¼ê´€ëœ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
                nextjs_api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
                custom_npc_url = f"{nextjs_api_url}/api/npc/get?id={id}"
                logger.info(f"ğŸ” Fetching custom NPC info from Next.js API: {custom_npc_url}")
                
                async with aiohttp.ClientSession() as session:
                    async with session.get(custom_npc_url) as response:
                        status_code = response.status
                        logger.info(f"ğŸ“Š API Response status: {status_code}")
                        
                        if response.status == 200:
                            npc_data = await response.json()
                            logger.info(f"âœ… Retrieved custom NPC data: {npc_data.get('name', 'Unknown')}")
                            logger.debug(f"ğŸ“‹ Complete NPC data: {npc_data}")
                            
                            # í•„ìš”í•œ í•„ë“œ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
                            portrait_url = npc_data.get('portrait_url')
                            logger.info(f"ğŸ–¼ï¸ Portrait URL: {portrait_url}")
                            
                            # ì‘ë‹µ êµ¬ì„±
                            response_data = {
                                "id": id,
                                "name": npc_data.get('name', f"Philosopher {id[:6]}"),
                                "description": npc_data.get('description', "A philosopher with unique perspectives"),
                                "key_concepts": npc_data.get('key_concepts', []),
                                "portrait_url": portrait_url,
                                "is_custom": True,
                                # ì¶”ê°€ ì •ë³´ (í”„ë¡¬í”„íŠ¸ì— í•„ìš”í•œ íŠ¹ì„±)
                                "voice_style": npc_data.get('voice_style', ""),
                                "debate_approach": npc_data.get('debate_approach', ""),
                                "communication_style": npc_data.get('communication_style', "")
                            }
                            
                            # ìºì‹œì— ì €ì¥
                            npc_cache[cache_key] = {
                                'data': response_data,
                                'timestamp': current_time
                            }
                            
                            logger.info(f"ğŸ”„ Returning and caching custom NPC data for {response_data['name']}")
                            return response_data
                        else:
                            # API ì˜¤ë¥˜ ì‹œ ë¡œê¹… í›„ ê¸°ë³¸ê°’ ì‚¬ìš©
                            error_text = await response.text()
                            logger.warning(f"âŒ Failed to get custom NPC from API: {error_text}")
                            
                            # ì¼ë°˜ì ì¸ 404 ì˜¤ë¥˜ë©´ ë‹¤ë¥¸ ì—”ë“œí¬ì¸íŠ¸ë„ ì‹œë„
                            if response.status == 404:
                                logger.info(f"ğŸ” Trying alternative API endpoint for custom NPC")
                                # ëŒ€ì²´ URL - MongoDB IDë¡œ ì§ì ‘ ì¿¼ë¦¬
                                alt_url = f"{nextjs_api_url}/api/npc/get-by-backend-id?id={id}"
                                logger.info(f"ğŸ” Trying alternative API endpoint: {alt_url}")
                                
                                async with session.get(alt_url) as alt_response:
                                    if alt_response.status == 200:
                                        npc_data = await alt_response.json()
                                        logger.info(f"âœ… Retrieved custom NPC data from alternative endpoint: {npc_data.get('name', 'Unknown')}")
                                        
                                        # ì‘ë‹µ êµ¬ì„±
                                        response_data = {
                                            "id": id,
                                            "name": npc_data.get('name', f"Philosopher {id[:6]}"),
                                            "description": npc_data.get('description', "A philosopher with unique perspectives"),
                                            "key_concepts": npc_data.get('key_concepts', []),
                                            "portrait_url": npc_data.get('portrait_url'),
                                            "is_custom": True,
                                            "voice_style": npc_data.get('voice_style', ""),
                                            "debate_approach": npc_data.get('debate_approach', ""),
                                            "communication_style": npc_data.get('communication_style', "")
                                        }
                                        
                                        # ìºì‹œì— ì €ì¥
                                        npc_cache[cache_key] = {
                                            'data': response_data,
                                            'timestamp': current_time
                                        }
                                        
                                        logger.info(f"ğŸ”„ Returning and caching custom NPC data from alternative source: {response_data['name']}")
                                        return response_data
            except Exception as api_err:
                logger.error(f"âŒâŒ Error fetching custom NPC from API: {str(api_err)}")
            
            # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì •ë³´ ì œê³µ
            # ì´ë¦„ì„ ê¸°ì¤€ìœ¼ë¡œ ê³ ìœ í•œ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•  ìˆ˜ ìˆê²Œ í•¨
            hash_value = sum(ord(c) for c in id) % 5  # ê°„ë‹¨í•œ í•´ì‹œ í•¨ìˆ˜
            
            philosopher_images = ["Aristotle.png", "Nietzsche.png", "Descartes.png", 
                                 "Confucius.png", "Wittgenstein.png"]
            
            selected_image = philosopher_images[hash_value]
            portrait_url = f"http://localhost:8000/portraits/{selected_image}"
            
            logger.info(f"ğŸ”„ Using default portrait for custom NPC: {portrait_url}")
            
            fallback_data = {
                "id": id,
                "name": f"Philosopher {id[:6]}",
                "description": "A philosopher with unique perspectives and ideas",
                "key_concepts": ["Unique", "Custom", "Personal"],
                "portrait_url": portrait_url,
                "is_custom": True
            }
            
            # í´ë°± ë°ì´í„°ë„ ìºì‹œì— ì €ì¥ (ì§§ì€ TTL ì ìš©)
            short_ttl = 60 * 5  # 5ë¶„
            npc_cache[cache_key] = {
                'data': fallback_data,
                'timestamp': current_time - npc_cache_ttl + short_ttl
            }
            
            logger.info(f"ğŸ”„ Returning fallback data for custom NPC: {fallback_data['name']}")
            return fallback_data

        # ê¸°ë³¸ ì² í•™ìì¸ ê²½ìš°
        philosopher_id = id.lower()
        logger.info(f"Looking up philosopher with ID: {philosopher_id}")
        
        # YAML íŒŒì¼ì—ì„œ ì² í•™ì ì •ë³´ ì°¾ê¸°
        if philosopher_id in philosophers_data:
            data = philosophers_data[philosopher_id]
            logger.info(f"Found philosopher {philosopher_id} in YAML data")
            
            # portrait_url ì¶”ê°€
            portrait_url = None
            if philosopher_id in PORTRAITS_MAP:
                portrait_url = f"http://localhost:8000/portraits/{PORTRAITS_MAP[philosopher_id]}"
                
            response_data = {
                "id": philosopher_id,
                "name": data.get("name", "Unknown"),
                "description": data.get("description", ""),
                "key_concepts": data.get("key_concepts", []),
                "portrait_url": portrait_url,
                "is_custom": False
            }
            
            # ìºì‹œì— ì €ì¥
            npc_cache[cache_key] = {
                'data': response_data,
                'timestamp': current_time
            }
            
            logger.info(f"ğŸ”„ Returning and caching YAML data for philosopher: {response_data['name']}")
            return response_data
        # ê¸°ë³¸ ì •ë³´ì—ì„œ ì°¾ê¸°
        elif philosopher_id in philosopher_descriptions:
            description = philosopher_descriptions[philosopher_id]
            name = description.split(' was ')[0]
            logger.info(f"Found philosopher {philosopher_id} in hardcoded descriptions")
            
            portrait_url = None
            if philosopher_id in PORTRAITS_MAP:
                portrait_url = f"http://localhost:8000/portraits/{PORTRAITS_MAP[philosopher_id]}"
            
            response_data = {
                "id": philosopher_id,
                "name": name,
                "description": description,
                "portrait_url": portrait_url,
                "is_custom": False
            }
            
            # ìºì‹œì— ì €ì¥
            npc_cache[cache_key] = {
                'data': response_data,
                'timestamp': current_time
            }
            
            logger.info(f"ğŸ”„ Returning and caching hardcoded data for philosopher: {response_data['name']}")
            return response_data
        
        # NPCë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        logger.warning(f"NPC with ID '{id}' not found")
        # 404 ëŒ€ì‹  ê¸°ë³¸ ì •ë³´ ì œê³µ (í´ë°± ë©”ì»¤ë‹ˆì¦˜)
        fallback_data = {
            "id": id,
            "name": id.capitalize(),
            "description": "A philosopher with unique perspectives",
            "is_custom": False
        }
        
        # í´ë°± ë°ì´í„°ëŠ” ì§§ì€ ìœ íš¨ ì‹œê°„ìœ¼ë¡œ ìºì‹œ
        short_ttl = 60 * 5  # 5ë¶„
        npc_cache[cache_key] = {
            'data': fallback_data,
            'timestamp': current_time - npc_cache_ttl + short_ttl
        }
        
        logger.info(f"ğŸ”„ Returning fallback data for unknown philosopher: {fallback_data['name']}")
        return fallback_data
    except Exception as e:
        logger.exception(f"Error retrieving NPC: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ì •ë³´ ì œê³µ
        fallback_data = {
            "id": id,
            "name": id.capitalize(),
            "description": "Information temporarily unavailable",
            "is_custom": False
        }
        logger.info(f"ğŸ”„ Returning error fallback data: {fallback_data['name']}")
        return fallback_data

# ì±„íŒ…ë°© ìƒì„± ë° ì´ˆê¸° ë©”ì‹œì§€ ìƒì„±ì„ í†µí•©í•œ ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/rooms")
async def create_chat_room(request: ChatRoomCreationRequest):
    try:
        logger.info(f"Received room creation request: {request.title}")
        logger.info(f"Generate initial message: {request.generateInitialMessage}")
        logger.info(f"NPCs: {request.npcs}")
        logger.info(f"LLM Provider: {request.llmProvider}, Model: {request.llmModel}")
        
        # 1. ì±„íŒ…ë°© ìƒì„± - ê¸°ì¡´ ë¡œì§ ìœ ì§€
        # ê³ ìœ  ID ìƒì„±
        new_room_id = str(uuid4())
        logger.info(f"Generated new room ID: {new_room_id}")
        
        # ì±„íŒ…ë°© ê°ì²´ ìƒì„±
        new_room = {
            "id": new_room_id,
            "title": request.title,
            "context": request.context,
            "participants": {
                "users": [request.currentUser] if request.currentUser else [],
                "npcs": request.npcs
            },
            "totalParticipants": len(request.npcs) + (1 if request.currentUser else 0),
            "lastActivity": datetime.now().isoformat(),
            "isPublic": request.isPublic
        }
        
        # 2. ì´ˆê¸° ë©”ì‹œì§€ ìƒì„± ë¡œì§ ê°œì„  (í†µí•©)
        initial_message = None
        if request.generateInitialMessage and request.npcs and len(request.npcs) > 0:
            logger.info(f"Generating initial message for room {new_room_id}")
            first_npc_id = request.npcs[0]
            logger.info(f"Using first NPC: {first_npc_id}")
            
            try:
                # NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                npc_info = await get_npc_details(first_npc_id)
                logger.info(f"Retrieved NPC info: {npc_info['name']}")
                
                # ì² í•™ì ì„¤ëª… êµ¬ì„±
                npc_description = f"{npc_info['name']}: {npc_info['description']}"
                logger.info(f"Generated NPC description: {npc_description[:100]}...")
                
                # LLM ì„¤ì • ë””ë²„ê¹…
                logger.info(f"OpenAI API key exists: {bool(os.environ.get('OPENAI_API_KEY'))}")
                logger.info(f"Using LLM provider: {request.llmProvider}")
                logger.info(f"Using LLM model: {request.llmModel}")
                
                # ì´ˆê¸° ë©”ì‹œì§€ ìƒì„± - ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
                initial_message = ""
                max_retries = 3
                retry_count = 0
                
                while not initial_message and retry_count < max_retries:
                    try:
                        # ì´ˆê¸° ë©”ì‹œì§€ ìƒì„±
                        logger.info(f"[ATTEMPT {retry_count + 1}] Calling generate_philosophical_response with provider={request.llmProvider}, model={request.llmModel}")
                        
                        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
                        start_time = time.time()
                        initial_message_result, metadata = llm_manager.generate_philosophical_response(
                            npc_description=npc_description,
                            topic=request.title,
                            context=request.context or "",
                            llm_provider=request.llmProvider,
                            llm_model=request.llmModel
                        )
                        # ì†Œìš” ì‹œê°„ ê³„ì‚°
                        elapsed_time = time.time() - start_time
                        logger.info(f"LLM generation took {elapsed_time:.2f} seconds")
                        
                        # ì‘ë‹µ ë¡œê¹…
                        logger.info(f"LLM response (raw):\n{initial_message_result}")
                        logger.info(f"LLM metadata: {metadata}")
                        
                        # Trim the initial message
                        initial_message = initial_message_result.strip() if initial_message_result else ""
                        
                        # ë¹ˆ ë©”ì‹œì§€ ê²€ì¦
                        if not initial_message:
                            logger.warning(f"Empty message generated, retrying ({retry_count + 1}/{max_retries})")
                            retry_count += 1
                            # ë‹¤ìŒ ì‹œë„ ì „ ì§§ì€ ì§€ì—°
                            time.sleep(0.5)
                            continue
                        
                        # "Welcome to" ë©”ì‹œì§€ í•„í„°ë§
                        if initial_message.lower().startswith("welcome to"):
                            logger.warning(f"'Welcome to' message generated, retrying ({retry_count + 1}/{max_retries})")
                            retry_count += 1
                            initial_message = ""
                            continue
                            
                        logger.info(f"Successfully generated message: {initial_message[:100]}...")
                            
                    except Exception as e:
                        logger.error(f"Error in message generation attempt {retry_count + 1}: {str(e)}", exc_info=True)
                        retry_count += 1
                        time.sleep(0.5)
                
                # ìœ íš¨í•œ ë©”ì‹œì§€ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if initial_message:
                    # ë©”ì‹œì§€ ID ìƒì„±
                    message_id = f"welcome-{int(time.time())}"
                    
                    # ë©”ì‹œì§€ ê°ì²´ ìƒì„±
                    message_obj = {
                        "id": message_id,
                        "text": initial_message,
                        "sender": npc_info['name'],
                        "isUser": False,
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    # ì‘ë‹µì— ì´ˆê¸° ë©”ì‹œì§€ í¬í•¨
                    new_room["initial_message"] = message_obj
                    logger.info(f"Initial message generated for room {new_room_id} from {npc_info['name']}: {initial_message[:100]}...")
                else:
                    logger.warning(f"Failed to generate valid initial message after {max_retries} attempts")
                    # ëŒ€ì²´ ë©”ì‹œì§€ ìƒì„± (ì •ì )
                    fallback_questions = [
                        f"I find this topic of \"{request.title}\" quite fascinating. What aspects of it interest you the most?",
                        f"Let us explore \"{request.title}\" together. What questions come to mind when you consider this subject?",
                        f"The question of \"{request.title}\" has intrigued philosophers for centuries. Where shall we begin our inquiry?",
                        f"I've spent much time contemplating \"{request.title}\". What is your perspective on this matter?",
                        f"To understand \"{request.title}\", we must first examine our assumptions. What do you believe to be true about this subject?"
                    ]
                    
                    # ëœë¤ ì§ˆë¬¸ ì„ íƒ
                    fallback_message = random.choice(fallback_questions)
                    
                    message_obj = {
                        "id": f"welcome-{int(time.time())}",
                        "text": fallback_message,
                        "sender": npc_info['name'],
                        "isUser": False,
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    new_room["initial_message"] = message_obj
                    logger.info(f"Using fallback message for room {new_room_id} from {npc_info['name']}: {fallback_message}")
            except Exception as e:
                logger.exception(f"Error generating initial message: {str(e)}")
                # ì´ˆê¸° ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ìƒì„±
                try:
                    # ì‘ê¸‰ ìƒí™©ì—ì„œë„ ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì•¼ í•¨
                    default_npc_name = request.npcs[0].capitalize() if request.npcs else "Philosopher"
                    fallback_message = f"I find this topic of \"{request.title}\" intriguing. What are your thoughts on it?"
                    
                    message_obj = {
                        "id": f"welcome-{int(time.time())}",
                        "text": fallback_message,
                        "sender": default_npc_name,
                        "isUser": False,
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    new_room["initial_message"] = message_obj
                    logger.info(f"Using emergency fallback message for room {new_room_id} from {default_npc_name}")
                    logger.info(f"Room {new_room_id} has initial message from: {request.npcs[0]}")
                except Exception as final_err:
                    logger.critical(f"Unable to create any initial message: {str(final_err)}")
        
        # ì´ˆê¸° ë©”ì‹œì§€ ìœ ë¬´ ìµœì¢… í™•ì¸
        if "initial_message" in new_room:
            logger.info(f"Room {new_room_id} has initial message from: {new_room['initial_message']['sender']}")
        else:
            logger.warning(f"Room {new_room_id} has NO initial message")
        
        logger.info(f"Returning new room with ID: {new_room_id}")
        return new_room
    except Exception as e:
        logger.exception(f"Error creating chat room: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# NPC ê°„ ìë™ ëŒ€í™” ìƒì„± API
@app.post("/api/dialogue/generate")
async def generate_dialogue(request: DialogueGenerateRequest):
    try:
        logger.info(f"Received dialogue generation request for topic: {request.topic}")
        logger.info(f"Participants: {request.participants}")
        logger.info(f"Rounds: {request.rounds}")
        
        # ì°¸ì—¬ì ê²€ì¦ (ìµœì†Œ 2ëª… ì´ìƒ)
        if len(request.participants) < 2:
            logger.warning("At least 2 participants are required for dialogue")
            return {"error": "At least 2 participants are required"}
            
        # NPC ì •ë³´ ë¡œë“œ
        npc_descriptions = []
        for npc_id in request.participants:
            try:
                npc_info = await get_npc_details(npc_id)
                npc_description = f"{npc_info['name']}: {npc_info['description']}"
                npc_descriptions.append({
                    "id": npc_id,
                    "name": npc_info['name'],
                    "description": npc_description
                })
                logger.info(f"Loaded NPC {npc_info['name']} for dialogue")
            except Exception as e:
                logger.error(f"Error loading NPC {npc_id}: {str(e)}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì„¤ëª… ì¶”ê°€
                npc_descriptions.append({
                    "id": npc_id,
                    "name": npc_id.capitalize(),
                    "description": f"{npc_id.capitalize()}: A philosopher with unique perspectives"
                })
        
        # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
        dialogue_history = ""
        all_exchanges = []
        
        # NPCë“¤ ê°„ì˜ ëŒ€í™” ìƒì„±
        for round_num in range(request.rounds):
            logger.info(f"Generating dialogue round {round_num + 1}/{request.rounds}")
            
            # ê° ë¼ìš´ë“œë§ˆë‹¤ 2ëª…ì˜ NPCë¥¼ ì„ íƒí•˜ì—¬ ëŒ€í™” ì§„í–‰
            idx1 = round_num % len(npc_descriptions)
            idx2 = (round_num + 1) % len(npc_descriptions)
            npc1 = npc_descriptions[idx1]
            npc2 = npc_descriptions[idx2]
            
            logger.info(f"NPC exchange: {npc1['name']} <-> {npc2['name']}")
            
            # LLMì— ëŒ€í™” ìƒì„± ìš”ì²­
            start_time = time.time()
            dialogue_result = llm_manager.generate_dialogue_exchange(
                npc1_description=npc1['description'],
                npc2_description=npc2['description'],
                topic=request.topic,
                previous_dialogue=dialogue_history,
                source_materials=None,
                user_contexts=None
            )
            elapsed_time = time.time() - start_time
            logger.info(f"Dialogue exchange generated in {elapsed_time:.2f} seconds")
            
            # ìƒì„±ëœ ëŒ€í™” ì²˜ë¦¬
            exchanges = dialogue_result.get("exchanges", [])
            if exchanges:
                logger.info(f"Generated {len(exchanges)} dialogue exchanges")
                for exchange in exchanges:
                    # ëŒ€í™” ë‚´ìš© ì¶”ê°€
                    all_exchanges.append(exchange)
                    # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸
                    dialogue_history += f"\n{exchange['speaker']}: {exchange['content']}"
            else:
                logger.warning("No dialogue exchanges generated in this round")
            
        # ê²°ê³¼ ë°˜í™˜
        logger.info(f"Completed dialogue generation with {len(all_exchanges)} total exchanges")
        return {
            "topic": request.topic,
            "participants": [npc['name'] for npc in npc_descriptions],
            "rounds": request.rounds,
            "exchanges": all_exchanges,
            "raw_dialogue": dialogue_history.strip(),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.exception(f"Error in dialogue generation: {str(e)}")
        return {"error": f"Failed to generate dialogue: {str(e)}"}

# ì„œë²„ ì‹¤í–‰ (ë…ë¦½ ì‹¤í–‰ ì‹œ)
if __name__ == "__main__":
    uvicorn.run("api_server:app", host="0.0.0.0", port=8000, reload=True)