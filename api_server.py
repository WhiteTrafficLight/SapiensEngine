# api_server.py ìˆ˜ì •
from fastapi import FastAPI, Depends, HTTPException, Request, WebSocket, WebSocketDisconnect, BackgroundTasks, Body, status, Form, File, UploadFile
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from typing import List, Dict, Optional, Any, Union
import asyncio
import os
import json
import time
import logging
import uuid
import random  # ëœë¤ ì„ íƒì„ ìœ„í•œ import ì¶”ê°€
from datetime import datetime
from pydantic import BaseModel
from typing import Optional, List, Dict, Any, Union, Set
import uvicorn
import yaml
from fastapi.staticfiles import StaticFiles
import openai
import requests
from slugify import slugify
import aiohttp
from uuid import uuid4
from types import SimpleNamespace
import re

# Sapiens Engine ì„í¬íŠ¸
from sapiens_engine.core.llm_manager import LLMManager
from sapiens_engine.core.config_loader import ConfigLoader

# tiktoken ì¶”ê°€ - í† í° ê³„ì‚°ìš©
try:
    import tiktoken
except ImportError:
    logger.warning("tiktoken íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¼ì‚¬ì¹˜ í† í° ê³„ì‚°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# YAML íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_yaml_file(file_path):
    """YAML íŒŒì¼ì„ ë¡œë“œ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return yaml.safe_load(file)
    except Exception as e:
        logger.error(f"Error loading YAML file {file_path}: {e}")
        return {}

# ì² í•™ì ì •ë³´ ë¡œë“œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PHILOSOPHERS_FILE = os.path.join(BASE_DIR, "sapiens_engine/config/philosophers.yaml")
logger.info(f"Loading philosophers from: {PHILOSOPHERS_FILE}")
philosophers_data = load_yaml_file(PHILOSOPHERS_FILE)
if not philosophers_data:
    logger.warning("Failed to load philosophers data. Using hardcoded descriptions.")

# ì² í•™ì ì´ˆìƒí™” ë§¤í•‘
PORTRAITS_MAP = {
    "socrates": "Socrates.png",
    "plato": "Plato.png",
    "aristotle": "Aristotle.png",
    "kant": "Kant.png",
    "nietzsche": "Nietzsche.png",
    "hegel": "Hegel.png",
    "marx": "Marx.png",
    "sartre": "Sartre.png",
    "camus": "Camus.png",
    "beauvoir": "Beauvoir.png",
    "rousseau": "Rousseau.png",
    "confucius": "Confucius.png",
    "laozi": "Laozi.png",
    "buddha": "Buddha.png",
    "wittgenstein": "Wittgenstein.png"
}

# ìš”ì²­ ëª¨ë¸ ì •ì˜
class InitialChatRequest(BaseModel):
    philosopher: str
    topic: str
    context: Optional[str] = ""
    user_message: Optional[str] = None

# ì±„íŒ…ë°© ìƒì„± ìš”ì²­ ëª¨ë¸ ì¶”ê°€
class ChatRoomCreationRequest(BaseModel):
    title: str
    context: Optional[str] = ""
    contextUrl: Optional[str] = None
    contextFileContent: Optional[str] = None
    maxParticipants: int
    npcs: List[str]
    isPublic: Optional[bool] = True
    currentUser: Optional[str] = None
    # ìƒˆ í•„ë“œ ì¶”ê°€
    generateInitialMessage: Optional[bool] = True
    llmProvider: Optional[str] = "openai"
    llmModel: Optional[str] = "gpt-4o"
    dialogueType: Optional[str] = "free"
    npcPositions: Optional[Dict[str, str]] = None  # ì°¬ë°˜í† ë¡  ì…ì¥ ì •ë³´ (pro/con)

# ëŒ€í™” ìƒì„± ìš”ì²­ ëª¨ë¸ ì¶”ê°€
class ChatGenerateRequest(BaseModel):
    npc_descriptions: Optional[str] = None
    npcs: Optional[List[str]] = []  # í•„ìˆ˜ í•„ë“œë¥¼ Optionalë¡œ ì„¤ì •
    room_id: str  # ë£¸ ID í•„ë“œ ì¶”ê°€
    user_message: str  # ì‚¬ìš©ì ë©”ì‹œì§€ í•„ë“œ ì¶”ê°€
    topic: Optional[str] = ""
    context: Optional[str] = ""
    previous_dialogue: Optional[str] = ""  # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
    llm_provider: Optional[str] = "openai"
    llm_model: Optional[str] = "gpt-4o"
    api_key: Optional[str] = None
    use_rag: Optional[bool] = False  # RAG ì‚¬ìš© ì—¬ë¶€ í”Œë˜ê·¸ ì¶”ê°€

# ì‘ë‹µ ëª¨ë¸ ì •ì˜
class ChatResponse(BaseModel):
    response: str
    philosopher: str
    metadata: Optional[Dict[str, Any]] = None

# Portrait generation request model
class PortraitRequest(BaseModel):
    npc_name: str
    role: str
    reference_philosophers: List[str]
    voice_style: str  # include user-specified voice style for expression

# NPC ìƒì„± ìš”ì²­ ëª¨ë¸ ë° ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
class NpcCreateRequest(BaseModel):
    name: str
    role: str
    voice_style: str
    reference_philosophers: List[str]
    communication_style: str
    debate_approach: str
    created_by: str
    created_at: str

# NPC ê°„ ìë™ ëŒ€í™” ìƒì„±ì„ ìœ„í•œ ìš”ì²­ í´ë˜ìŠ¤
class DialogueGenerateRequest(BaseModel):
    participants: List[str]  # NPC ID ëª©ë¡
    topic: str
    rounds: Optional[int] = 3  # ëŒ€í™” ë¼ìš´ë“œ ìˆ˜
    context: Optional[str] = ""  # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸

# ìë™ ëŒ€í™” ìš”ì²­ ëª¨ë¸
class AutoConversationRequest(BaseModel):
    room_id: str
    npcs: List[str]
    topic: Optional[str] = ""
    delay_range: Optional[List[int]] = [15, 25]

# ìë™ ëŒ€í™” ì‘ë‹µ ëª¨ë¸
class AutoConversationResponse(BaseModel):
    status: str
    room_id: str
    message: Optional[str] = None

# ìë™ ëŒ€í™” í™œì„±í™” ìƒíƒœ ì¶”ì  (ì„œë²„ ë©”ëª¨ë¦¬ì— ì €ì¥)
active_auto_conversations = {}

# íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€í•  ì „ì—­ ìºì‹œ ë³€ìˆ˜
# NPC ìºì‹œ ì„¤ì •
npc_cache = {}  # IDë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ëŠ” ìºì‹œ ë”•ì…”ë„ˆë¦¬
npc_cache_ttl = 60 * 10  # ìºì‹œ ìœ íš¨ ì‹œê°„: 10ë¶„

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="Sapiens Engine API")

# í™˜ê²½ ì„¤ì • ì¶œë ¥
nextjs_api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
logger.info(f"===== ì‹œìŠ¤í…œ í™˜ê²½ ì„¤ì • =====")
logger.info(f"NEXTJS_API_URL: {nextjs_api_url}")
logger.info(f"OPENAI_API_KEY: {'ì„¤ì •ë¨' if os.environ.get('OPENAI_API_KEY') else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
logger.info(f"DEBUG ëª¨ë“œ: {logging.getLogger().level == logging.DEBUG}")
logger.info(f"==================")

# CORS ì„¤ì • (AgoraMind ì›¹ ì•±ì—ì„œ ì ‘ê·¼ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” êµ¬ì²´ì ì¸ ì˜¤ë¦¬ì§„ìœ¼ë¡œ ë³€ê²½
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë ‰í† ë¦¬ ê²½ë¡œ ë””ë²„ê¹…
logger.info(f"Current directory: {os.getcwd()}")
logger.info(f"BASE_DIR: {BASE_DIR}")
logger.info(f"Files in current directory: {os.listdir('.')}")

# /portraits ê²½ë¡œë¡œ ì´ˆìƒí™” ì •ì  íŒŒì¼ ì„œë¹„ìŠ¤ - ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
PORTRAITS_DIR = os.path.join(os.getcwd(), "portraits")
logger.info(f"Portrait directory path: {PORTRAITS_DIR}")
if os.path.isdir(PORTRAITS_DIR):
    app.mount("/portraits", StaticFiles(directory=PORTRAITS_DIR), name="portraits")
    logger.info(f"Mounted portraits from {PORTRAITS_DIR} at /portraits")
else:
    logger.error(f"!!! Portraits directory not found: {PORTRAITS_DIR}")
    # ì˜¤ë¥˜ ë°œìƒ í›„ ì„œë²„ ì¢…ë£Œ
    logger.error("Portrait directory not found - cannot serve images")

# LLM ë§¤ë‹ˆì € ì´ˆê¸°í™”
config_loader = ConfigLoader()
llm_manager = LLMManager(config_loader)

# ì² í•™ì ì„¤ëª… ì‚¬ì „ (NPC í´ë˜ìŠ¤ ëŒ€ì‹  ì§ì ‘ ì •ì˜)
philosopher_descriptions = {
    "socrates": "Socrates was an Ancient Greek philosopher known for the Socratic method of questioning, seeking wisdom through dialogue, and the phrase 'I know that I know nothing'. His style is to ask probing questions, challenge assumptions, and use irony. Key concepts include: Socratic method, Examined life, Intellectual humility, Ethical inquiry, Dialectic.",
    "plato": "Plato was an Ancient Greek philosopher, student of Socrates, and founder of the Academy. Known for his theory of Forms, belief in objective truths, and political philosophy. His style is dialectical, making references to eternal ideals and using allegories to illustrate points. Key concepts include: Theory of Forms, The Good, The Republic, The soul, Philosopher-kings.",
    "aristotle": "Aristotle was an Ancient Greek philosopher, student of Plato, and tutor to Alexander the Great. Known for empiricism, virtue ethics, and systematic classification of knowledge. His style is methodical, analytical, and balanced, focusing on practical wisdom and the middle path. Key concepts include: Golden mean, Four causes, Virtue ethics, Eudaimonia, Practical wisdom.",
    "kant": "Kant was an 18th century German philosopher known for his work on ethics, metaphysics, epistemology, and aesthetics. His style is formal, structured, and precise, using technical terminology and emphasizing universal moral principles. Key concepts include: Categorical imperative, Duty, Phenomena vs. noumena, Synthetic a priori, Transcendental idealism.",
    "nietzsche": "Nietzsche was a 19th century German philosopher known for his critique of morality, religion, and contemporary culture. His style is bold, provocative, and poetic, using aphorisms and metaphors to challenge conventional wisdom. Key concepts include: Will to power, Eternal recurrence, Ãœbermensch, Master-slave morality, Perspectivism.",
    "sartre": "Sartre was a 20th century French existentialist philosopher and writer who emphasized freedom, responsibility, and authenticity in human existence. His style is direct, challenging, and focused on concrete human situations. Key concepts include: Existence precedes essence, Radical freedom, Bad faith, Being-for-itself, Authenticity.",
    "camus": "Camus was a 20th century French philosopher associated with absurdism who explored how to find meaning in an indifferent universe. His style is philosophical yet accessible, using literary references and everyday examples. Key concepts include: The Absurd, Revolt, Sisyphus, Philosophical suicide, Authentic living.",
    "simone de beauvoir": "Simone de Beauvoir was a 20th century French philosopher and feminist theorist who explored ethics, politics, and the social construction of gender. Her style connects abstract concepts to lived experiences, especially regarding gender and social relationships. Key concepts include: Situated freedom, The Other, Woman as Other, Ethics of ambiguity, Reciprocal recognition.",
    "marx": "Marx was a 19th century German philosopher, economist, and political theorist who developed historical materialism and critiqued capitalism. His style is analytical and critical, focusing on material conditions and class relations. Key concepts include: Historical materialism, Class struggle, Alienation, Commodity fetishism, Dialectical materialism.",
    "rousseau": "Rousseau was an 18th century Genevan philosopher of the Enlightenment known for his work on political philosophy, education, and human nature. His style combines passionate rhetoric with systematic analysis, appealing to natural human qualities. Key concepts include: Natural state, General will, Social contract, Noble savage, Authentic self."
}

# OpenAI API key
openai.api_key = os.environ.get("OPENAI_API_KEY")

# WebSocket ì—°ê²° ê´€ë¦¬ì
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, List[WebSocket]] = {}
        self.auto_conversation_tasks: Dict[str, asyncio.Task] = {}
    
    async def connect(self, websocket: WebSocket, room_id: str):
        await websocket.accept()
        if room_id not in self.active_connections:
            self.active_connections[room_id] = []
        self.active_connections[room_id].append(websocket)
        logger.info(f"WebSocket connection established for room {room_id}")
    
    async def disconnect(self, websocket: WebSocket, room_id: str):
        if room_id in self.active_connections:
            try:
                self.active_connections[room_id].remove(websocket)
                if not self.active_connections[room_id]:
                    del self.active_connections[room_id]
                logger.info(f"WebSocket connection closed for room {room_id}")
            except ValueError:
                logger.warning(f"WebSocket not found in connections for room {room_id}")
    
    async def broadcast(self, message: dict, room_id: str):
        if room_id in self.active_connections:
            disconnected_ws = []
            for connection in self.active_connections[room_id]:
                try:
                    await connection.send_json(message)
                except RuntimeError as e:
                    logger.error(f"Error broadcasting to client: {str(e)}")
                    disconnected_ws.append(connection)
            
            # ì—°ê²° ì¢…ë£Œëœ ì›¹ì†Œì¼“ ì •ë¦¬
            for ws in disconnected_ws:
                await self.disconnect(ws, room_id)
    
    def start_auto_conversation(self, room_id: str, task: asyncio.Task):
        self.auto_conversation_tasks[room_id] = task
        logger.info(f"Started auto conversation for room {room_id}")
    
    def stop_auto_conversation(self, room_id: str):
        if room_id in self.auto_conversation_tasks:
            if not self.auto_conversation_tasks[room_id].done():
                self.auto_conversation_tasks[room_id].cancel()
            del self.auto_conversation_tasks[room_id]
            logger.info(f"Stopped auto conversation for room {room_id}")
            return True
        return False

# ConnectionManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
manager = ConnectionManager()

# ì±„íŒ… ë©”ì‹œì§€ë¥¼ Next.js APIë¥¼ í†µí•´ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
async def save_message_to_db(room_id: str, message: dict):
    try:
        # Next.js API í˜¸ì¶œí•˜ì—¬ ë©”ì‹œì§€ ì €ì¥
        async with aiohttp.ClientSession() as session:
            # API ì—”ë“œí¬ì¸íŠ¸ URL (ì‹¤ì œ URLë¡œ ë³€ê²½ í•„ìš”)
            api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
            # URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ room_id ì „ë‹¬ 
            url = f"{api_url}/api/rooms?id={room_id}"
            
            # ë””ë²„ê¹…: ì €ì¥ ì „ ë©”ì‹œì§€ êµ¬ì¡° ì¶œë ¥
            logger.info(f"ğŸ§ª MongoDB ì €ì¥ ì „ message ê°ì²´ í‚¤: {list(message.keys())}")
            logger.info(f"ğŸ§ª citations í‚¤ ì¡´ì¬: {'citations' in message}")
            
            if 'citations' in message:
                logger.info(f"ğŸ§ª citations íƒ€ì…: {type(message['citations'])}")
                logger.info(f"ğŸ§ª citations ë‚´ìš©: {json.dumps(message['citations'])[:500]}...")
            
            # ë©”ì‹œì§€ ë°ì´í„° ì¤€ë¹„
            payload = {
                "message": message
            }
            
            # API í˜¸ì¶œ ì§ì „ í˜ì´ë¡œë“œ í™•ì¸
            logger.info(f"ğŸ§ª API í˜¸ì¶œ í˜ì´ë¡œë“œ: {json.dumps(payload)[:1000]}...")
            
            # API í˜¸ì¶œ
            async with session.put(url, json=payload) as response:
                if response.status == 200:
                    logger.info(f"âœ… Message saved to database for room {room_id}: {message['id']}")
                    
                    # ì‘ë‹µ í™•ì¸
                    try:
                        response_data = await response.json()
                        logger.info(f"ğŸ§ª MongoDB ì €ì¥ ì‘ë‹µ: {json.dumps(response_data)}")
                    except:
                        response_text = await response.text()
                        logger.info(f"ğŸ§ª MongoDB ì €ì¥ ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text[:500]}")
                    
                    return True
                else:
                    error_text = await response.text()
                    logger.error(f"âŒ Failed to save message: Status {response.status}, Error: {error_text}")
                    return False
    except Exception as e:
        logger.error(f"âŒ Error saving message to database: {str(e)}")
        return False

# ì±„íŒ…ë°© ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
async def get_room_messages(room_id: str, limit: int = 20):
    try:
        # Next.js API í˜¸ì¶œí•˜ì—¬ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        async with aiohttp.ClientSession() as session:
            # API ì—”ë“œí¬ì¸íŠ¸ URL (ì‹¤ì œ URLë¡œ ë³€ê²½ í•„ìš”)
            api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
            url = f"{api_url}/api/rooms?id={room_id}"
            
            # API í˜¸ì¶œ
            async with session.get(url) as response:
                if response.status == 200:
                    data = await response.json()
                    messages = data.get("messages", [])
                    
                    # ì œí•œëœ ìˆ˜ì˜ ìµœì‹  ë©”ì‹œì§€ë§Œ ë°˜í™˜
                    if len(messages) > limit:
                        messages = messages[-limit:]
                    
                    logger.info(f"Retrieved {len(messages)} messages for room {room_id}")
                    return messages
                else:
                    error_text = await response.text()
                    logger.error(f"Failed to get messages: {error_text}")
                    return []
    except Exception as e:
        logger.error(f"Error retrieving messages: {str(e)}")
        return []

# ì±„íŒ…ë°© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
async def get_room_data(room_id: str):
    try:
        # Next.js API í˜¸ì¶œí•˜ì—¬ ì±„íŒ…ë°© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        async with aiohttp.ClientSession() as session:
            api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
            url = f"{api_url}/api/rooms?id={room_id}"
            
            async with session.get(url) as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"Retrieved room data for {room_id}")
                    return data
                else:
                    error_text = await response.text()
                    logger.error(f"Failed to get room data: {error_text}")
                    return {}
    except Exception as e:
        logger.error(f"Error retrieving room data: {str(e)}")
        return {}

# ìë™ ëŒ€í™” ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/auto-conversation", response_model=AutoConversationResponse)
async def start_auto_conversation(request: AutoConversationRequest, background_tasks: BackgroundTasks):
    """ìë™ ëŒ€í™” ìƒì„± ì‹œì‘"""
    room_id = request.room_id
    
    # ì´ë¯¸ ìë™ ëŒ€í™”ê°€ í™œì„±í™”ëœ ì±„íŒ…ë°©ì¸ì§€ í™•ì¸
    if room_id in active_auto_conversations:
        # ì´ì „ íƒœìŠ¤í¬ ì¤‘ì§€
        active_auto_conversations[room_id]["active"] = False
        logger.info(f"Stopping existing auto conversation for room {room_id}")
        # ì¶©ë¶„í•œ ì‹œê°„ì„ ì£¼ì–´ íƒœìŠ¤í¬ê°€ ì¢…ë£Œë˜ë„ë¡ í•¨
        await asyncio.sleep(1)
    
    # ìƒˆ ìë™ ëŒ€í™” ìƒíƒœ ì¶”ì  ì„¤ì •
    active_auto_conversations[room_id] = {
        "active": True,
        "npcs": request.npcs,
        "topic": request.topic,
        "delay_range": request.delay_range,
        "last_message_time": time.time()
    }
    
    # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ìë™ ëŒ€í™” ë£¨í”„ ì‹œì‘
    background_tasks.add_task(
        auto_conversation_loop,
        room_id,
        request.npcs,
        request.topic,
        request.delay_range
    )
    
    logger.info(f"Started auto conversation for room {room_id} with {len(request.npcs)} NPCs")
    return {"status": "started", "room_id": room_id}

@app.delete("/api/auto-conversation", response_model=AutoConversationResponse)
async def stop_auto_conversation(room_id: str):
    """ìë™ ëŒ€í™” ìƒì„± ì¤‘ì§€ - Query parameterë¡œ room_idë¥¼ ë°›ìŒ"""
    logger.info(f"Stopping auto conversation for room {room_id}")
    
    # active_auto_conversations ìƒíƒœ ë””ë²„ê¹…
    logger.debug(f"í˜„ì¬ í™œì„± ëŒ€í™” ìƒíƒœ: {active_auto_conversations}")
    
    if room_id in active_auto_conversations:
        logger.info(f"í•´ë‹¹ ë°©ì˜ ìë™ ëŒ€í™” ì •ë³´: {active_auto_conversations[room_id]}")
        # active í”Œë˜ê·¸ë¥¼ Falseë¡œ ì„¤ì •
        active_auto_conversations[room_id]["active"] = False
        
        # active í”Œë˜ê·¸ ì„¤ì • ì§í›„ ìƒíƒœ í™•ì¸
        logger.info(f"active=False ì„¤ì • í›„ ìƒíƒœ: {active_auto_conversations[room_id]}")
        
        # ë°”ë¡œ ì‚­ì œí•˜ì§€ ì•Šê³  active í”Œë˜ê·¸ë§Œ ë”
        # ì´ë ‡ê²Œ í•˜ë©´ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì¢…ë£Œë¨
        logger.info(f"Stopped auto conversation for room {room_id}")
        return {"status": "stopped", "room_id": room_id}
    else:
        logger.warning(f"No active auto conversation found for room {room_id}")
        return {"status": "not_found", "room_id": room_id, "message": "No active auto conversation found"}

@app.get("/api/auto-conversation/status")
async def check_auto_conversation_status(room_id: str):
    """ìë™ ëŒ€í™” ìƒíƒœ í™•ì¸ - Query parameterë¡œ room_idë¥¼ ë°›ìŒ"""
    logger.info(f"Checking auto conversation status for room {room_id}")
    
    if room_id in active_auto_conversations:
        is_active = active_auto_conversations[room_id].get("active", False)
        logger.info(f"Room {room_id} auto conversation status: {'active' if is_active else 'inactive'}")
        return {
            "room_id": room_id,
            "active": is_active,
            "npcs": active_auto_conversations[room_id].get("npcs", []),
            "topic": active_auto_conversations[room_id].get("topic", "")
        }
    else:
        logger.info(f"Room {room_id} has no auto conversation record")
        return {"room_id": room_id, "active": False}

# ìë™ ëŒ€í™” ìƒì„± ë£¨í”„ í•¨ìˆ˜
async def auto_conversation_loop(room_id, current_topic, room_data, current_npcs):
    # ì´ˆê¸°í™”
    global active_auto_conversations
    
    # ì‹¤í–‰ ì¤‘ì¸ ëŒ€í™”ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
    if room_id not in active_auto_conversations:
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        active_auto_conversations[room_id] = {
            "running": True,
            "topic": current_topic,
            "last_user_interaction": time.time(),
            "dialogue_history": [],
            "user_question_pending": False
        }
    
    additional_context = ""
    if room_data.get("context"):
        additional_context = f"Additional context: {room_data['context']}"
    
    # ëŒ€í™” íŒ¨í„´ íƒ€ì… ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: free)
    dialogue_type = room_data.get("dialogueType", "free")
    
    logger.info(f"ğŸ­ ìë™ ëŒ€í™” ì‹œì‘: ë°© ID {room_id}, ì£¼ì œ: {current_topic}, ëŒ€í™” íŒ¨í„´: {dialogue_type}")
    
    # ëŒ€í™” íŒ¨í„´ì— ë”°ë¥¸ ì´ˆê¸°í™”
    if dialogue_type not in active_auto_conversations[room_id]:
        if dialogue_type == "debate":
            # ì°¬ë°˜í† ë¡ ì˜ ê²½ìš° ê° NPCì—ê²Œ ì°¬ì„±/ë°˜ëŒ€ ì…ì¥ í• ë‹¹
            active_auto_conversations[room_id]["debate_positions"] = {}
            
            # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ ì…ì¥ ì •ë³´ê°€ ìˆë‹¤ë©´ ì‚¬ìš©
            if "npcPositions" in room_data and room_data["npcPositions"]:
                logger.info(f"ğŸ­ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì „ë‹¬ëœ ì°¬ë°˜í† ë¡  í¬ì§€ì…˜ ì‚¬ìš©: {room_data['npcPositions']}")
                
                # ì…ì¥ ì •ë³´ë¥¼ debate_positionsë¡œ ë³µì‚¬
                for npc_id, position in room_data["npcPositions"].items():
                    if npc_id in current_npcs:
                        active_auto_conversations[room_id]["debate_positions"][npc_id] = position
                
                # ì…ì¥ì´ ì§€ì •ë˜ì§€ ì•Šì€ NPCê°€ ìˆë‹¤ë©´ ê¸°ë³¸ê°’ í• ë‹¹
                for npc in current_npcs:
                    if npc not in active_auto_conversations[room_id]["debate_positions"]:
                        # ë” ì ì€ ìª½ì— ë°°ì •
                        pro_count = list(active_auto_conversations[room_id]["debate_positions"].values()).count("pro")
                        con_count = list(active_auto_conversations[room_id]["debate_positions"].values()).count("con")
                        default_position = "pro" if pro_count <= con_count else "con"
                        active_auto_conversations[room_id]["debate_positions"][npc] = default_position
            else:
                # ê¸°ì¡´ ë¡œì§: ë²ˆê°ˆì•„ê°€ë©° ì°¬ì„±/ë°˜ëŒ€ ì…ì¥ í• ë‹¹
                positions = ["pro", "con"]
                position_idx = 0
                
                for npc in current_npcs:
                    active_auto_conversations[room_id]["debate_positions"][npc] = positions[position_idx % len(positions)]
                    position_idx += 1
                
            logger.info(f"ğŸ­ ì°¬ë°˜í† ë¡  í¬ì§€ì…˜ í• ë‹¹: {active_auto_conversations[room_id]['debate_positions']}")
            
        elif dialogue_type == "socratic":
            # ì†Œí¬ë¼í…ŒìŠ¤ì‹ ëŒ€í™”ì—ì„œëŠ” ì†Œí¬ë¼í…ŒìŠ¤ê°€ ì§ˆë¬¸ ì—­í• ì„ í•˜ë„ë¡ í•¨
            active_auto_conversations[room_id]["questioner"] = "socrates" if "socrates" in current_npcs else current_npcs[0]
            active_auto_conversations[room_id]["socratic_phase"] = "question"  # question, examination, refutation
            
        elif dialogue_type == "dialectical":
            # ë³€ì¦ë²•ì  ëŒ€í™” êµ¬ì¡° ì´ˆê¸°í™”
            active_auto_conversations[room_id]["dialectical_phase"] = "thesis"  # thesis, antithesis, synthesis
            active_auto_conversations[room_id]["thesis_npc"] = None
            active_auto_conversations[room_id]["antithesis_npc"] = None
    
    # ... ê¸°ì¡´ ì½”ë“œ ...
    
    try:
        while active_auto_conversations.get(room_id, {}).get("running", False):
            # ... ê¸°ì¡´ ì½”ë“œ ...
            
            # ì‘ë‹µí•  NPC ì„ íƒ - ëŒ€í™” íŒ¨í„´ì— ë”°ë¼ ë‹¬ë¼ì§
            responding_npc_id = None
            prompt_prefix = ""
            
            if dialogue_type == "free":
                # ììœ í† ë¡ : ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ ë¬´ì‘ìœ„ NPC ì„ íƒ (ë‹¤ë¥¸ ì¡°ê±´ ì¶©ì¡± ì‹œ)
                # ... ê¸°ì¡´ NPC ì„ íƒ ë¡œì§ ìœ ì§€ ...
                pass
                
            elif dialogue_type == "debate":
                # ì°¬ë°˜í† ë¡ : ì´ì „ ë°œì–¸ìì˜ ë°˜ëŒ€ ì…ì¥ì„ ê°€ì§„ NPC ì„ íƒ
                if active_auto_conversations[room_id]["dialogue_history"]:
                    last_npc = active_auto_conversations[room_id]["dialogue_history"][-1]["npc_id"]
                    last_position = active_auto_conversations[room_id]["debate_positions"].get(last_npc)
                    
                    # ë°˜ëŒ€ ì…ì¥ì˜ NPCë“¤ì„ ì°¾ìŒ
                    opposite_position = "con" if last_position == "pro" else "pro"
                    opposing_npcs = [
                        npc for npc in current_npcs 
                        if active_auto_conversations[room_id]["debate_positions"].get(npc) == opposite_position
                    ]
                    
                    if opposing_npcs:
                        responding_npc_id = random.choice(opposing_npcs)
                        position = active_auto_conversations[room_id]["debate_positions"].get(responding_npc_id)
                        prompt_prefix = f"You are taking the {position} position on this topic. Present a strong argument for your side in response to the previous speaker."
                    else:
                        # ì²« ë°œì–¸ì€ ì°¬ì„± ì¸¡ì—ì„œ ì‹œì‘
                        pro_npcs = [
                            npc for npc in current_npcs 
                            if active_auto_conversations[room_id]["debate_positions"].get(npc) == "pro"
                        ]
                        if pro_npcs:
                            responding_npc_id = random.choice(pro_npcs)
                            prompt_prefix = "You are taking the pro position on this topic. Present your initial thesis and arguments supporting it."
            
            elif dialogue_type == "socratic":
                # ì†Œí¬ë¼í…ŒìŠ¤ì‹ ëŒ€í™”: ì§ˆë¬¸ì(ëŒ€ê°œ ì†Œí¬ë¼í…ŒìŠ¤)ì™€ ì‘ë‹µì ê°„ ë²ˆê°ˆì•„ê°€ë©° ì§„í–‰
                questioner = active_auto_conversations[room_id]["questioner"]
                phase = active_auto_conversations[room_id]["socratic_phase"]
                
                if not active_auto_conversations[room_id]["dialogue_history"] or phase == "question":
                    # ëŒ€í™” ì‹œì‘ ë˜ëŠ” ì§ˆë¬¸ ë‹¨ê³„: ì§ˆë¬¸ìê°€ ë°œì–¸
                    responding_npc_id = questioner
                    prompt_prefix = "Ask a thought-provoking question that challenges assumptions about the topic."
                    active_auto_conversations[room_id]["socratic_phase"] = "examination"
                else:
                    # ê²€í†  ë‹¨ê³„: ì§ˆë¬¸ìê°€ ì•„ë‹Œ ë‹¤ë¥¸ NPCê°€ ì‘ë‹µ
                    available_npcs = [npc for npc in current_npcs if npc != questioner]
                    if available_npcs:
                        responding_npc_id = random.choice(available_npcs)
                        if phase == "examination":
                            prompt_prefix = "Respond to the question, but be aware you may need to defend your answer."
                            active_auto_conversations[room_id]["socratic_phase"] = "refutation"
                        else:  # refutation
                            prompt_prefix = "Reconsider your position in light of the critique."
                            active_auto_conversations[room_id]["socratic_phase"] = "question"
            
            elif dialogue_type == "dialectical":
                # ë³€ì¦ë²•ì  ëŒ€í™”: ì£¼ì¥(thesis) -> ë°˜ë¡ (antithesis) -> ì¢…í•©(synthesis)
                phase = active_auto_conversations[room_id]["dialectical_phase"]
                
                if phase == "thesis" or not active_auto_conversations[room_id]["thesis_npc"]:
                    # ì£¼ì¥ ë‹¨ê³„
                    responding_npc_id = random.choice(current_npcs)
                    active_auto_conversations[room_id]["thesis_npc"] = responding_npc_id
                    prompt_prefix = "Present your philosophical thesis on this topic."
                    active_auto_conversations[room_id]["dialectical_phase"] = "antithesis"
                    
                elif phase == "antithesis":
                    # ë°˜ë¡  ë‹¨ê³„: ì£¼ì¥í•œ NPCì™€ ë‹¤ë¥¸ NPCë¥¼ ì„ íƒ
                    thesis_npc = active_auto_conversations[room_id]["thesis_npc"]
                    available_npcs = [npc for npc in current_npcs if npc != thesis_npc]
                    if available_npcs:
                        responding_npc_id = random.choice(available_npcs)
                        active_auto_conversations[room_id]["antithesis_npc"] = responding_npc_id
                        prompt_prefix = "Challenge and present a counter-argument to the thesis presented earlier."
                        active_auto_conversations[room_id]["dialectical_phase"] = "synthesis"
                
                elif phase == "synthesis":
                    # ì¢…í•© ë‹¨ê³„: ì£¼ì¥, ë°˜ë¡  ì™¸ì˜ ë‹¤ë¥¸ NPC ë˜ëŠ” ì£¼ì¥/ë°˜ë¡  NPC ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ
                    thesis_npc = active_auto_conversations[room_id]["thesis_npc"]
                    antithesis_npc = active_auto_conversations[room_id]["antithesis_npc"]
                    
                    # ì¢…í•©ì€ ì œ3ì ë˜ëŠ” ì£¼ì¥/ë°˜ë¡  NPC ì¤‘ í•˜ë‚˜ê°€ ìˆ˜í–‰
                    synthesis_candidates = current_npcs
                    if len(current_npcs) > 2:  # ì¶©ë¶„í•œ NPCê°€ ìˆìœ¼ë©´ ì œ3ì ìš°ì„ 
                        synthesis_candidates = [npc for npc in current_npcs if npc != thesis_npc and npc != antithesis_npc]
                    
                    if synthesis_candidates:
                        responding_npc_id = random.choice(synthesis_candidates)
                        prompt_prefix = "Synthesize the thesis and antithesis into a more comprehensive understanding."
                        # ë‹¤ì‹œ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°
                        active_auto_conversations[room_id]["dialectical_phase"] = "thesis"
                        active_auto_conversations[room_id]["thesis_npc"] = None
                        active_auto_conversations[room_id]["antithesis_npc"] = None
            
            # ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ ëŒì•„ê° - responding_npc_idê°€ ì•„ì§ ì„ íƒë˜ì§€ ì•Šì•˜ë‹¤ë©´ ê¸°ë³¸ ì„ íƒ ë¡œì§ ìˆ˜í–‰
            if not responding_npc_id:
                # ... ê¸°ì¡´ NPC ì„ íƒ ë¡œì§ ...
                pass
                
            # NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            npc_info = {}
            for npc in philosophers_data:
                if npc["id"].lower() == responding_npc_id.lower():
                    npc_info = npc
                    break
            
            # ... ê¸°ì¡´ ì½”ë“œ ...
            
            # í”„ë¡¬í”„íŠ¸ì— ëŒ€í™” íŒ¨í„´ ê´€ë ¨ ì§€ì‹œ ì¶”ê°€
            if prompt_prefix:
                additional_context = f"{prompt_prefix}\n\n{additional_context}"
            
            # ... ê¸°ì¡´ ì½”ë“œ ...
            
            # "npc-selected" ì´ë²¤íŠ¸ ë°œì†¡ - ì´ë¯¸ êµ¬í˜„ëœ ë¶€ë¶„
            socket_manager.emit_to_room(
                room_id=str(room_id),
                event="npc-selected",
                data={"npc_id": responding_npc_id, "npc_name": npc_info.get("name", responding_npc_id)}
            )
            
            # ... ê¸°ì¡´ ì½”ë“œ ...
            
    except Exception as e:
        logger.error(f"ìë™ ëŒ€í™” ì˜¤ë¥˜: {str(e)}", exc_info=True)
        # ... ê¸°ì¡´ ì½”ë“œ ...

# WebSocket ì—”ë“œí¬ì¸íŠ¸
@app.websocket("/ws/{room_id}")
async def websocket_endpoint(websocket: WebSocket, room_id: str):
    await manager.connect(websocket, room_id)
    try:
        while True:
            data = await websocket.receive_json()
            logger.info(f"Received WebSocket message: {data}")
            
            if "command" in data:
                if data["command"] == "start_auto":
                    # ìë™ ëŒ€í™” ì‹œì‘
                    npcs = data.get("npcs", [])
                    topic = data.get("topic", "")
                    
                    if len(npcs) < 2:
                        await websocket.send_json({
                            "type": "error",
                            "message": "At least 2 NPCs are required for auto conversation"
                        })
                    else:
                        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ì§€
                        manager.stop_auto_conversation(room_id)
                        
                        # ìƒˆ ìë™ ëŒ€í™” ì‹œì‘
                        task = asyncio.create_task(
                            auto_conversation_loop(room_id, npcs, topic, [15, 30])
                        )
                        manager.start_auto_conversation(room_id, task)
                        
                        await websocket.send_json({
                            "type": "auto_dialogue_status",
                            "status": "started"
                        })
                elif data["command"] == "stop_auto":
                    # ìë™ ëŒ€í™” ì¤‘ì§€
                    stopped = manager.stop_auto_conversation(room_id)
                    await websocket.send_json({
                        "type": "auto_dialogue_status",
                        "status": "stopped" if stopped else "not_running"
                    })
            elif "type" in data and data["type"] == "send-message":
                # ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œ ë¡œê¹…
                logger.info(f"ğŸš¨ socket.id {websocket.client.port} send-message RAW data: {data}")
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                if "roomId" not in data or "message" not in data:
                    logger.error(f"Invalid message format: {data}")
                    continue
                
                # RAG ì‚¬ìš© ì—¬ë¶€ í•„ë“œ ì¶”ì¶œ
                use_rag = data.get("useRAG", False)
                logger.info(f"ğŸ” RAG ì‚¬ìš© ì—¬ë¶€(í´ë¼ì´ì–¸íŠ¸ ìš”ì²­): {'í™œì„±í™”' if use_rag else 'ë¹„í™œì„±í™”'}")
                
                message_data = data["message"]
                
                # ë©”ì‹œì§€ ë¡œê·¸
                logger.info(f"ğŸš¨ 'send-message' ì´ë²¤íŠ¸ ìˆ˜ì‹  - ë°© ID: {data['roomId']}, ë©”ì‹œì§€: {message_data}")
                
                try:
                    # DBì— ë©”ì‹œì§€ ì €ì¥
                    message_text = message_data.get("text", "")
                    logger.info(f"ğŸ’¾ MongoDBì— ë©”ì‹œì§€ ì €ì¥ ì¤‘: {message_text[:30]}...")
                    saved = await save_message_to_db(data["roomId"], message_data)
                    
                    if saved:
                        logger.info(f"âœ… ë©”ì‹œì§€ê°€ MongoDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        logger.error(f"âŒ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨")
                    
                    # ì±„íŒ…ë°©ì˜ ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì—ê²Œ ë©”ì‹œì§€ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                    # Remove/truncate some fields before broadcasting
                    broadcast_message = {
                        "id": message_data.get("id", f"msg-{time.time()}"),
                        "text": message_text[:1000] + "..." if len(message_text) > 1000 else message_text,
                        "sender": message_data.get("sender", "Unknown")
                    }
                    
                    # ë¸Œë¡œë“œìºìŠ¤íŠ¸
                    client_count = 0
                    logger.info(f"ğŸ“¢ ë©”ì‹œì§€ ë¸Œë¡œë“œìºìŠ¤íŠ¸ [ë°© {data['roomId']}]: {json.dumps(broadcast_message)}")
                    
                    if data["roomId"] in manager.active_connections:
                        client_count = len(manager.active_connections[data["roomId"]])
                    
                    logger.info(f"ğŸ“Š í˜„ì¬ ë°©({data['roomId']})ì— ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ ìˆ˜: {client_count}ëª…")
                    
                    # ë³¸ì¸ì„ ì œì™¸í•œ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë©”ì‹œì§€ ì „ì†¡
                    for connection in manager.active_connections.get(data["roomId"], []):
                        if connection != websocket:  # ë°œì‹ ìì—ê²ŒëŠ” ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì§€ ì•ŠìŒ
                            try:
                                await connection.send_json({
                                    "type": "new-message",
                                    "roomId": data["roomId"],
                                    "message": broadcast_message
                                })
                            except Exception as e:
                                logger.error(f"ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
                    
                    logger.info(f"âœ… ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì™„ë£Œ - ë°œì‹ ì ì œì™¸ ë°©ì†¡")
                    
                    # AI ì‘ë‹µ ìƒì„± ë¡œì§
                    logger.info(f"ğŸ¤– AI ì‘ë‹µ ìƒì„± ì¤‘... ë°© ID: {data['roomId']}")
                    
                    # ìë™ ëŒ€í™” ëª¨ë“œì¸ì§€ í™•ì¸
                    is_auto_mode = data["roomId"] in active_auto_conversations and active_auto_conversations[data["roomId"]].get("active", False)
                    logger.info(f"ğŸ” ìë™ ëŒ€í™” ëª¨ë“œ í™•ì¸ ê²°ê³¼: {'í™œì„±í™”ë¨' if is_auto_mode else 'ë¹„í™œì„±í™”ë¨'}")
                    
                    if not is_auto_mode:
                        logger.info(f"ğŸ” ìë™ ëŒ€í™” ëª¨ë“œ ë¹„í™œì„±í™” - AI API ìš”ì²­ ì‹œì‘ - ë°© ID: {data['roomId']}")
                        
                        # ë°© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        room_data = await get_room_data(data["roomId"])
                        
                        if not room_data or "participants" not in room_data:
                            logger.error(f"âŒ ë°© ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ: {data['roomId']}")
                            continue
                        
                        # NPC ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                        npcs = room_data.get("participants", {}).get("npcs", [])
                        
                        if not npcs:
                            logger.warning(f"âš ï¸ ë°©ì— NPCê°€ ì—†ìŒ: {data['roomId']}")
                            continue
                        
                        # ëŒ€í™” ì£¼ì œ ê°€ì ¸ì˜¤ê¸°
                        topic = room_data.get("title", "")
                        context = room_data.get("context", "")
                        
                        # ìµœê·¼ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
                        messages = await get_room_messages(data["roomId"])
                        
                        # AI ì‘ë‹µ ìš”ì²­ í˜ì´ë¡œë“œ êµ¬ì„±
                        logger.info(f"ğŸ” ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
                        
                        # ì‘ë‹µí•  ì² í•™ì ì„ íƒ
                        responding_philosopher = select_responding_philosopher(npcs, message_text)
                        logger.info(f"ğŸ¯ ì‘ë‹µí•  ì² í•™ì: {responding_philosopher}")
                        
                        # ì¹¸íŠ¸ì˜ ê²½ìš° ìë™ìœ¼ë¡œ RAG í™œì„±í™”
                        if responding_philosopher.lower() == 'kant':
                            use_rag = True
                            logger.info(f"ğŸ” ì¹¸íŠ¸ ì‘ë‹µì„ ìœ„í•´ RAG ìë™ í™œì„±í™”ë¨")
                            
                        api_payload = {
                            "room_id": data["roomId"],
                            "user_message": message_text,
                            "npcs": npcs,
                            "topic": topic,
                            "context": context,
                            "use_rag": use_rag  # ìˆ˜ì •ëœ RAG ì‚¬ìš© ì—¬ë¶€
                        }
                        
                        logger.info(f"ğŸ“¤ API ìš”ì²­ í˜ì´ë¡œë“œ: {json.dumps(api_payload)}")
                        
                        # Next.js API ì„œë²„ URL ê°€ì ¸ì˜¤ê¸°
                        api_url = os.environ.get("NEXT_PUBLIC_API_BASE_URL", "http://localhost:8000")
                        chat_api_url = f"{api_url}/api/chat/generate"
                        
                        logger.info(f"ğŸ”— Python API URL: {chat_api_url}")
                        
                        try:
                            # API í˜¸ì¶œ
                            async with aiohttp.ClientSession() as session:
                                async with session.post(chat_api_url, json=api_payload) as response:
                                    logger.info(f"ğŸ” Python API ì‘ë‹µ ìƒíƒœ: {response.status} {response.reason}")
                                    
                                    if response.status == 200:
                                        ai_response = await response.json()
                                        logger.info(f"ğŸ“¥ Python API ì‘ë‹µ ë°ì´í„°: {json.dumps(ai_response)[:200]}...")
                                        
                                        # AI ì‘ë‹µ ë©”ì‹œì§€ êµ¬ì„±
                                        ai_message = {
                                            "id": f"ai-{int(time.time() * 1000)}",
                                            "text": ai_response["response"],
                                            "sender": ai_response["philosopher"],
                                            "isUser": False,
                                            "timestamp": datetime.now().isoformat()
                                        }
                                        
                                        # ë””ë²„ê¹…ì„ ìœ„í•œ citations ìƒì„¸ ì •ë³´ ì¶œë ¥
                                        logger.info(f"ğŸ§ª AI ì‘ë‹µ ì›ë³¸: {json.dumps(ai_response)[:1000]}...")
                                        logger.info(f"ğŸ§ª AI ì‘ë‹µì— 'citations' í‚¤ ì¡´ì¬: {'citations' in ai_response}")
                                        if "citations" in ai_response:
                                            logger.info(f"ğŸ§ª citations íƒ€ì…: {type(ai_response['citations'])}")
                                            logger.info(f"ğŸ§ª citations ê°¯ìˆ˜: {len(ai_response['citations'])}")
                                            logger.info(f"ğŸ§ª ì²«ë²ˆì§¸ citation: {json.dumps(ai_response['citations'][0]) if ai_response['citations'] else 'none'}")
                                            
                                            # citations í•„ë“œê°€ ìˆìœ¼ë©´ ì¶”ê°€
                                            ai_message["citations"] = ai_response["citations"]
                                            logger.info(f"ğŸ“š AI ë©”ì‹œì§€ì— {len(ai_response['citations'])}ê°œì˜ ì¸ìš© ì •ë³´ í¬í•¨ë¨")
                                            logger.info(f"ğŸ§ª ai_message ê°ì²´: {json.dumps(ai_message)[:1000]}...")
                                        else:
                                            logger.warning("âš ï¸ AI ì‘ë‹µì— citations í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤!")
                                        
                                        # ë””ë²„ê¹…ìš© ë¡œê·¸ ì¶”ê°€
                                        logger.info(f"ğŸ“‹ ìµœì¢… AI ë©”ì‹œì§€ ê°ì²´: {json.dumps(ai_message)}")
                                        
                                        # MongoDBì— AI ë©”ì‹œì§€ ì €ì¥
                                        saved = await save_message_to_db(data["roomId"], ai_message)
                                        if saved:
                                            logger.info(f"âœ… AI ë©”ì‹œì§€({ai_message['id']})ê°€ MongoDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                        else:
                                            logger.error(f"âŒ AI ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨")
                                        
                                        # ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ AI ì‘ë‹µ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                                        logger.info(f"ğŸ“¢ AI ì‘ë‹µ ë¸Œë¡œë“œìºìŠ¤íŠ¸: {ai_message['text'][:100]}...")
                                        logger.debug(f"ğŸ“¢ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•  ë©”ì‹œì§€ ê°ì²´: {json.dumps(ai_message)[:500]}...")
                                        
                                        for connection in manager.active_connections.get(data["roomId"], []):
                                            try:
                                                await connection.send_json({
                                                    "type": "new-message",
                                                    "roomId": data["roomId"],
                                                    "message": ai_message
                                                })
                                            except Exception as e:
                                                logger.error(f"AI ì‘ë‹µ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
                                        
                                        logger.info(f"âœ… AI ì‘ë‹µ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì™„ë£Œ - ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡ë¨")
                                    else:
                                        error_text = await response.text()
                                        logger.error(f"âŒ Python API ì˜¤ë¥˜: {error_text}")
                        except Exception as e:
                            logger.error(f"âŒ API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
                
                except Exception as e:
                    logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
    except WebSocketDisconnect:
        await manager.disconnect(websocket, room_id)
    except Exception as e:
        logger.exception(f"Error in WebSocket connection: {str(e)}")
        try:
            await manager.disconnect(websocket, room_id)
        except:
            pass

# ë‹¤ìŒ NPC ì„ íƒ ë„ìš°ë¯¸ í•¨ìˆ˜
def select_next_npc(npcs: List[str], last_speaker: str = None) -> str:
    """
    ëŒ€í™”ì—ì„œ ì‘ë‹µí•  ë‹¤ìŒ NPC ì„ íƒ
    
    Args:
        npcs: ê°€ëŠ¥í•œ NPC ëª©ë¡
        last_speaker: ì´ì „ ë©”ì‹œì§€ ë°œì‹ ì (ìˆìœ¼ë©´)
    
    Returns:
        ì„ íƒëœ NPC ID
    """
    if not npcs:
        raise ValueError("No NPCs available")
    
    # ì´ì „ ë°œì‹ ìê°€ ì—†ìœ¼ë©´ ëœë¤ ì„ íƒ
    if not last_speaker:
        return random.choice(npcs)
    
    # ì´ì „ ë°œì‹ ìê°€ ì•„ë‹Œ NPC ì¤‘ì—ì„œ ì„ íƒ
    available_npcs = [npc for npc in npcs if last_speaker not in npc]
    if available_npcs:
        return random.choice(available_npcs)
    
    # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ì²« ë²ˆì§¸ NPC ë°˜í™˜
    return npcs[0]

@app.get("/")
def read_root():
    return {"message": "Welcome to Sapiens Engine API"}

@app.get("/api/philosophers")
async def get_philosophers():
    """ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ ì² í•™ì ëª©ë¡ ë°˜í™˜"""
    philosophers_list = []
    
    # YAML íŒŒì¼ì—ì„œ ë¡œë“œí•œ ì² í•™ì ì •ë³´ ì‚¬ìš©
    if philosophers_data:
        for key, data in philosophers_data.items():
            # build item with portrait_url
            portrait_url = None
            if key in PORTRAITS_MAP:
                portrait_url = f"http://localhost:8000/portraits/{PORTRAITS_MAP[key]}"
            item = {
                "id": key,
                "name": data.get("name", "Unknown"),
                "period": data.get("period", ""),
                "nationality": data.get("nationality", "")
            }
            if portrait_url:
                item["portrait_url"] = portrait_url
            philosophers_list.append(item)
    else:
        # YAML íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´ ì‚¬ìš©
        for key, description in philosopher_descriptions.items():
            name = description.split(' was ')[0]
            philosophers_list.append({
                "id": key,
                "name": name
            })
    
    return {
        "philosophers": philosophers_list
    }

@app.get("/api/philosophers/{philosopher_id}")
async def get_philosopher_details(philosopher_id: str):
    """íŠ¹ì • ì² í•™ìì˜ ì„¸ë¶€ ì •ë³´ ë°˜í™˜"""
    philosopher_id = philosopher_id.lower()
    
    # YAML íŒŒì¼ì—ì„œ ì² í•™ì ì •ë³´ ì°¾ê¸°
    if philosopher_id in philosophers_data:
        data = philosophers_data[philosopher_id]
        # portrait_url ì¶”ê°€
        portrait_url = None
        if philosopher_id in PORTRAITS_MAP:
            portrait_url = f"http://localhost:8000/portraits/{PORTRAITS_MAP[philosopher_id]}"
        response = { "id": philosopher_id, **data }
        if portrait_url:
            response["portrait_url"] = portrait_url
        return response
        
    # ê¸°ë³¸ ì •ë³´ì—ì„œ ì°¾ê¸°
    if philosopher_id in philosopher_descriptions:
        description = philosopher_descriptions[philosopher_id]
        name = description.split(' was ')[0]
        response = {
            "id": philosopher_id,
            "name": name,
            "description": description
        }
        if philosopher_id in PORTRAITS_MAP:
            response["portrait_url"] = f"http://localhost:8000/portraits/{PORTRAITS_MAP[philosopher_id]}"
        return response
        
    # ì² í•™ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
    raise HTTPException(status_code=404, detail=f"Philosopher '{philosopher_id}' not found")

@app.post("/api/chat/initial", response_model=ChatResponse)
async def create_initial_chat(request: InitialChatRequest):
    try:
        logger.info(f"Received initial chat request: {request}")
        
        # ìš”ì²­í•œ ì² í•™ì ê²€ìƒ‰
        philosopher = request.philosopher.lower()
        
        # ì² í•™ì ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        if philosopher in philosopher_descriptions:
            philosopher_description = philosopher_descriptions[philosopher]
        else:
            # ê¸°ë³¸ ì„¤ëª… ìƒì„±
            logger.warning(f"Philosopher {philosopher} not found in configuration")
            philosopher_description = f"{request.philosopher} is a philosopher interested in various philosophical topics."
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        user_message = ""
        if request.user_message:
            user_message = f"User: {request.user_message}\n"
        
        # ì‘ë‹µ ìƒì„±
        response_text, metadata = llm_manager.generate_philosophical_response(
            npc_description=philosopher_description,
            topic=request.topic,
            context=request.context,
            previous_dialogue=user_message
        )
        
        return ChatResponse(
            response=response_text,
            philosopher=request.philosopher,
            metadata=metadata
        )
    
    except Exception as e:
        logger.exception(f"Error generating initial chat response: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/portraits/generate")
async def generate_portrait(request: PortraitRequest):
    """Generate NPC portrait via OpenAI and save to static portraits folder"""
    try:
        # ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ ìœ„í•œ ì°¸ì¡° ì´ë¯¸ì§€ URL ìƒì„±
        style_image_urls = []
        for ph in request.reference_philosophers:
            pid = ph.lower()
            if pid in PORTRAITS_MAP:
                style_image_urls.append(f"http://localhost:8000/portraits/{PORTRAITS_MAP[pid]}")
        style_refs_text = ""
        if style_image_urls:
            style_refs_text = " Use the following reference images for style: " + ", ".join(style_image_urls) + "."

        # ë¹Œë“œí•  í”„ë¡¬í”„íŠ¸: ê³ ì •ëœ ìŠ¤íƒ€ì¼ & ì² í•™ì ì–¼êµ´ ì™„ì „ ë³‘í•©, ìŒì„± ìŠ¤íƒ€ì¼(í‘œì •) ë°˜ì˜
        ref_urls = ", ".join(style_image_urls)
        const_style = "A sepia-toned charcoal portrait (chest-up), fine pencil texture on vintage paper background, soft diffuse lighting, rich warm tones."
        philosophers = ", ".join(request.reference_philosophers)
        
        # ë” ëª…í™•í•œ ë¸”ë Œë”© ì§€ì‹œì‚¬í•­
        blend_text = f"""Create ONE SINGLE FICTIONAL FACE that is a perfect 50/50 hybrid fusion between 
        {philosophers}. Do not show multiple separate individuals or different faces. 
        Create ONE new imaginary person with merged facial features from both philosophers."""
        
        # í‘œì • ì§€ì‹œì‚¬í•­
        render_text = f"This merged character should have an expression/demeanor that shows: {request.voice_style}"
        
        prompt = (
            f"{const_style} {blend_text} {render_text} "
            f"The portrait should be of ONE person named {request.npc_name}, not multiple people. "
            f"Generate a square (1024x1024 pixels) high-quality PNG portrait. "
            "Provide a PNG without any text or overlays."
        )
        # OpenAI ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ with explicit model (using new openai-python v1.0 interface)
        response = openai.images.generate(
            model="dall-e-3",
            prompt=prompt,
            n=1,
            size="1024x1024"
        )
        image_url = response.data[0].url
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        img_bytes = requests.get(image_url).content
        # íŒŒì¼ëª… ìƒì„±
        filename = f"{slugify(request.npc_name)}_{int(time.time())}.png"
        filepath = os.path.join(PORTRAITS_DIR, filename)
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
        with open(filepath, 'wb') as img_file:
            img_file.write(img_bytes)
        
        # íŒŒì¼ ì €ì¥ ê²€ì¦
        if os.path.exists(filepath):
            file_size = os.path.getsize(filepath)
            logger.info(f"Image saved successfully: {filepath} ({file_size} bytes)")
        else:
            logger.error(f"Failed to save image: {filepath}")
            raise HTTPException(status_code=500, detail="Failed to save generated image")
        
        # ë°˜í™˜í•  URL (ì ˆëŒ€ ê²½ë¡œë¡œ ë³€ê²½)
        return { 'url': f"http://localhost:8000/portraits/{filename}" }
    except Exception as e:
        logger.exception(f"Error generating portrait: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/npc/create")
async def create_npc(request: NpcCreateRequest):
    """Stub NPC creation endpoint: returns generated ID to Next.js"""
    new_id = str(uuid4())
    return { "id": new_id }

# ëŒ€í™” ê´€ë¦¬ì í´ë˜ìŠ¤ ì¶”ê°€
class ConversationManager:
    """ëŒ€í™” ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê³  í† í° ì œí•œì„ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.conversations = {}  # room_idë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ëŠ” ëŒ€í™” ìƒíƒœ ì €ì¥ì†Œ
        self.max_token_limit = 7000  # í† í° ì œí•œ (GPT-4 ê¸°ì¤€ ì¡°ì • ê°€ëŠ¥)
        self.recent_messages_count = 10  # í•­ìƒ ìœ ì§€í•  ìµœê·¼ ë©”ì‹œì§€ ìˆ˜
        self.llm_manager = llm_manager  # ê¸°ì¡´ llm_manager ì‚¬ìš©
        logger.info("ğŸ”§ ConversationManager ì´ˆê¸°í™”ë¨: í† í° ì œí•œ %d, ìµœê·¼ ë©”ì‹œì§€ ìœ ì§€ %dê°œ", 
                    self.max_token_limit, self.recent_messages_count)
        
    async def get_or_create_conversation(self, room_id):
        """ëŒ€í™” ìƒíƒœë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒˆë¡œ ìƒì„±"""
        if room_id not in self.conversations:
            # DBì—ì„œ ê¸°ì¡´ ë©”ì‹œì§€ì™€ ë°© ì •ë³´ ë¡œë“œ
            try:
                # ëŒ€í™”ë°© ì •ë³´ ë¡œë“œ
                room_data = await get_room_data(room_id)
                messages = await get_room_messages(room_id, limit=50)  # ìµœê·¼ 50ê°œ ë©”ì‹œì§€ë¡œ ì‹œì‘
                
                # ì •ì  ì •ë³´ ì„¤ì •
                self.conversations[room_id] = {
                    "messages": messages,
                    "npc_descriptions": {},
                    "context": room_data.get("context", ""),
                    "topic": room_data.get("title", ""),
                    "npcs": room_data.get("npcs", []),
                    "last_summary_time": time.time()
                }
                
                # NPC ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
                for npc_id in self.conversations[room_id]["npcs"]:
                    await self.load_npc_description(room_id, npc_id)
                    
                logger.info(f"ğŸ”„ Room {room_id} ëŒ€í™” DBì—ì„œ ë¡œë“œë¨: {len(messages)}ê°œ ë©”ì‹œì§€, í† í”½: {room_data.get('title', 'ì—†ìŒ')}")
        
                # í˜„ì¬ í† í° ìˆ˜ ê³„ì‚° ë° ë¡œê¹…
                if messages:
                    token_count = self._count_tokens_approx(messages)
                    logger.debug(f"ğŸ“Š Room {room_id} í˜„ì¬ í† í° ìˆ˜: {token_count}/{self.max_token_limit} ({token_count/self.max_token_limit*100:.1f}%)")
            except Exception as e:
                logger.error(f"Error loading conversation data for room {room_id}: {e}")
                # ì˜¤ë¥˜ ì‹œ ë¹ˆ ëŒ€í™”ë¡œ ì´ˆê¸°í™”
                self.conversations[room_id] = {
                    "messages": [],
                    "npc_descriptions": {},
                    "context": "",
                    "topic": "",
                    "npcs": [],
                    "last_summary_time": time.time()
                }
                
        return self.conversations[room_id]
    
    async def load_npc_description(self, room_id, npc_id):
        """NPC ì„¤ëª… ë¡œë“œ"""
        conversation = await self.get_or_create_conversation(room_id)
        
        # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ
        if npc_id in conversation["npc_descriptions"]:
            return conversation["npc_descriptions"][npc_id]
            
        try:
            # NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            npc_info = await get_npc_details(npc_id)
            npc_description = f"{npc_info['name']}: {npc_info.get('description', 'A philosopher with unique perspectives')}"
            
            # ì»¤ìŠ¤í…€ NPCì¸ ê²½ìš° ì¶”ê°€ íŠ¹ì„± í¬í•¨
            if npc_info.get('is_custom', False):
                additional_traits = []
                
                if npc_info.get('voice_style'):
                    additional_traits.append(f"Voice style: {npc_info['voice_style']}")
                
                if npc_info.get('debate_approach'):
                    additional_traits.append(f"Debate approach: {npc_info['debate_approach']}")
                
                if npc_info.get('communication_style'):
                    additional_traits.append(f"Communication style: {npc_info['communication_style']}")
                
                # íŠ¹ì„±ì´ ìˆìœ¼ë©´ ì„¤ëª…ì— ì¶”ê°€
                if additional_traits:
                    traits_text = "; ".join(additional_traits)
                    npc_description += f". {traits_text}"
                    
            # ìºì‹œì— ì €ì¥
            conversation["npc_descriptions"][npc_id] = npc_description
            logger.info(f"NPC description loaded for {npc_id}")
            
            return npc_description
        except Exception as e:
            logger.error(f"Error loading NPC description for {npc_id}: {e}")
            # ê¸°ë³¸ ì„¤ëª… ì œê³µ
            default_description = f"Philosopher {npc_id[:6]}: A thinker with unique perspectives"
            conversation["npc_descriptions"][npc_id] = default_description
            return default_description
    
    async def add_message(self, room_id, message_data):
        """ë©”ì‹œì§€ ì¶”ê°€ ë° ì½˜í…ìŠ¤íŠ¸ ê´€ë¦¬"""
        conversation = await self.get_or_create_conversation(room_id)
        
        # ë©”ì‹œì§€ ì¶”ê°€
        conversation["messages"].append(message_data)
        
        # ë””ë²„ê¹…: ë©”ì‹œì§€ ì¶”ê°€ í›„ í† í° ìˆ˜ ê³„ì‚°
        token_count = self._count_tokens_approx(conversation["messages"])
        logger.debug(f"ğŸ“ ë©”ì‹œì§€ ì¶”ê°€ë¨ - Room {room_id}: ë°œì‹ ì={message_data.get('sender', 'unknown')}, í˜„ì¬ í† í° ìˆ˜={token_count}")
        
        # DBì— ë©”ì‹œì§€ ì €ì¥ (ê¸°ì¡´ ë¡œì§ ì‚¬ìš©)
        await save_message_to_db(room_id, message_data)
        
        # ë©”ì‹œì§€ ì¶”ê°€ í›„ í•„ìš”í•˜ë©´ ì½˜í…ìŠ¤íŠ¸ ìµœì í™”
        await self._manage_context_window(room_id)
        
        return message_data
    
    async def _manage_context_window(self, room_id):
        """í† í° ì œí•œì„ ê³ ë ¤í•˜ì—¬ ì½˜í…ìŠ¤íŠ¸ ì°½ ê´€ë¦¬"""
        conversation = await self.get_or_create_conversation(room_id)
        messages = conversation["messages"]
        
        # ë©”ì‹œì§€ê°€ ì¶©ë¶„íˆ ë§ì•„ì¡Œì„ ë•Œë§Œ ì²˜ë¦¬
        if len(messages) < 20:
            return
            
        # ì˜ˆìƒ í† í° ìˆ˜ ê³„ì‚°
        total_tokens = self._count_tokens_approx(messages)
        
        # í† í° ìˆ˜ê°€ ì œí•œì— ê·¼ì ‘í•˜ë©´ ì˜¤ë˜ëœ ë©”ì‹œì§€ ìš”ì•½
        if total_tokens > self.max_token_limit * 0.8:  # 80% ì„ê³„ê°’
            logger.info(f"âš ï¸ í† í° ìˆ˜({total_tokens})ê°€ ì œí•œ({self.max_token_limit})ì˜ 80%ì— ê·¼ì ‘ - Room {room_id} ì˜¤ë˜ëœ ë©”ì‹œì§€ ìš”ì•½")
            await self._summarize_older_messages(room_id)
    
    async def _summarize_older_messages(self, room_id):
        """ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ìš”ì•½í•˜ì—¬ í† í° ìˆ˜ ì¤„ì´ê¸°"""
        conversation = await self.get_or_create_conversation(room_id)
        messages = conversation["messages"]
        
        # ìµœê·¼ ë©”ì‹œì§€ëŠ” ë³´ì¡´
        recent_messages = messages[-self.recent_messages_count:]
        older_messages = messages[:-self.recent_messages_count]
        
        if len(older_messages) < 5:
            return  # ìš”ì•½í•  ë©”ì‹œì§€ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ìŠ¤í‚µ
        
        try:
            # ì˜¤ë˜ëœ ë©”ì‹œì§€ í¬ë§·íŒ…
            formatted_messages = self._format_messages_for_summary(older_messages)
            
            # ìš”ì•½ ìƒì„± ì‹œì‘ ë¡œê¹…
            logger.debug(f"ğŸ”„ ìš”ì•½ ì‹œì‘ - Room {room_id}: {len(older_messages)}ê°œ ë©”ì‹œì§€ ìš”ì•½ ì¤‘")
            before_token_count = self._count_tokens_approx(messages)
            
            # ìš”ì•½ ìƒì„±
            system_prompt = "Summarize the following conversation in 2-3 concise sentences, preserving key points and context."
            summary = self.llm_manager.generate_response(
                system_prompt=system_prompt,
                user_prompt=formatted_messages,
                llm_provider="openai",
                llm_model="gpt-3.5-turbo"  # ìš”ì•½ì—ëŠ” ì €ë ´í•œ ëª¨ë¸ ì‚¬ìš©
            )
            
            # ìš”ì•½ ë©”ì‹œì§€ ìƒì„±
            summary_message = {
                "id": f"summary-{uuid4()}",
                "text": f"[Previous conversation summary: {summary}]",
                "sender": "System",
                "is_summary": True,
                "isUser": False,
                "timestamp": datetime.now().isoformat()
            }
            
            # ëŒ€í™” ìƒíƒœ ì—…ë°ì´íŠ¸ - ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´
            conversation["messages"] = [summary_message] + recent_messages
            after_token_count = self._count_tokens_approx(conversation["messages"])
            
            logger.info(f"âœ… Room {room_id} ìš”ì•½ ì™„ë£Œ: {len(older_messages)}ê°œ ë©”ì‹œì§€ê°€ ìš”ì•½ë¨")
            logger.info(f"ğŸ“Š í† í° ê°ì†Œ: {before_token_count} â†’ {after_token_count} ({before_token_count-after_token_count}ê°œ í† í° ì ˆì•½)")
            
            # ìš”ì•½ ë©”ì‹œì§€ DBì— ì €ì¥
            await save_message_to_db(room_id, summary_message)
            
        except Exception as e:
            logger.error(f"âŒ ë©”ì‹œì§€ ìš”ì•½ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ë‹¨ìˆœíˆ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì˜ë¼ë‚´ê¸°
            conversation["messages"] = older_messages[-5:] + recent_messages  # ì˜¤ë˜ëœ ë©”ì‹œì§€ ì¤‘ ìµœê·¼ 5ê°œë§Œ ìœ ì§€
            logger.warning(f"âš ï¸ ìš”ì•½ ëŒ€ì‹  ì˜¤ë˜ëœ ë©”ì‹œì§€ {len(older_messages)-5}ê°œ ì œê±°ë¨")
    
    def _format_messages_for_summary(self, messages):
        """ìš”ì•½ì„ ìœ„í•œ ë©”ì‹œì§€ í¬ë§·íŒ…"""
        formatted = []
        for msg in messages:
            sender = msg.get("sender", "Unknown")
            text = msg.get("text", "")
            is_user = msg.get("isUser", False)
            
            prefix = "User" if is_user else sender
            formatted.append(f"{prefix}: {text}")
            
        return "\n".join(formatted)
    
    async def get_prompt_context(self, room_id, responding_npc_id):
        """LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        conversation = await self.get_or_create_conversation(room_id)
        
        # NPC ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        npc_description = conversation["npc_descriptions"].get(responding_npc_id, "")
        if not npc_description:
            npc_description = await self.load_npc_description(room_id, responding_npc_id)
            
        # ëŒ€í™” í¬ë§·íŒ…
        messages = conversation["messages"]
        formatted_dialogue = self._format_previous_dialogue(messages)
        
        return {
            "npc_description": npc_description,
            "topic": conversation["topic"],
            "context": conversation["context"],
            "previous_dialogue": formatted_dialogue
        }
    
    def _format_previous_dialogue(self, messages):
        """ëŒ€í™” ê¸°ë¡ì„ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        formatted = []
        
        for msg in messages:
            # ìš”ì•½ ë©”ì‹œì§€ëŠ” ê·¸ëŒ€ë¡œ í¬í•¨
            if msg.get("is_summary", False):
                formatted.append(msg["text"])
                continue
                
            sender = msg.get("sender", "Unknown")
            text = msg.get("text", "")
            is_user = msg.get("isUser", False)
            
            prefix = "User" if is_user else sender
            formatted.append(f"{prefix}: {text}")
            
        return "\n".join(formatted)
    
    def _count_tokens_approx(self, messages, model="gpt-4"):
        """ë©”ì‹œì§€ì˜ ëŒ€ëµì ì¸ í† í° ìˆ˜ ê³„ì‚°"""
        try:
            if 'tiktoken' in globals():
                encoding = tiktoken.encoding_for_model(model)
                
                total_tokens = 0
                for msg in messages:
                    # ë©”ì‹œì§€ ë‚´ìš©ì˜ í† í° ìˆ˜ ê³„ì‚°
                    text = msg.get("text", "")
                    tokens = len(encoding.encode(text))
                    # ë©”ì‹œì§€ ë©”íƒ€ë°ì´í„°ì— ëŒ€í•œ ì¶”ê°€ í† í°
                    total_tokens += tokens + 4  # ê° ë©”ì‹œì§€ì— ëŒ€í•œ ì˜¤ë²„í—¤ë“œ
                    
                # ì „ì²´ ìš”ì²­ í˜•ì‹ì— ëŒ€í•œ ê¸°ë³¸ í† í° ì¶”ê°€
                total_tokens += 2
                
                return total_tokens
            else:
                # tiktokenì´ ì—†ìœ¼ë©´ ë¬¸ì ê¸¸ì´ ê¸°ë°˜ ëŒ€ëµì ì¸ ì¶”ì •ì¹˜ ë°˜í™˜
                chars = sum(len(msg.get("text", "")) for msg in messages)
                tokens_approx = chars // 4  # ì˜ì–´ í…ìŠ¤íŠ¸ì—ì„œ ëŒ€ëµ 4ìë‹¹ 1í† í°ìœ¼ë¡œ ì¶”ì •
                logger.debug("âš ï¸ tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ: ë¬¸ì ê¸°ë°˜ í† í° ì¶”ì •ì¹˜ ì‚¬ìš© (%d ë¬¸ì â†’ %d í† í°)", chars, tokens_approx)
                return tokens_approx
        except Exception as e:
            logger.error(f"âŒ í† í° ê³„ì‚° ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ë¬¸ì ê¸¸ì´ ê¸°ë°˜ ëŒ€ëµì ì¸ ì¶”ì •ì¹˜ ë°˜í™˜
            chars = sum(len(msg.get("text", "")) for msg in messages)
            return chars // 4

# ëŒ€í™” ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
conversation_manager = ConversationManager()

# ChatGenerateRequest ëª¨ë¸ ìˆ˜ì •
class ChatGenerateRequest(BaseModel):
    npc_descriptions: Optional[str] = None
    npcs: Optional[List[str]] = []  # í•„ìˆ˜ í•„ë“œë¥¼ Optionalë¡œ ì„¤ì •
    room_id: str  # ë£¸ ID í•„ë“œ ì¶”ê°€
    user_message: str  # ì‚¬ìš©ì ë©”ì‹œì§€ í•„ë“œ ì¶”ê°€
    topic: Optional[str] = ""
    context: Optional[str] = ""
    previous_dialogue: Optional[str] = ""  # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
    llm_provider: Optional[str] = "openai"
    llm_model: Optional[str] = "gpt-4o"
    api_key: Optional[str] = None
    use_rag: Optional[bool] = False  # RAG ì‚¬ìš© ì—¬ë¶€ í”Œë˜ê·¸ ì¶”ê°€

# API ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì •
@app.post("/api/chat/generate")
async def generate_chat_response(request: ChatGenerateRequest):
    """
    ìƒˆë¡œìš´ AI ì±„íŒ… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        logger.info(f"ğŸ”„ ì±„íŒ… ì‘ë‹µ ìƒì„± ìš”ì²­: {request.room_id}")
        
        # ì‚¬ìš©í•  NPC ëª©ë¡ í™•ì¸ (ìš°ì„  ìˆœìœ„: npcs > npc_descriptions)
        npcs = request.npcs or []
        if not npcs and request.npc_descriptions:
            # ë ˆê±°ì‹œ ì§€ì›: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ npc ëª©ë¡ ë¬¸ìì—´ì„ íŒŒì‹±
            npcs = [npc.strip() for npc in request.npc_descriptions.split(',')]
        
        # ì ì–´ë„ í•˜ë‚˜ì˜ NPCê°€ í•„ìš”í•¨
        if not npcs:
            raise HTTPException(status_code=400, detail="No NPCs specified")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ê°€ í•„ìš”í•¨
        if not request.user_message or not request.user_message.strip():
            raise HTTPException(status_code=400, detail="User message is required")
        
        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ë¹ˆ ë¬¸ìì—´ì´ë©´ Noneìœ¼ë¡œ ì„¤ì •)
        context = request.context.strip() if request.context else None
        topic = request.topic.strip() if request.topic else None
        
        # ì´ì „ ëŒ€í™” ë¬¸ë§¥ ì²˜ë¦¬
        previous_dialogue = request.previous_dialogue.strip() if request.previous_dialogue else None
        
        # LLM í”„ë¡œë°”ì´ë” ë° ëª¨ë¸ ì„¤ì •
        llm_provider = request.llm_provider.lower() if request.llm_provider else None
        llm_model = request.llm_model if request.llm_model else None
        
        # API í‚¤ ì²˜ë¦¬
        api_key = request.api_key
        if api_key:
            # API í‚¤ê°€ ì œê³µëœ ê²½ìš° í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
            if llm_provider == "openai":
                os.environ["OPENAI_API_KEY"] = api_key
            elif llm_provider == "anthropic":
                os.environ["ANTHROPIC_API_KEY"] = api_key
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ë¡œê¹…
        logger.info(f"ğŸ’¬ user_message: {request.user_message[:50]}...")
        
        # RAG ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        use_rag = request.use_rag if request.use_rag is not None else False
        logger.info(f"ğŸ” RAG ì‚¬ìš© ì—¬ë¶€(í´ë¼ì´ì–¸íŠ¸ ìš”ì²­): {use_rag}")
        
        # ì‘ë‹µí•  ì² í•™ì(NPC) ì„ íƒ
        responding_philosopher = select_responding_philosopher(npcs, request.user_message)
        logger.info(f"ğŸ¯ ì‘ë‹µí•  ì² í•™ì: {responding_philosopher}")
        
        # *** ìƒˆ ë¡œì§: NPC ì„ íƒ ì¦‰ì‹œ ì†Œì¼“ ì´ë²¤íŠ¸ ë°œì†¡ ***
        try:
            # npc-selected ì´ë²¤íŠ¸ ë°œì†¡
            async with aiohttp.ClientSession() as session:
                nextjs_api_url = os.environ.get("NEXTJS_API_URL", "http://localhost:3000")
                
                # ì†Œì¼“ ì´ë²¤íŠ¸ ë°ì´í„°
                npc_selected_data = {
                    "action": "broadcast",
                    "room": request.room_id,
                    "event": "npc-selected",
                    "data": {
                        "npc_id": responding_philosopher
                    }
                }
                
                logger.info(f"NPC ì„ íƒ ì´ë²¤íŠ¸ ë°œì†¡: {responding_philosopher}")
                
                # ì´ë²¤íŠ¸ ì „ì†¡
                npc_selected_response = await session.post(
                    f"{nextjs_api_url}/api/socket",
                    json=npc_selected_data,
                    headers={"Content-Type": "application/json"}
                )
                
                # ì‘ë‹µ í™•ì¸
                npc_selected_status = npc_selected_response.status
                if npc_selected_status != 200:
                    logger.warning(f"NPC ì„ íƒ ì´ë²¤íŠ¸ ë°œì†¡ ì‹¤íŒ¨: {npc_selected_status}")
        except Exception as e:
            logger.error(f"NPC ì„ íƒ ì´ë²¤íŠ¸ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # ì¹¸íŠ¸ì˜ ê²½ìš° ìë™ìœ¼ë¡œ RAG í™œì„±í™”
        if responding_philosopher.lower() == 'kant':
            use_rag = True
            logger.info(f"ğŸ” ì¹¸íŠ¸ ì‘ë‹µì„ ìœ„í•´ RAG ìë™ í™œì„±í™”ë¨")
        
        # ì„ íƒëœ ì² í•™ìì— ëŒ€í•œ ì„¤ëª… ë¡œë“œ
        philosopher_system_prompt = philosopher_descriptions.get(responding_philosopher.lower(), "")
        if not philosopher_system_prompt:
            logger.warning(f"âš ï¸ ì² í•™ì ì„¤ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {responding_philosopher}. ê¸°ë³¸ ì„¤ëª… ì‚¬ìš©.")
            philosopher_system_prompt = f"{responding_philosopher} is a philosopher with unique views."
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        dialogue_context = ""
        if previous_dialogue:
            dialogue_context = previous_dialogue
        else:
            # ìƒˆë¡œìš´ ëŒ€í™”ì¸ ê²½ìš° ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
            dialogue_context = f"User: {request.user_message}"
        
        # ì£¼ì œê°€ ì—†ëŠ” ê²½ìš° ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì¶”ë¡ 
        if not topic:
            dialogue_lines = dialogue_context.strip().split('\n')
            if len(dialogue_lines) > 0:
                # ì²« ë²ˆì§¸ ì¤„ì—ì„œ ì£¼ì œ ì¶”ì¶œ ì‹œë„
                first_line = dialogue_lines[0].strip()
                # 'User:' ì ‘ë‘ì‚¬ ì œê±°
                if first_line.lower().startswith("user:"):
                    topic = first_line.split(':', 1)[1].strip()
                else:
                    topic = first_line
            # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì‚¬ìš©ì ë©”ì‹œì§€ ì‚¬ìš©
            if not topic:
                topic = request.user_message
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ë¡œê¹…
        logger.info(f"ğŸ’¬ user_message: {request.user_message[:50]}...")
        logger.info(f"ğŸ’¬ topic: {topic[:50]}...")
        logger.info(f"ğŸ’¬ context: {context[:50] if context else 'None'}...")
        logger.info(f"ğŸ’¬ dialogue_context: {dialogue_context[:50]}...")
        
        # LLM Managerë¥¼ ì‚¬ìš©í•˜ì—¬ ì² í•™ì  ì‘ë‹µ ìƒì„±
        logger.debug(f"ğŸ”„ ì² í•™ì  ì‘ë‹µ ìƒì„± ì‹œì‘...")
        response_text, metadata = llm_manager.generate_philosophical_response(
            npc_description=philosopher_system_prompt,
            topic=topic,
            context=context or "",
            previous_dialogue=dialogue_context,
            llm_provider=llm_provider,
            llm_model=llm_model,
            use_rag=use_rag,
            npc_id=responding_philosopher.lower()
        )
        
        # ì‘ë‹µ ë¡œê¹…
        logger.info(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ: {response_text[:50]}...")
        
        # ì¸ìš© ì •ë³´ í™•ì¸ ë° ì¶”ì¶œ
        citations = metadata.get("citations", [])
        if citations:
            logger.info(f"ğŸ“š {len(citations)}ê°œì˜ ì¸ìš© ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            # í™•ì¸ì„ ìœ„í•´ ì²« ë²ˆì§¸ ì¸ìš© ì •ë³´ ë¡œê¹…
            if len(citations) > 0:
                logger.info(f"ğŸ“š ì²« ë²ˆì§¸ ì¸ìš© ì •ë³´: id={citations[0].get('id', '?')}, source={citations[0].get('source', '?')}")
                logger.debug(f"ğŸ“š ì¸ìš© ì •ë³´ ì „ì²´ ëª©ë¡: {citations}")
        else:
            logger.warning("âš ï¸ ì¸ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„± - ì¸ìš© ì •ë³´ë¥¼ ì‘ë‹µ ê°ì²´ì˜ ìµœìƒìœ„ ìˆ˜ì¤€ì— í¬í•¨
        response_data = {
            "response": response_text,
            "philosopher": responding_philosopher,
            "metadata": {
                "elapsed_time": metadata.get("elapsed_time", "N/A"),
                "rag_used": metadata.get("rag_used", False)
            },
            "citations": citations  # citations í•„ë“œë¥¼ ì§ì ‘ ìµœìƒìœ„ ìˆ˜ì¤€ì— ì¶”ê°€
        }
        
        # ì‘ë‹µ ë°ì´í„° ë””ë²„ê¹…ì„ ìœ„í•´ ë¡œê¹…
        logger.debug(f"ğŸ“¤ ìµœì¢… ì‘ë‹µ ë°ì´í„° êµ¬ì¡°: {list(response_data.keys())}")
        logger.debug(f"ğŸ“¤ ì‘ë‹µ ë°ì´í„° citations í•„ë“œ íƒ€ì…: {type(response_data['citations'])}")
        logger.debug(f"ğŸ“¤ ì‘ë‹µ ë°ì´í„° citations í•­ëª© ìˆ˜: {len(response_data['citations'])}")
        
        return response_data
    
    except Exception as e:
        logger.error(f"âŒ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        # ìƒì„¸í•œ ì˜¤ë¥˜ ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤ ë¡œê¹…
        logger.exception("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        raise HTTPException(status_code=500, detail=f"Failed to generate response: {str(e)}")

def select_responding_philosopher(npcs: List[str], user_message: str) -> str:
    """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•˜ì—¬ ì‘ë‹µí•  ì² í•™ìë¥¼ ì„ íƒ"""
    if not npcs:
        raise ValueError("No philosophers available to respond")
    
    # LLMì„ í™œìš©í•œ NPC ì„ íƒ í•¨ìˆ˜ë¡œ ê°œì„ 
    try:
        logger.info(f"ğŸ“Š ì‘ë‹µ NPC ì„ íƒ ì‹œì‘: '{user_message[:50]}...'")
        logger.info(f"ğŸ“Š NPC í›„ë³´ ëª©ë¡: {', '.join(npcs)}")
        
        # NPC ì„¸ë¶€ ì •ë³´ ë¡œë“œ - NPC IDì™€ ì´ë¦„, ì„¤ëª…ì„ ë§¤í•‘
        npc_details = {}
        for npc_id in npcs:
            try:
                # ì „ì—­ npc_cache ì‚¬ìš©
                cache_key = f"npc:{npc_id}"
                cached_info = npc_cache.get(cache_key, None)
                if cached_info and 'data' in cached_info:
                    npc_info = cached_info['data']
                else:
                    # ìºì‹œì— ì—†ìœ¼ë©´ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
                    logger.debug(f"ğŸ“‹ NPC {npc_id} ì •ë³´ë¥¼ ìºì‹œì—ì„œ ì°¾ì§€ ëª»í•¨, DB ì¡°íšŒ")
                    npc_info = asyncio.run(get_npc_details(npc_id))
                
                # NPC ì´ë¦„, í•„ëª…, í•œê¸€ ì´ë¦„ ë“± ë³€í˜• ì¶”ê°€
                npc_name = npc_info.get('name', '')
                npc_details[npc_id] = {
                    "name": npc_name,
                    "name_lower": npc_name.lower(),
                    "ko_name": get_korean_name(npc_id, npc_name),  # í•œê¸€ ì´ë¦„ ì¶”ê°€
                }
                logger.debug(f"ğŸ“‹ NPC {npc_id} ì •ë³´: {npc_details[npc_id]}")
            except Exception as e:
                logger.error(f"NPC {npc_id} ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        
        # 1. ë¨¼ì € ì‚¬ìš©ìê°€ ì§ì ‘ ì–¸ê¸‰í•œ NPCë¥¼ ì°¾ìŒ
        logger.info(f"ğŸ” 1ë‹¨ê³„: ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì§ì ‘ ì–¸ê¸‰ëœ NPC ì°¾ê¸°")
        mentioned_npc = find_mentioned_npc(user_message, npc_details)
        if mentioned_npc:
            logger.info(f"âœ… ì‚¬ìš©ìê°€ ì§ì ‘ ì–¸ê¸‰í•œ NPC ë°œê²¬: {mentioned_npc}")
            # NPC ì´ë¦„ ë¡œê¹…
            npc_name = npc_details.get(mentioned_npc, {}).get('name', mentioned_npc)
            logger.info(f"âœ… ì‘ë‹µì ì„ íƒ ì™„ë£Œ: {mentioned_npc} ({npc_name})")
            return mentioned_npc
        
        # 2. ì§ì ‘ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ LLMì„ ì‚¬ìš©í•˜ì—¬ ì í•©í•œ NPC ì„ íƒ
        logger.info(f"ğŸ” 2ë‹¨ê³„: LLMì„ ì‚¬ìš©í•˜ì—¬ ì í•©í•œ NPC ì„ íƒ")
        selected_npc = select_npc_with_llm(user_message, npcs, npc_details)
        if selected_npc:
            # NPC ì´ë¦„ ë¡œê¹…
            npc_name = npc_details.get(selected_npc, {}).get('name', selected_npc)
            logger.info(f"âœ… LLMì´ ì„ íƒí•œ NPC: {selected_npc} ({npc_name})")
            return selected_npc
        
        # 3. LLM ì„ íƒ ì‹¤íŒ¨ ì‹œ ëœë¤ ì„ íƒ
        logger.info(f"ğŸ” 3ë‹¨ê³„: ëœë¤ NPC ì„ íƒ")
        random_npc = random.choice(npcs)
        # NPC ì´ë¦„ ë¡œê¹…
        npc_name = npc_details.get(random_npc, {}).get('name', random_npc)
        logger.info(f"âœ… ëœë¤ ì„ íƒëœ NPC: {random_npc} ({npc_name})")
        return random_npc
        
    except Exception as e:
        logger.error(f"NPC ì„ íƒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëœë¤ ì„ íƒìœ¼ë¡œ í´ë°±
        random_npc = random.choice(npcs)
        logger.info(f"âœ… ì˜¤ë¥˜ í›„ ëœë¤ ì„ íƒëœ NPC: {random_npc}")
        return random_npc

# í•œê¸€ ì´ë¦„ ë§¤í•‘ ì¶”ê°€
def get_korean_name(npc_id: str, english_name: str) -> str:
    """NPCì˜ í•œê¸€ ì´ë¦„ ë°˜í™˜"""
    # ê¸°ë³¸ í•œê¸€ ì´ë¦„ ë§¤í•‘
    ko_names = {
        "socrates": "ì†Œí¬ë¼í…ŒìŠ¤",
        "plato": "í”Œë¼í†¤",
        "aristotle": "ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤",
        "kant": "ì¹¸íŠ¸",
        "hegel": "í—¤ê²”",
        "nietzsche": "ë‹ˆì²´",
        "marx": "ë§ˆë¥´í¬ìŠ¤",
        "sartre": "ì‚¬ë¥´íŠ¸ë¥´",
        "camus": "ì¹´ë®ˆ",
        "beauvoir": "ë³´ë¶€ì•„ë¥´",
        "confucius": "ê³µì",
        "laozi": "ë…¸ì",
        "buddha": "ë¶“ë‹¤",
        "rousseau": "ë£¨ì†Œ",
        "wittgenstein": "ë¹„íŠ¸ê²ìŠˆíƒ€ì¸"
    }
    
    # ë¨¼ì € IDë¡œ ì°¾ê¸°
    if npc_id.lower() in ko_names:
        return ko_names[npc_id.lower()]
    
    # ì˜ì–´ ì´ë¦„ì˜ ì¼ë¶€ê°€ ë§¤í•‘ì— ìˆëŠ”ì§€ í™•ì¸
    for en_name, ko_name in ko_names.items():
        if en_name in english_name.lower():
            return ko_name
    
    # ë§¤í•‘ì´ ì—†ìœ¼ë©´ ì˜ì–´ ì´ë¦„ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return english_name

# ì§ì ‘ ì–¸ê¸‰ëœ NPC ì°¾ê¸°
def find_mentioned_npc(message: str, npc_details: Dict[str, Dict[str, str]]) -> Optional[str]:
    """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì§ì ‘ ì–¸ê¸‰ëœ NPC ID ì°¾ê¸°"""
    if not message or not npc_details:
        return None
    
    logger.info(f"ğŸ” ë©”ì‹œì§€ì—ì„œ ì–¸ê¸‰ëœ NPC ì°¾ê¸°: '{message}'")
    
    # LLMì„ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ì—ì„œ ì–¸ê¸‰ëœ NPC ì°¾ê¸°
    try:
        return select_npc_with_llm(message, list(npc_details.keys()), npc_details, is_direct_mention=True)
    except Exception as e:
        logger.error(f"LLMì„ ì‚¬ìš©í•œ NPC ì–¸ê¸‰ ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# LLMìœ¼ë¡œ NPC ì„ íƒ
def select_npc_with_llm(user_message: str, npcs: List[str], npc_details: Dict[str, Dict[str, str]], is_direct_mention: bool = False) -> Optional[str]:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì— ê°€ì¥ ì í•©í•œ NPC ì„ íƒ"""
    if not npcs or not user_message:
        return None
        
    try:
        # NPC ì •ë³´ ëª©ë¡ ìƒì„± (ID, ì´ë¦„, í•œê¸€ ì´ë¦„ í¬í•¨)
        npc_info_list = []
        for npc_id in npcs:
            details = npc_details.get(npc_id, {})
            name = details.get("name", npc_id)
            ko_name = details.get("ko_name", "")
            
            # ê° NPCë§ˆë‹¤ ë‹¤ì–‘í•œ ì‹ë³„ì ì •ë³´ í¬í•¨
            npc_info = f"ID: {npc_id} | ì´ë¦„: {name}"
            if ko_name:
                npc_info += f" | í•œê¸€ ì´ë¦„: {ko_name}"
                
            npc_info_list.append(npc_info)
        
        npc_options = "\n".join(npc_info_list)
        
        mode = "ì§ì ‘ ì–¸ê¸‰ ê°ì§€" if is_direct_mention else "ì‘ë‹µ NPC ì„ íƒ"
        logger.info(f"ğŸ§  LLMì„ ì‚¬ìš©í•œ {mode} ì‹œì‘: '{user_message[:50]}...'")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± - ëª©ì ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì¡°ì •
        if is_direct_mention:
            system_prompt = f"""
            ë‹¹ì‹ ì€ ëŒ€í™”ì—ì„œ ì‚¬ìš©ìê°€ ì§ì ‘ ì–¸ê¸‰í•œ ì°¸ì—¬ìë¥¼ ê°ì§€í•˜ëŠ” AIì…ë‹ˆë‹¤.
            
            ì•„ë˜ ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì§ì ‘ ì–¸ê¸‰ëœ ì°¸ì—¬ì(NPC)ê°€ ìˆëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”.
            
            ê°€ëŠ¥í•œ NPC ëª©ë¡:
            {npc_options}
            
            ê·œì¹™:
            1. ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ NPCì˜ ì´ë¦„ì´ë‚˜ IDê°€ ì§ì ‘ ì–¸ê¸‰ëœ ê²½ìš°ì—ë§Œ í•´ë‹¹ NPCë¥¼ ì„ íƒí•˜ì„¸ìš”.
            2. ì˜¤íƒ€ê°€ ìˆì–´ë„ ë¶„ëª…íˆ íŠ¹ì • NPCë¥¼ ì§€ì¹­í–ˆë‹¤ë©´ í•´ë‹¹ NPCë¥¼ ì„ íƒí•˜ì„¸ìš”.
            3. ì§ì ‘ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ì•„ë¬´ ê²ƒë„ ì„ íƒí•˜ì§€ ë§ˆì„¸ìš”.
            4. ì„ íƒí•œ NPCì˜ IDë§Œ ì •í™•íˆ ë°˜í™˜í•˜ì„¸ìš”. (ì˜ˆ: "e0c3872b-2103-4d04-8a2d-801bbd7f43cf")
            
            ì¶œë ¥ í˜•ì‹:
            NPC_ID: <npc_id ë˜ëŠ” 'ì—†ìŒ'>
            """
        else:
            system_prompt = f"""
            ë‹¹ì‹ ì€ ëŒ€í™”ì—ì„œ ì‚¬ìš©ì ë©”ì‹œì§€ì— ê°€ì¥ ì í•©í•œ ì‘ë‹µìë¥¼ ì„ íƒí•˜ëŠ” AIì…ë‹ˆë‹¤.
            
            ì•„ë˜ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ê³ , ì‘ë‹µí•˜ê¸°ì— ê°€ì¥ ì í•©í•œ ì°¸ì—¬ì(NPC)ë¥¼ ì„ íƒí•˜ì„¸ìš”.
            
            ê°€ëŠ¥í•œ NPC ëª©ë¡:
            {npc_options}
            
            ê·œì¹™:
            1. ì‚¬ìš©ìê°€ íŠ¹ì • ì² í•™ìì˜ ê²¬í•´ë‚˜ ì´ë¡ ì„ ì–¸ê¸‰í•˜ë©´, ê·¸ ì² í•™ìë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
            2. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ì˜ê²¬ì´ íŠ¹ì • ì² í•™ìì˜ ì „ë¬¸ ë¶„ì•¼ì™€ ê´€ë ¨ìˆìœ¼ë©´, ê·¸ ì² í•™ìë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
            3. ëª¨ë“  NPCê°€ ë™ë“±í•˜ê²Œ ì‘ë‹µí•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì´ë©´, ê°€ì¥ í¥ë¯¸ë¡œìš´ ê´€ì ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” NPCë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
            4. ì„ íƒí•œ NPCì˜ IDë§Œ ì •í™•íˆ ë°˜í™˜í•˜ì„¸ìš”. (ì˜ˆ: "e0c3872b-2103-4d04-8a2d-801bbd7f43cf")
            
            ì¶œë ¥ í˜•ì‹:
            NPC_ID: <npc_id>
            """
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        if is_direct_mention:
            user_prompt = f"ë‹¤ìŒ ë©”ì‹œì§€ì—ì„œ ì‚¬ìš©ìê°€ ì§ì ‘ ì–¸ê¸‰í•œ NPCê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”: '{user_message}'"
        else:
            user_prompt = f"ë‹¤ìŒ ì‚¬ìš©ì ë©”ì‹œì§€ì— ì‘ë‹µí•˜ê¸°ì— ê°€ì¥ ì í•©í•œ NPCë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”: '{user_message}'"
        
        # LLM í˜¸ì¶œ - ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš©
        logger.debug(f"ğŸ§  NPC ì„ íƒ LLM í˜¸ì¶œ ì¤‘...")
        response = llm_manager.generate_response(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            llm_provider="openai",
            llm_model="gpt-3.5-turbo"
        )
        
        logger.debug(f"ğŸ§  LLM ì›ë³¸ ì‘ë‹µ: {response}")
        
        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ID ì¶”ì¶œ ì‹œë„
        id_match = re.search(r'NPC_ID: *(\S+)', response, re.IGNORECASE)
        if id_match:
            extracted_id = id_match.group(1).strip()
            
            # "ì—†ìŒ" ì²˜ë¦¬ (ì§ì ‘ ì–¸ê¸‰ì´ ì—†ëŠ” ê²½ìš°)
            if extracted_id.lower() in ["ì—†ìŒ", "none", "null"]:
                logger.info(f"âœ… LLM ì‘ë‹µ: ì§ì ‘ ì–¸ê¸‰ëœ NPC ì—†ìŒ")
                return None
                
            # IDê°€ ìœ íš¨í•˜ë©´ ë°˜í™˜
            if extracted_id in npcs:
                logger.info(f"âœ… LLMì´ ì„ íƒí•œ NPC ID: {extracted_id}")
                return extracted_id
            else:
                logger.warning(f"âš ï¸ LLMì´ ì¶”ì¶œí•œ IDê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ: {extracted_id}")
        
        # ì •ê·œì‹ìœ¼ë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ ì‘ë‹µì—ì„œ NPC ID í¬í•¨ ì—¬ë¶€ í™•ì¸
        for npc_id in npcs:
            if npc_id in response:
                logger.info(f"âœ… LLM ì‘ë‹µì—ì„œ NPC ID ë°œê²¬: {npc_id}")
                return npc_id
        
        # ë§Œì•½ ì§ì ‘ ì–¸ê¸‰ ê²€ì‚¬ëª¨ë“œì˜€ëŠ”ë° ì°¾ì§€ ëª»í–ˆë‹¤ë©´ None ë°˜í™˜
        if is_direct_mention:
            logger.info("âŒ ë©”ì‹œì§€ì—ì„œ ì§ì ‘ ì–¸ê¸‰ëœ NPCë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None
            
        # ì‘ë‹µ NPC ì„ íƒ ëª¨ë“œì—ì„œëŠ” ëœë¤ ì„ íƒ ì§„í–‰
        logger.warning("âŒ LLMì—ì„œ ìœ íš¨í•œ NPCë¥¼ ì„ íƒí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None
        
    except Exception as e:
        logger.error(f"LLMì„ ì‚¬ìš©í•œ NPC ì„ íƒ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

@app.get("/api/npc/get")
async def get_npc_details(id: str):
    try:
        # Cache í‚¤ ìƒì„±
        cache_key = f"npc_{id}"
        current_time = time.time()
        
        # ìºì‹œì—ì„œ ì¡°íšŒ (ë§Œë£Œ ì‹œê°„: 10ë¶„)
        if cache_key in npc_cache and (current_time - npc_cache[cache_key]['timestamp']) < 600:
            logger.info(f"ğŸ” Cache hit: NPC {id} found in cache")
            return npc_cache[cache_key]['data']
        
        logger.info(f"Looking up philosopher with ID: {id}")
        
        # UUID í˜•íƒœì¸ ê²½ìš° ì»¤ìŠ¤í…€ NPCë¡œ ê°„ì£¼
        is_uuid = False
        try:
            uuid_obj = uuid.UUID(id)
            is_uuid = True
            logger.info(f"Detected UUID format: {id}, treating as custom NPC")
        except ValueError:
            is_uuid = False
        
        if is_uuid:
            # ì»¤ìŠ¤í…€ NPC ì¡°íšŒ ë¡œì§
            custom_npc = None
            
            try:
                # MongoDBì—ì„œ NPC ì¡°íšŒ
                db_client = get_mongo_client()
                db = db_client[MONGO_DB]
                npc_collection = db["npcs"]
                
                # backend_id í•„ë“œë¡œ ì¡°íšŒ
                custom_npc = npc_collection.find_one({"backend_id": id})
                
                if custom_npc:
                    logger.info(f"Found custom NPC with backend_id: {id}")
                    
                    # MongoDB ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    custom_npc["_id"] = str(custom_npc["_id"])
                    
                    # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
                    response_data = {
                        "id": id,
                        "name": custom_npc.get("name", "Unknown"),
                        "description": custom_npc.get("description", ""),
                        "reference_philosophers": custom_npc.get("reference_philosophers", []),
                        "communication_style": custom_npc.get("communication_style", "balanced"),
                        "debate_approach": custom_npc.get("debate_approach", "dialectical"),
                        "voice_style": custom_npc.get("voice_style", ""),
                        "portrait_url": custom_npc.get("portrait_url", ""),
                        "is_custom": True
                    }
            
                    # ìºì‹œì— ì €ì¥
                    npc_cache[cache_key] = {
                        'data': response_data,
                        'timestamp': current_time
                    }
                    
                    return response_data
            except Exception as e:
                logger.error(f"Error looking up custom NPC: {str(e)}")

        # ê¸°ë³¸ ì² í•™ì ID ë˜ëŠ” ì»¤ìŠ¤í…€ NPCë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
        philosopher_id = id.lower()
        
        # YAML íŒŒì¼ì—ì„œ ì² í•™ì ì •ë³´ ì°¾ê¸°
        if philosopher_id in philosophers_data:
            data = philosophers_data[philosopher_id]
            logger.info(f"Found philosopher {philosopher_id} in YAML data")
            
            # portrait_url ì¶”ê°€
            portrait_url = None
            if philosopher_id in PORTRAITS_MAP:
                portrait_url = f"http://localhost:8000/portraits/{PORTRAITS_MAP[philosopher_id]}"
                
            response_data = {
                "id": philosopher_id,
                "name": data.get("name", "Unknown"),
                "description": data.get("description", ""),
                "key_concepts": data.get("key_concepts", []),
                "style": data.get("style", ""),  # style í•„ë“œ ì¶”ê°€
                "portrait_url": portrait_url,
                "is_custom": False
            }
            
            # ìºì‹œì— ì €ì¥
            npc_cache[cache_key] = {
                'data': response_data,
                'timestamp': current_time
            }
            
            logger.info(f"ğŸ”„ Returning and caching YAML data for philosopher: {response_data['name']}")
            return response_data
        else:
            # ìµœì¢…ì ìœ¼ë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš° 404 ì‘ë‹µ
            return JSONResponse(
                status_code=404, 
                content={"detail": f"Philosopher or NPC with ID {id} not found"}
            )
    except Exception as e:
        logger.error(f"Error in get_npc_details: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"detail": f"Failed to get NPC details: {str(e)}"}
        )

# ì±„íŒ…ë°© ìƒì„± ë° ì´ˆê¸° ë©”ì‹œì§€ ìƒì„±ì„ í†µí•©í•œ ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/rooms")
async def create_chat_room(request: ChatRoomCreationRequest):
    try:
        logger.info(f"Received room creation request: {request.title}")
        logger.info(f"Generate initial message: {request.generateInitialMessage}")
        logger.info(f"NPCs: {request.npcs}")
        logger.info(f"LLM Provider: {request.llmProvider}, Model: {request.llmModel}")
        
        # 1. ì±„íŒ…ë°© ìƒì„± - ê¸°ì¡´ ë¡œì§ ìœ ì§€
        # ê³ ìœ  ID ìƒì„±
        new_room_id = str(uuid4())
        logger.info(f"Generated new room ID: {new_room_id}")
        
        # ì±„íŒ…ë°© ê°ì²´ ìƒì„±
        new_room = {
            "id": new_room_id,
            "title": request.title,
            "context": request.context,
            "participants": {
                "users": [request.currentUser] if request.currentUser else [],
                "npcs": request.npcs
            },
            "totalParticipants": len(request.npcs) + (1 if request.currentUser else 0),
            "lastActivity": datetime.now().isoformat(),
            "isPublic": request.isPublic,
            "dialogueType": request.dialogueType
        }
        
        # ì°¬ë°˜í† ë¡  ëª¨ë“œì¼ ê²½ìš° NPC ì…ì¥ ì •ë³´ ì¶”ê°€
        if request.dialogueType == "debate" and request.npcPositions:
            new_room["npcPositions"] = request.npcPositions
            logger.info(f"ì°¬ë°˜í† ë¡  ì…ì¥ ì •ë³´ ì„¤ì •: {request.npcPositions}")
        
        # 2. ì´ˆê¸° ë©”ì‹œì§€ ìƒì„± ë¡œì§ ê°œì„  (í†µí•©)
        initial_message = None
        if request.generateInitialMessage and request.npcs and len(request.npcs) > 0:
            logger.info(f"Generating initial message for room {new_room_id}")
            first_npc_id = request.npcs[0]
            logger.info(f"Using first NPC: {first_npc_id}")
            
            try:
                # NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                npc_info = await get_npc_details(first_npc_id)
                logger.info(f"Retrieved NPC info: {npc_info['name']}")
                
                # ì² í•™ì ì„¤ëª… êµ¬ì„±
                npc_description = f"{npc_info['name']}: {npc_info['description']}"
                logger.info(f"Generated NPC description: {npc_description[:100]}...")
                
                # LLM ì„¤ì • ë””ë²„ê¹…
                logger.info(f"OpenAI API key exists: {bool(os.environ.get('OPENAI_API_KEY'))}")
                logger.info(f"Using LLM provider: {request.llmProvider}")
                logger.info(f"Using LLM model: {request.llmModel}")
                
                # ì´ˆê¸° ë©”ì‹œì§€ ìƒì„± - ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
                initial_message = ""
                max_retries = 3
                retry_count = 0
                
                while not initial_message and retry_count < max_retries:
                    try:
                        # ì´ˆê¸° ë©”ì‹œì§€ ìƒì„±
                        logger.info(f"[ATTEMPT {retry_count + 1}] Calling generate_philosophical_response with provider={request.llmProvider}, model={request.llmModel}")
                        
                        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
                        start_time = time.time()
                        initial_message_result, metadata = llm_manager.generate_philosophical_response(
                            npc_description=npc_description,
                            topic=request.title,
                            context=request.context or "",
                            llm_provider=request.llmProvider,
                            llm_model=request.llmModel
                        )
                        # ì†Œìš” ì‹œê°„ ê³„ì‚°
                        elapsed_time = time.time() - start_time
                        logger.info(f"LLM generation took {elapsed_time:.2f} seconds")
                        
                        # ì‘ë‹µ ë¡œê¹…
                        logger.info(f"LLM response (raw):\n{initial_message_result}")
                        logger.info(f"LLM metadata: {metadata}")
                        
                        # Trim the initial message
                        initial_message = initial_message_result.strip() if initial_message_result else ""
                        
                        # ë¹ˆ ë©”ì‹œì§€ ê²€ì¦
                        if not initial_message:
                            logger.warning(f"Empty message generated, retrying ({retry_count + 1}/{max_retries})")
                            retry_count += 1
                            # ë‹¤ìŒ ì‹œë„ ì „ ì§§ì€ ì§€ì—°
                            time.sleep(0.5)
                            continue
                        
                        # "Welcome to" ë©”ì‹œì§€ í•„í„°ë§
                        if initial_message.lower().startswith("welcome to"):
                            logger.warning(f"'Welcome to' message generated, retrying ({retry_count + 1}/{max_retries})")
                            retry_count += 1
                            initial_message = ""
                            continue
                            
                        logger.info(f"Successfully generated message: {initial_message[:100]}...")
                            
                    except Exception as e:
                        logger.error(f"Error in message generation attempt {retry_count + 1}: {str(e)}", exc_info=True)
                        retry_count += 1
                        time.sleep(0.5)
                
                # ìœ íš¨í•œ ë©”ì‹œì§€ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if initial_message:
                    # ë©”ì‹œì§€ ID ìƒì„±
                    message_id = f"welcome-{int(time.time())}"
                    
                    # ë©”ì‹œì§€ ê°ì²´ ìƒì„±
                    message_obj = {
                        "id": message_id,
                        "text": initial_message,
                        "sender": npc_info['name'],
                        "isUser": False,
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    # ì‘ë‹µì— ì´ˆê¸° ë©”ì‹œì§€ í¬í•¨
                    new_room["initial_message"] = message_obj
                    logger.info(f"Initial message generated for room {new_room_id} from {npc_info['name']}: {initial_message[:100]}...")
                else:
                    logger.warning(f"Failed to generate valid initial message after {max_retries} attempts")
                    # ëŒ€ì²´ ë©”ì‹œì§€ ìƒì„± (ì •ì )
                    fallback_questions = [
                        f"I find this topic of \"{request.title}\" quite fascinating. What aspects of it interest you the most?",
                        f"Let us explore \"{request.title}\" together. What questions come to mind when you consider this subject?",
                        f"The question of \"{request.title}\" has intrigued philosophers for centuries. Where shall we begin our inquiry?",
                        f"I've spent much time contemplating \"{request.title}\". What is your perspective on this matter?",
                        f"To understand \"{request.title}\", we must first examine our assumptions. What do you believe to be true about this subject?"
                    ]
                    
                    # ëœë¤ ì§ˆë¬¸ ì„ íƒ
                    fallback_message = random.choice(fallback_questions)
                    
                    message_obj = {
                        "id": f"welcome-{int(time.time())}",
                        "text": fallback_message,
                        "sender": npc_info['name'],
                        "isUser": False,
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    new_room["initial_message"] = message_obj
                    logger.info(f"Using fallback message for room {new_room_id} from {npc_info['name']}: {fallback_message}")
            except Exception as e:
                logger.exception(f"Error generating initial message: {str(e)}")
                # ì´ˆê¸° ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ìƒì„±
                try:
                    # ì‘ê¸‰ ìƒí™©ì—ì„œë„ ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì•¼ í•¨
                    default_npc_name = request.npcs[0].capitalize() if request.npcs else "Philosopher"
                    fallback_message = f"I find this topic of \"{request.title}\" intriguing. What are your thoughts on it?"
                    
                    message_obj = {
                        "id": f"welcome-{int(time.time())}",
                        "text": fallback_message,
                        "sender": default_npc_name,
                        "isUser": False,
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    new_room["initial_message"] = message_obj
                    logger.info(f"Using emergency fallback message for room {new_room_id} from {default_npc_name}")
                    logger.info(f"Room {new_room_id} has initial message from: {request.npcs[0]}")
                except Exception as final_err:
                    logger.critical(f"Unable to create any initial message: {str(final_err)}")
        
        # ì´ˆê¸° ë©”ì‹œì§€ ìœ ë¬´ ìµœì¢… í™•ì¸
        if "initial_message" in new_room:
            logger.info(f"Room {new_room_id} has initial message from: {new_room['initial_message']['sender']}")
        else:
            logger.warning(f"Room {new_room_id} has NO initial message")
        
        logger.info(f"Returning new room with ID: {new_room_id}")
        return new_room
    except Exception as e:
        logger.exception(f"Error creating chat room: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# NPC ê°„ ìë™ ëŒ€í™” ìƒì„± API
@app.post("/api/dialogue/generate")
async def generate_dialogue(request: DialogueGenerateRequest):
    try:
        logger.info(f"Received dialogue generation request for topic: {request.topic}")
        logger.info(f"Participants: {request.participants}")
        logger.info(f"Rounds: {request.rounds}")
        
        # ì°¸ì—¬ì ê²€ì¦ (ìµœì†Œ 2ëª… ì´ìƒ)
        if len(request.participants) < 2:
            logger.warning("At least 2 participants are required for dialogue")
            return {"error": "At least 2 participants are required"}
            
        # NPC ì •ë³´ ë¡œë“œ
        npc_descriptions = []
        for npc_id in request.participants:
            try:
                npc_info = await get_npc_details(npc_id)
                npc_description = f"{npc_info['name']}: {npc_info['description']}"
                npc_descriptions.append({
                    "id": npc_id,
                    "name": npc_info['name'],
                    "description": npc_description
                })
                logger.info(f"Loaded NPC {npc_info['name']} for dialogue")
            except Exception as e:
                logger.error(f"Error loading NPC {npc_id}: {str(e)}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì„¤ëª… ì¶”ê°€
                npc_descriptions.append({
                    "id": npc_id,
                    "name": npc_id.capitalize(),
                    "description": f"{npc_id.capitalize()}: A philosopher with unique perspectives"
                })
        
        # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
        dialogue_history = ""
        all_exchanges = []
        
        # NPCë“¤ ê°„ì˜ ëŒ€í™” ìƒì„±
        for round_num in range(request.rounds):
            logger.info(f"Generating dialogue round {round_num + 1}/{request.rounds}")
            
            # ê° ë¼ìš´ë“œë§ˆë‹¤ 2ëª…ì˜ NPCë¥¼ ì„ íƒí•˜ì—¬ ëŒ€í™” ì§„í–‰
            idx1 = round_num % len(npc_descriptions)
            idx2 = (round_num + 1) % len(npc_descriptions)
            npc1 = npc_descriptions[idx1]
            npc2 = npc_descriptions[idx2]
            
            logger.info(f"NPC exchange: {npc1['name']} <-> {npc2['name']}")
            
            # LLMì— ëŒ€í™” ìƒì„± ìš”ì²­
            start_time = time.time()
            dialogue_result = llm_manager.generate_dialogue_exchange(
                npc1_description=npc1['description'],
                npc2_description=npc2['description'],
                topic=request.topic,
                previous_dialogue=dialogue_history,
                source_materials=None,
                user_contexts=None
            )
            elapsed_time = time.time() - start_time
            logger.info(f"Dialogue exchange generated in {elapsed_time:.2f} seconds")
            
            # ìƒì„±ëœ ëŒ€í™” ì²˜ë¦¬
            exchanges = dialogue_result.get("exchanges", [])
            if exchanges:
                logger.info(f"Generated {len(exchanges)} dialogue exchanges")
                for exchange in exchanges:
                    # ëŒ€í™” ë‚´ìš© ì¶”ê°€
                    all_exchanges.append(exchange)
                    # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸
                    dialogue_history += f"\n{exchange['speaker']}: {exchange['content']}"
            else:
                logger.warning("No dialogue exchanges generated in this round")
            
        # ê²°ê³¼ ë°˜í™˜
        logger.info(f"Completed dialogue generation with {len(all_exchanges)} total exchanges")
        return {
            "topic": request.topic,
            "participants": [npc['name'] for npc in npc_descriptions],
            "rounds": request.rounds,
            "exchanges": all_exchanges,
            "raw_dialogue": dialogue_history.strip(),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.exception(f"Error in dialogue generation: {str(e)}")
        return {"error": f"Failed to generate dialogue: {str(e)}"}

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€ - NPC ID ì´ë¦„ ë§¤í•‘ ìƒì„± ë° ë³€í™˜ í•¨ìˆ˜
async def create_npc_id_name_mapping(npc_ids: List[str]) -> Dict[str, str]:
    """ì£¼ì–´ì§„ NPC ID ëª©ë¡ì—ì„œ ID-ì´ë¦„ ë§¤í•‘ ì‚¬ì „ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    mapping = {}
    
    for npc_id in npc_ids:
        try:
            # NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            npc_info = await get_npc_details(npc_id)
            
            # ì •ë³´ê°€ ìˆê³  ì´ë¦„ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ë§¤í•‘ ì¶”ê°€
            if npc_info and 'name' in npc_info:
                npc_name = npc_info.get('name')
                
                # ì´ë¦„ì´ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸
                if npc_name and isinstance(npc_name, str) and len(npc_name.strip()) > 0:
                    # IDë¥¼ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
                    mapping[npc_id] = npc_name
                    
                    # UUID í˜•íƒœì¸ ê²½ìš° ì¶”ê°€ ë§¤í•‘
                    if '-' in npc_id:
                        # UUID ì „ì²´ë¥¼ ë§¤í•‘
                        mapping[npc_id] = npc_name
                        
                        # ëŒ€í™”ì—ì„œ í”íˆ ì–¸ê¸‰ë˜ëŠ” UUID ì•ë¶€ë¶„ë§Œ ë§¤í•‘ (ì˜ˆ: 638e7579)
                        short_id = npc_id.split('-')[0]
                        if len(short_id) >= 8:
                            mapping[short_id] = npc_name
                            logger.debug(f"UUID ì•ë¶€ë¶„ ë§¤í•‘ ì¶”ê°€: {short_id} -> {npc_name}")
                    
                    logger.debug(f"ID-ì´ë¦„ ë§¤í•‘ ì¶”ê°€: {npc_id} -> {npc_name}")
                else:
                    logger.warning(f"NPC {npc_id}ì˜ ì´ë¦„ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŒ: {npc_name}")
            else:
                logger.warning(f"NPC {npc_id}ì˜ ìƒì„¸ ì •ë³´ê°€ ì—†ê±°ë‚˜ ì´ë¦„ì´ ì—†ìŒ")
                
        except Exception as e:
            logger.error(f"NPC ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (ID: {npc_id}): {str(e)}")
    
    # ë§¤í•‘ ì „ì²´ ë¡œê¹…
    logger.info(f"ìƒì„±ëœ ID-ì´ë¦„ ë§¤í•‘: {mapping}")
    return mapping

def replace_ids_with_names(text: str, id_name_mapping: Dict[str, str]) -> str:
    """í…ìŠ¤íŠ¸ì—ì„œ NPC IDë¥¼ í•´ë‹¹ ì´ë¦„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not text or not id_name_mapping:
        return text
        
    result = text
    
    # ë¨¼ì € ì „ì²´ UUID íŒ¨í„´ ì²˜ë¦¬ (í•˜ì´í”ˆ í¬í•¨ëœ ID ë¨¼ì €)
    uuid_pattern = r'([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})'
    
    # UUID íŒ¨í„´ì„ ì°¾ì•„ ì²˜ë¦¬
    for npc_id in id_name_mapping:
        if '-' in npc_id:  # UUID í˜•íƒœë§Œ ìš°ì„  ì²˜ë¦¬
            npc_name = id_name_mapping[npc_id]
            
            # UUID + ë‹˜ íŒ¨í„´
            result = re.sub(rf'{re.escape(npc_id)}ë‹˜', f'{npc_name}ë‹˜', result)
            
            # @UUID íŒ¨í„´
            result = re.sub(rf'@{re.escape(npc_id)}', f'@{npc_name}', result)
            
            # UUID ë‹¨ë… íŒ¨í„´ (ë‹¨ì–´ ê²½ê³„ í™•ì¸)
            result = re.sub(rf'\b{re.escape(npc_id)}\b', npc_name, result)
    
    # ê·¸ ë‹¤ìŒ í•˜ì´í”ˆì´ ì—†ëŠ” ì¼ë°˜ ID ì²˜ë¦¬
    for npc_id, npc_name in sorted(id_name_mapping.items(), key=lambda x: len(x[0]), reverse=True):
        if '-' not in npc_id:  # ì¼ë°˜ IDë§Œ ì²˜ë¦¬ (UUIDëŠ” ì´ë¯¸ ì²˜ë¦¬í•¨)
            # ë‹¤ì–‘í•œ íŒ¨í„´ ì²˜ë¦¬ (ID ìì²´, IDë‹˜, @ID ë“±)
            patterns = [
                f"{npc_id}", 
                f"{npc_id}ë‹˜",
                f"@{npc_id}"
            ]
            
            for pattern in patterns:
                # ë‹¨ì–´ ê²½ê³„ í™•ì¸ 
                matches = re.finditer(r'(\b|^)' + re.escape(pattern) + r'(\b|$)', result)
                
                # ë’¤ì—ì„œë¶€í„° ë³€í™˜(ì¸ë±ìŠ¤ê°€ ë³€í•˜ì§€ ì•Šë„ë¡)
                positions = [(m.start(), m.end()) for m in matches]
                for start, end in reversed(positions):
                    prefix = result[:start]
                    suffix = result[end:]
                    
                    if "ë‹˜" in pattern:
                        replacement = f"{npc_name}ë‹˜"
                    elif "@" in pattern:
                        replacement = f"@{npc_name}"
                    else:
                        replacement = npc_name
                        
                    result = prefix + replacement + suffix
                    logger.debug(f"NPC ID {pattern}ë¥¼ ì´ë¦„ {npc_name}ìœ¼ë¡œ ë³€í™˜")
    
    return result

# ì„œë²„ ì‹¤í–‰ (ë…ë¦½ ì‹¤í–‰ ì‹œ)
if __name__ == "__main__":
    uvicorn.run("api_server:app", host="0.0.0.0", port=8000, reload=True)

# ëŒ€í™” ìƒíƒœ ì§„ë‹¨ìš© API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.get("/api/debug/conversation/{room_id}")
async def debug_conversation_state(room_id: str):
    """ëŒ€í™” ìƒíƒœë¥¼ ì§„ë‹¨í•˜ê¸° ìœ„í•œ ë””ë²„ê¹… ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # ëŒ€í™” ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        conversation = await conversation_manager.get_or_create_conversation(room_id)
        
        # í† í° ìˆ˜ ê³„ì‚°
        message_count = len(conversation["messages"])
        total_tokens = conversation_manager._count_tokens_approx(conversation["messages"])
        token_percentage = (total_tokens / conversation_manager.max_token_limit) * 100
        
        # ìš”ì•½ëœ ë©”ì‹œì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
        summary_count = sum(1 for msg in conversation["messages"] if msg.get("is_summary", False))
        
        # ì‘ë‹µ êµ¬ì„±
        response = {
            "room_id": room_id,
            "topic": conversation["topic"],
            "message_count": message_count,
            "token_count": total_tokens,
            "token_limit": conversation_manager.max_token_limit,
            "token_percentage": f"{token_percentage:.1f}%",
            "summary_count": summary_count,
            "npcs": conversation["npcs"],
            "recent_messages": [
                {
                    "id": msg.get("id", "unknown"),
                    "sender": msg.get("sender", "unknown"),
                    "is_summary": msg.get("is_summary", False),
                    "length": len(msg.get("text", "")),
                    "tokens": conversation_manager._count_tokens_approx([msg])
                }
                for msg in conversation["messages"][-5:] # ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ í¬í•¨
            ],
            "server_time": datetime.now().isoformat()
        }
        
        logger.info(f"ğŸ” ëŒ€í™” ìƒíƒœ ì§„ë‹¨ - Room {room_id}: {message_count}ê°œ ë©”ì‹œì§€, {total_tokens}ê°œ í† í° ({token_percentage:.1f}%)")
        return response
        
    except Exception as e:
        logger.error(f"âŒ ëŒ€í™” ìƒíƒœ ì§„ë‹¨ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ëŒ€í™” ìƒíƒœë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

# í† í° ì¹´ìš´íŠ¸ í…ŒìŠ¤íŠ¸ìš© API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.post("/api/debug/tokencount")
async def debug_token_count(text: str):
    """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë””ë²„ê¹… ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # í…ìŠ¤íŠ¸ë¥¼ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        test_message = {"text": text}
        
        # tiktokenìœ¼ë¡œ í† í° ìˆ˜ ê³„ì‚°
        token_count = 0
        char_count = len(text)
        
        if 'tiktoken' in globals():
            encoding = tiktoken.encoding_for_model("gpt-4")
            token_count = len(encoding.encode(text))
        else:
            # ê·¼ì‚¬ì¹˜ ê³„ì‚°
            token_count = char_count // 4
        
        return {
            "text_length": char_count,
            "token_count": token_count,
            "tokens_per_char": token_count / char_count if char_count > 0 else 0,
            "using_tiktoken": 'tiktoken' in globals()
        }
    except Exception as e:
        logger.error(f"âŒ í† í° ê³„ì‚° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í† í° ê³„ì‚° ì˜¤ë¥˜: {str(e)}")